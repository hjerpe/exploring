{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vKSxr-q27Xk5"
   },
   "source": [
    "# L4-D - Building your own Quantizer: Load your Quantized Weights from Hugging Face Hub\n",
    "\n",
    "In this lesson, you will learn memory efficient model loading."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dGQrTCG58GY2"
   },
   "source": [
    "Run the next cell to import all of the functions you have used before in the previous lesson(s) of `Building your own Quantizer` to follow along with the video.\n",
    "\n",
    "- To access the `helper.py` file, you can click `File --> Open...`, on the top left."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "\n",
    "from helper import W8A16LinearLayer, replace_linear_with_target_and_quantize, replace_linear_with_target\n",
    "from dotenv import load_dotenv, find_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = load_dotenv(find_dotenv())\n",
    "hf_access_token = os.getenv(\"HF_ACCESS_TOKEN\")\n",
    "hf_write = os.getenv(\"HF_WRITE\")\n",
    "print(hf_access_token)\n",
    "print(hf_write)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K_l5R7AFoVpd"
   },
   "source": [
    "## Memory Efficient Model Loading\n",
    "\n",
    "- Load [facebook/opt-125m](https://huggingface.co/facebook/opt-125m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 145,
     "referenced_widgets": [
      "5a7754d36b674876a0bae29b4c4f11d9",
      "c658d9df748b48c1adb06e4d3d4902f1",
      "04ca325e4a49419fbee7dd59c0f07fc0",
      "d4c13f7416454241a528c248fdee5a95",
      "44389f5e666e49e089123389d2579ec9",
      "bc39279e834a4afcbff01f5df265dbfb",
      "2eb5f8e58f3744c98e9b89d85410c635",
      "2c03277df8874208a7104394783a18d5",
      "07bd53fa9fcd4314babc5d817934eaef",
      "ae2b9066c32848039d3455a80099527d",
      "97b7eed82a304e23beedd5af1768a56e",
      "6295e65e21854dfa87a9fef743f59766",
      "5ec35cb8548241929be54d7b47939cfd",
      "27489d707ce64af99fc14e064f3c4d06",
      "f6b94c8a65004a6ba8e2761d54166c55",
      "52192bd284c944ecb4c03c792f46b369",
      "08535d87616a4748aa6977252cea83f6",
      "5b427337b23447ef8e2d035b1ea375ab",
      "a53e8b3f6e664da297f62184cbc7b62e",
      "0508129e3c254387ad852a136c4b26b8",
      "344ba2e021b84144b39ae5c302c9230a",
      "601ecaebbc184783ae790341d4df9871",
      "a981a5036fb74718a93cea81376bb99b",
      "47d09961cd5945dd8f26562b68f5ad9e",
      "4935b71b9366450594aca81fe3253120",
      "6cb925d5314d477a8de49cdbfbe98df0",
      "8686aa3f09f949e89335788c9dd2c021",
      "a61db1587b44416cb8d25cdf7b1f30f8",
      "021bb3b96943486d9460163e9a2ed3fc",
      "9102b226914b467e99295ffc4e29930b",
      "7d4278ef0ac6415689acfbe9f9b5c7d2",
      "8c914a5f84584e74bd68284a15f2861c"
     ]
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1700734507308,
     "user": {
      "displayName": "Younes Belkada",
      "userId": "15414910276690549281"
     },
     "user_tz": -60
    },
    "height": 132,
    "id": "BeSUMWv5rOLl",
    "outputId": "81c3def4-3c3a-4ad6-d827-5a05230fe440"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "model_id = \"facebook/opt-125m\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id, torch_dtype=torch.bfloat16, low_cpu_mem_usage=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1198,
     "status": "ok",
     "timestamp": 1700735397916,
     "user": {
      "displayName": "Younes Belkada",
      "userId": "15414910276690549281"
     },
     "user_tz": -60
    },
    "height": 64,
    "id": "WKHiXdnUoVQb"
   },
   "outputs": [],
   "source": [
    "replace_linear_with_target_and_quantize(model, \n",
    "                             W8A16LinearLayer, \n",
    "                                   [\"lm_head\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2075,
     "status": "ok",
     "timestamp": 1700735400948,
     "user": {
      "displayName": "Younes Belkada",
      "userId": "15414910276690549281"
     },
     "user_tz": -60
    },
    "height": 30,
    "id": "w6MNxYD3rmGh"
   },
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 278,
     "status": "ok",
     "timestamp": 1700735401224,
     "user": {
      "displayName": "Younes Belkada",
      "userId": "15414910276690549281"
     },
     "user_tz": -60
    },
    "height": 47,
    "id": "xXoiKTZErq-o"
   },
   "outputs": [],
   "source": [
    "quantized_state_dict = model.state_dict()\n",
    "torch.save(quantized_state_dict, \"quantized_state_dict.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The below code is for demonstration purposes only.\n",
    "- You'll need your own Hugging Face username in order for it to run.\n",
    "- You'll add your usernmae in `YOUR_HF_USERNAME = \"\"` "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "executionInfo": {
     "elapsed": 1893,
     "status": "ok",
     "timestamp": 1700735409396,
     "user": {
      "displayName": "Younes Belkada",
      "userId": "15414910276690549281"
     },
     "user_tz": -60
    },
    "id": "BPWEUwa6rtrG",
    "outputId": "f354bb37-12d3-4037-8b87-36d60cd3e0ce"
   },
   "source": [
    "```Python\n",
    "from huggingface_hub import HfApi, create_repo\n",
    "\n",
    "YOUR_HF_USERNAME = \"\"\n",
    "your_repo_id = f\"{YOUR_HF_USERNAME}/opt-125m-quantized-dlai\"\n",
    "\n",
    "api = HfApi()\n",
    "\n",
    "# create_repo(your_repo_id)\n",
    "\n",
    "api.upload_file(\n",
    " path_or_fileobj=\"quantized_state_dict.pth\",\n",
    " path_in_repo=\"quantized_state_dict.pth\",\n",
    " repo_id=your_repo_id\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from huggingface_hub import HfApi, create_repo\n",
    "\n",
    "YOUR_HF_USERNAME = \"hjerpe\"\n",
    "your_repo_id = f\"{YOUR_HF_USERNAME}/opt-125m-quantized-dlai\"\n",
    "\n",
    "# api = HfApi(token=hf_write)\n",
    "\n",
    "# create_repo(your_repo_id)\n",
    "\n",
    "# api.upload_file(\n",
    "#  path_or_fileobj=\"quantized_state_dict.pth\",\n",
    "#  path_in_repo=\"quantized_state_dict.pth\",\n",
    "#  repo_id=your_repo_id\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EIsqzrFDse7I"
   },
   "source": [
    "### Load the Model in the Meta Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 899,
     "status": "ok",
     "timestamp": 1700735433204,
     "user": {
      "displayName": "Younes Belkada",
      "userId": "15414910276690549281"
     },
     "user_tz": -60
    },
    "height": 166,
    "id": "qL8wID_ysyVD"
   },
   "outputs": [],
   "source": [
    "from transformers import OPTForCausalLM, AutoTokenizer, AutoConfig\n",
    "\n",
    "model_id = \"facebook/opt-125m\"\n",
    "config = AutoConfig.from_pretrained(model_id)\n",
    "\n",
    "with torch.device(\"meta\"):\n",
    "  model = OPTForCausalLM(config)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 727,
     "status": "ok",
     "timestamp": 1700735010719,
     "user": {
      "displayName": "Younes Belkada",
      "userId": "15414910276690549281"
     },
     "user_tz": -60
    },
    "height": 47,
    "id": "YgkfalAts3TM",
    "outputId": "3b0cc8a6-4421-40f0-e1e0-9a03ec322530"
   },
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "  print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 30,
    "id": "tS5P5b7ptPQt"
   },
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 858,
     "status": "ok",
     "timestamp": 1700735436517,
     "user": {
      "displayName": "Younes Belkada",
      "userId": "15414910276690549281"
     },
     "user_tz": -60
    },
    "height": 30,
    "id": "Nu1gi0bUtOSw"
   },
   "outputs": [],
   "source": [
    "replace_linear_with_target(model, W8A16LinearLayer, [\"lm_head\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1700735438474,
     "user": {
      "displayName": "Younes Belkada",
      "userId": "15414910276690549281"
     },
     "user_tz": -60
    },
    "height": 30,
    "id": "zW-QYLm-tetF",
    "outputId": "9b19aa34-44fa-436b-fca1-edb47307f374"
   },
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1700735439874,
     "user": {
      "displayName": "Younes Belkada",
      "userId": "15414910276690549281"
     },
     "user_tz": -60
    },
    "height": 115,
    "id": "67U3w4pDtjm_"
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "state_dict_cache_path = hf_hub_download(\n",
    "    f\"{YOUR_HF_USERNAME}/opt-125m-quantized-dlai\",\n",
    "    \n",
    "    \"quantized_state_dict.pth\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "state_dict = torch.load(state_dict_cache_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1085,
     "status": "ok",
     "timestamp": 1700735443407,
     "user": {
      "displayName": "Younes Belkada",
      "userId": "15414910276690549281"
     },
     "user_tz": -60
    },
    "height": 30,
    "id": "uOp6TKy4t0hQ",
    "outputId": "2f35af16-fbcc-4f26-cea9-e5af43fd0532"
   },
   "outputs": [],
   "source": [
    "model.load_state_dict(state_dict, strict=True, assign=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lMpfk-2du3TB"
   },
   "source": [
    "- Test your model.\n",
    "- **Note:** Your generated text might be different than what you see in the video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12352,
     "status": "ok",
     "timestamp": 1700735485242,
     "user": {
      "displayName": "Younes Belkada",
      "userId": "15414910276690549281"
     },
     "user_tz": -60
    },
    "height": 81,
    "id": "SgLYmERGu2xu",
    "outputId": "e7200afe-9108-4b34-874b-2fa85d7f2805"
   },
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)\n",
    "pipe(\"Hello today I am\", max_new_tokens=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "pipe = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)\n",
    "pipe(\"Hello today I am giving a course about\", max_new_tokens=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "default_venv",
   "language": "python",
   "name": "default_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
