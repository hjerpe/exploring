{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c9ff22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from helper import W8A16LinearLayer\n",
    "from helper import linear_dequantization, plot_quantization_errors\n",
    "from helper import linear_q_with_scale_and_zero_point\n",
    "from helper import plot_quantization_errors\n",
    "from helper import plot_results\n",
    "from helper import quantization_error\n",
    "from huggingface_hub import hf_hub_download\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "from transformers import DetrImageProcessor, DetrForObjectDetection\n",
    "from transformers import OPTForCausalLM, AutoTokenizer, AutoConfig\n",
    "from transformers import pipeline\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from dotenv import load_dotenv, find_dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d036a0",
   "metadata": {},
   "source": [
    "# L2-A - Linear Quantization I: Quantize and De-quantize a Tensor\n",
    "\n",
    "In this lesson, you will learn the fundamentals of linear quantization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad6083aa",
   "metadata": {},
   "source": [
    "The libraries are already installed in the classroom.  If you're running this notebook on your own machine, you can install the following:\n",
    "\n",
    "```Python\n",
    "!pip install torch==2.1.1\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78be97a4",
   "metadata": {},
   "source": [
    "## Quantization with Random `Scale` and `Zero Point`\n",
    "\n",
    "- Implement Linear Quantization for when the \"scale\" and the \"zero point\" are known/randomly selected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9900c9d4",
   "metadata": {
    "height": 234
   },
   "outputs": [],
   "source": [
    "def linear_q_with_scale_and_zero_point(\n",
    "    tensor, scale, zero_point, dtype = torch.int8):\n",
    "\n",
    "    scaled_and_shifted_tensor = tensor / scale + zero_point\n",
    "\n",
    "    rounded_tensor = torch.round(scaled_and_shifted_tensor)\n",
    "\n",
    "    q_min = torch.iinfo(dtype).min\n",
    "    q_max = torch.iinfo(dtype).max\n",
    "\n",
    "    q_tensor = rounded_tensor.clamp(q_min,q_max).to(dtype)\n",
    "    \n",
    "    return q_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d9639f0",
   "metadata": {
    "height": 115,
    "id": "Oz0fFY6gMXI6"
   },
   "outputs": [],
   "source": [
    "### a dummy tensor to test the implementation\n",
    "test_tensor=torch.tensor(\n",
    "    [[191.6, -13.5, 728.6],\n",
    "     [92.14, 295.5,  -184],\n",
    "     [0,     684.6, 245.5]]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d91bc251",
   "metadata": {
    "height": 81
   },
   "outputs": [],
   "source": [
    "### these are random values for \"scale\" and \"zero_point\"\n",
    "### to test the implementation\n",
    "scale = 3.5\n",
    "zero_point = -70"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd39ce8",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "quantized_tensor = linear_q_with_scale_and_zero_point(\n",
    "    test_tensor, scale, zero_point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b91a5b4",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "quantized_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2098a6c",
   "metadata": {},
   "source": [
    "## Dequantization with Random `Scale` and `Zero Point`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d155e7a6",
   "metadata": {},
   "source": [
    "- Now, Dequantize the tensor to see how precise the quantization is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "422d2792",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "dequantized_tensor = scale * (quantized_tensor.float() - zero_point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93aa5262",
   "metadata": {
    "height": 81
   },
   "outputs": [],
   "source": [
    "# this was the original tensor\n",
    "# [[191.6, -13.5, 728.6],\n",
    "#  [92.14, 295.5,  -184],\n",
    "#  [0,     684.6, 245.5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b937b8e0",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "dequantized_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "333c63d5",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "### without casting to float\n",
    "scale * (quantized_tensor - zero_point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e0028e0",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "def linear_dequantization(quantized_tensor, scale, zero_point):\n",
    "    return scale * (quantized_tensor.float() - zero_point)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f05129",
   "metadata": {},
   "source": [
    "- Calculate `dequantized_tensor` using the function `linear_dequantization`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71cbcc32",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "dequantized_tensor = linear_dequantization(\n",
    "    quantized_tensor, scale, zero_point)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42730b42",
   "metadata": {},
   "source": [
    "- Print the results of the `dequantized_tensor`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb02750",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "dequantized_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28463d64",
   "metadata": {},
   "source": [
    "### Quantization Error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5c10d8d",
   "metadata": {},
   "source": [
    "- Load the `plot_quantization_errors` from the helper file.\n",
    "- To access the `helper.py` file, you can click `File --> Open...`, on the top left."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e9bd48d",
   "metadata": {},
   "source": [
    "- Plot the quantization results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a1c4d2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 425
    },
    "height": 47,
    "id": "5Jr5S5ZBNhkj",
    "outputId": "2edb875f-db33-48ea-aec5-1bdfb7e1f244"
   },
   "outputs": [],
   "source": [
    "plot_quantization_errors(test_tensor, quantized_tensor,\n",
    "                         dequantized_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b93ca4eb",
   "metadata": {},
   "source": [
    "**Note:** For the plot above, `Quantization Error Tensor = abs(Original Tensor - Dequantized Tensor)`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81c0591e",
   "metadata": {},
   "source": [
    "- Calculate an \"overall\" quantization error by using [Mean Squared Error](https://en.wikipedia.org/wiki/Mean_squared_error) technique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db1c949",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "dequantized_tensor - test_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc263be4",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "(dequantized_tensor - test_tensor).square()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413a403f",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "(dequantized_tensor - test_tensor).square().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aebf6ab9",
   "metadata": {},
   "source": [
    "# L2-B - Linear Quantization I: Get the Scale and Zero Point\n",
    "\n",
    "In this lesson, continue to learn about fundamentals of linear quantization, and implement your own Linear Quantizer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec6b1698",
   "metadata": {},
   "source": [
    "Run the next cell to import all of the functions you have used before in the previous lesson(s) of `Linear Quantization I` to follow along with the video.\n",
    "\n",
    "- To access the `helper.py` file, you can click `File --> Open...`, on the top left."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35012152",
   "metadata": {},
   "outputs": [],
   "source": [
    "### a dummy tensor to test the implementation\n",
    "test_tensor=torch.tensor(\n",
    "    [[191.6, -13.5, 728.6],\n",
    "     [92.14, 295.5,  -184],\n",
    "     [0,     684.6, 245.5]]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e74682b",
   "metadata": {},
   "source": [
    "## Finding `Scale` and `Zero Point` for Quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a5690b",
   "metadata": {},
   "outputs": [],
   "source": [
    "q_min = torch.iinfo(torch.int8).min\n",
    "q_max = torch.iinfo(torch.int8).max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada66749",
   "metadata": {},
   "outputs": [],
   "source": [
    "q_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86108df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "q_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0eb7111",
   "metadata": {},
   "outputs": [],
   "source": [
    "# r_min = test_tensor.min()\n",
    "r_min = test_tensor.min().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc608788",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3bd5399",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_max = test_tensor.max().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d368d2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f8ecee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "scale = (r_max - r_min) / (q_max - q_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c71fd3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37412505",
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_point = q_min - (r_min / scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f810b9d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65d6ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_point = int(round(zero_point))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b4695ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_point"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b988a41",
   "metadata": {},
   "source": [
    "- Now, put all of this in a function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "144d5539",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_q_scale_and_zero_point(tensor, dtype=torch.int8):\n",
    "    \n",
    "    q_min, q_max = torch.iinfo(dtype).min, torch.iinfo(dtype).max\n",
    "    r_min, r_max = tensor.min().item(), tensor.max().item()\n",
    "\n",
    "    scale = (r_max - r_min) / (q_max - q_min)\n",
    "\n",
    "    zero_point = q_min - (r_min / scale)\n",
    "\n",
    "    # clip the zero_point to fall in [quantized_min, quantized_max]\n",
    "    if zero_point < q_min:\n",
    "        zero_point = q_min\n",
    "    elif zero_point > q_max:\n",
    "        zero_point = q_max\n",
    "    else:\n",
    "        # round and cast to int\n",
    "        zero_point = int(round(zero_point))\n",
    "    \n",
    "    return scale, zero_point"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a60b21",
   "metadata": {},
   "source": [
    "- Test the implementation using the `test_tensor` defined earlier.\n",
    "```Python\n",
    "[[191.6, -13.5, 728.6],\n",
    " [92.14, 295.5,  -184],\n",
    " [0,     684.6, 245.5]]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e84d104",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_scale, new_zero_point = get_q_scale_and_zero_point(\n",
    "    test_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9271f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e76de56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_zero_point"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "851f6b56",
   "metadata": {},
   "source": [
    "## Quantization and Dequantization with Calculated `Scale` and `Zero Point`\n",
    "\n",
    "- Use the calculated `scale` and `zero_point` with the functions `linear_q_with_scale_and_zero_point` and `linear_dequantization`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f744b36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "quantized_tensor = linear_q_with_scale_and_zero_point(\n",
    "    test_tensor, new_scale, new_zero_point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be15404e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dequantized_tensor = linear_dequantization(quantized_tensor,\n",
    "                                           new_scale, new_zero_point)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d66164",
   "metadata": {},
   "source": [
    "- Plot to see how the Quantization Error looks like after using calculated `scale` and `zero_point`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "433026e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_quantization_errors(test_tensor, quantized_tensor, \n",
    "                         dequantized_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9344d6b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "(dequantized_tensor-test_tensor).square().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95334b64",
   "metadata": {},
   "source": [
    "### Put Everything Together: Your Own Linear Quantizer\n",
    "\n",
    "- Now, put everything togther to make your own Linear Quantizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "831a44e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_quantization(tensor, dtype=torch.int8):\n",
    "    scale, zero_point = get_q_scale_and_zero_point(tensor, \n",
    "                                                   dtype=dtype)\n",
    "    \n",
    "    quantized_tensor = linear_q_with_scale_and_zero_point(tensor,\n",
    "                                                          scale, \n",
    "                                                          zero_point, \n",
    "                                                          dtype=dtype)\n",
    "    \n",
    "    return quantized_tensor, scale , zero_point"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "438a5275",
   "metadata": {},
   "source": [
    "- Test your implementation on a random matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffcaf11c",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_tensor = torch.randn((4, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb870afe",
   "metadata": {},
   "source": [
    "**Note:** Since the values are random, what you see in the video might be different than what you will get."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b84e32e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b1cd45",
   "metadata": {},
   "outputs": [],
   "source": [
    "quantized_tensor, scale, zero_point = linear_quantization(r_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d74a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "quantized_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b66201c",
   "metadata": {},
   "outputs": [],
   "source": [
    "scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ec3f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66cd8735",
   "metadata": {},
   "outputs": [],
   "source": [
    "dequantized_tensor = linear_dequantization(quantized_tensor,\n",
    "                                           scale, zero_point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7428d90f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_quantization_errors(r_tensor, quantized_tensor,\n",
    "                         dequantized_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "520fdf92",
   "metadata": {},
   "outputs": [],
   "source": [
    "(dequantized_tensor-r_tensor).square().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "047cbc07",
   "metadata": {},
   "source": [
    "# L3-A - Linear Quantization II: Symmetric vs. Asymmetric Mode\n",
    "\n",
    "In this lesson, you will learn a different way of performing linear quantization, Symmetric Mode."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a2681c6",
   "metadata": {},
   "source": [
    "The libraries are already installed in the classroom.  If you're running this notebook on your own machine, you can install the following:\n",
    "\n",
    "```Python\n",
    "!pip install torch==2.1.1\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e5f35b7",
   "metadata": {},
   "source": [
    "## Linear Quantization: Symmetric Mode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ec1df0",
   "metadata": {},
   "source": [
    "- Implement a function which returns the `scale` for Linear Quantization in Symmetric Mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49946c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_q_scale_symmetric(tensor, dtype=torch.int8):\n",
    "    r_max = tensor.abs().max().item()\n",
    "    q_max = torch.iinfo(dtype).max\n",
    "\n",
    "    # return the scale\n",
    "    return r_max/q_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5021ea7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### test the implementation on a 4x4 matrix\n",
    "test_tensor = torch.randn((4, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd71d1af",
   "metadata": {},
   "source": [
    "**Note:** Since the values are random, what you see in the video might be different than what you will get."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "072eab9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c689fc04",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_q_scale_symmetric(test_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38df3b10",
   "metadata": {},
   "source": [
    "- Perform Linear Quantization in Symmetric Mode.\n",
    "- `linear_q_with_scale_and_zero_point` is the same function you implemented in the previous lesson."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e6985c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_q_symmetric(tensor, dtype=torch.int8):\n",
    "    scale = get_q_scale_symmetric(tensor)\n",
    "    \n",
    "    quantized_tensor = linear_q_with_scale_and_zero_point(tensor,\n",
    "                                                     scale=scale,\n",
    "                   # in symmetric quantization zero point is = 0    \n",
    "                                                    zero_point=0,\n",
    "                                                      dtype=dtype)\n",
    "    \n",
    "    return quantized_tensor, scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e6b3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "quantized_tensor, scale = linear_q_symmetric(test_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d31478",
   "metadata": {},
   "source": [
    "### Dequantization\n",
    "\n",
    "- Perform Dequantization\n",
    "- Plot the Quantization error.\n",
    "- `linear_dequantization` is the same function you implemented in the previous lesson."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62291789",
   "metadata": {},
   "outputs": [],
   "source": [
    "dequantized_tensor = linear_dequantization(quantized_tensor,scale,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "519bf73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_quantization_errors(\n",
    "    test_tensor, quantized_tensor, dequantized_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d59789a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\"\"Quantization Error : \\\n",
    "{quantization_error(test_tensor, dequantized_tensor)}\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a47ebc",
   "metadata": {},
   "source": [
    "# L3-B - Linear Quantization II: Finer Granularity for more Precision\n",
    "\n",
    "In this lesson, you will learn about different granularities of performing linear quantization. You will cover `per tensor` in this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9aa9cdb",
   "metadata": {},
   "source": [
    "Run the next cell to import all of the functions you have used before in the previous lesson(s) of `Linear Quantization II` to follow along with the video.\n",
    "\n",
    "- To access the `helper.py` file, you can click `File --> Open...`, on the top left."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9afafd15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from helper import linear_q_symmetric, get_q_scale_symmetric, linear_dequantization\n",
    "from helper import plot_quantization_errors, quantization_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b22811",
   "metadata": {},
   "source": [
    "## Different Granularities for Quantization\n",
    "- For simplicity, you'll perform these using Symmetric mode."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9222bbc4",
   "metadata": {},
   "source": [
    "### Per Tensor\n",
    "- Perform `Per Tensor` Symmetric Quantization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7dcbacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test tensor\n",
    "test_tensor=torch.tensor(\n",
    "    [[191.6, -13.5, 728.6],\n",
    "     [92.14, 295.5,  -184],\n",
    "     [0,     684.6, 245.5]]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117521ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "quantized_tensor, scale = linear_q_symmetric(test_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202aaaa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dequantized_tensor = linear_dequantization(quantized_tensor, scale, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "950456ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_quantization_errors(test_tensor, quantized_tensor,\n",
    "                         dequantized_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c7576b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\"\"Quantization Error : \\\n",
    "{quantization_error(test_tensor, dequantized_tensor)}\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f6bdfe",
   "metadata": {
    "id": "z9ln8ylCKHsx"
   },
   "source": [
    "# L3-C - Linear Quantization II: Per Channel Quantization\n",
    "\n",
    "In this lesson, you will continue to learn about different granularities of performing linear quantization. You will cover `per channel` in this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf94d98",
   "metadata": {
    "id": "JA1-rcLz4t4D"
   },
   "source": [
    "## Different Granularities for Quantization\n",
    "- For simplicity, you'll perform these using Symmetric mode."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d08f9c18",
   "metadata": {
    "id": "oo4BCLpsDw3t"
   },
   "source": [
    "### Per Channel\n",
    "- Implement `Per Channel` Symmetric Quantization\n",
    "- `dim` parameter decides if it needs to be along the rows or columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70edd138",
   "metadata": {
    "height": 98
   },
   "outputs": [],
   "source": [
    "def linear_q_symmetric_per_channel(tensor,dim,dtype=torch.int8):\n",
    "\n",
    "\n",
    "\n",
    "    return quantized_tensor, scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0473f7",
   "metadata": {
    "height": 98
   },
   "outputs": [],
   "source": [
    "test_tensor=torch.tensor(\n",
    "    [[191.6, -13.5, 728.6],\n",
    "     [92.14, 295.5,  -184],\n",
    "     [0,     684.6, 245.5]]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdc07069",
   "metadata": {},
   "source": [
    "- `dim = 0`, along the rows\n",
    "- `dim = 1`, along the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9184a5f5",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "dim=0\n",
    "output_dim = test_tensor.shape[dim]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57179f8c",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "output_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b68c9f",
   "metadata": {
    "executionInfo": {
     "elapsed": 129,
     "status": "ok",
     "timestamp": 1705361580592,
     "user": {
      "displayName": "Marc Sun",
      "userId": "00829270524676809963"
     },
     "user_tz": 300
    },
    "height": 30,
    "id": "tnEv2pJ8D56J"
   },
   "outputs": [],
   "source": [
    "scale = torch.zeros(output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af63f10",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "scale"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "451cbdb9",
   "metadata": {},
   "source": [
    "- Iterate through each row to calculate its `scale`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69780876",
   "metadata": {
    "executionInfo": {
     "elapsed": 122,
     "status": "ok",
     "timestamp": 1705361582194,
     "user": {
      "displayName": "Marc Sun",
      "userId": "00829270524676809963"
     },
     "user_tz": 300
    },
    "height": 81,
    "id": "kDMFi-enEcDC"
   },
   "outputs": [],
   "source": [
    "for index in range(output_dim):\n",
    "    sub_tensor = test_tensor.select(dim,index)\n",
    "    # print(sub_tensor)\n",
    "    scale[index] = get_q_scale_symmetric(sub_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cdcf90f",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8067ad94",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 425
    },
    "executionInfo": {
     "elapsed": 875,
     "status": "ok",
     "timestamp": 1705361583875,
     "user": {
      "displayName": "Marc Sun",
      "userId": "00829270524676809963"
     },
     "user_tz": 300
    },
    "height": 30,
    "id": "OHd3YWNBYfW3",
    "outputId": "bbd84be6-b78a-41c5-8b64-2f412d524834"
   },
   "outputs": [],
   "source": [
    "scale_shape = [1] * test_tensor.dim()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952a5156",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 425
    },
    "executionInfo": {
     "elapsed": 805,
     "status": "ok",
     "timestamp": 1705361586500,
     "user": {
      "displayName": "Marc Sun",
      "userId": "00829270524676809963"
     },
     "user_tz": 300
    },
    "height": 30,
    "id": "k4hkoyA7Ykve",
    "outputId": "3b4d185b-cdbe-4bbc-e748-d93d714d512b"
   },
   "outputs": [],
   "source": [
    "scale_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d71cc2a",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "scale_shape[dim] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b91492",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "scale_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f39a238",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "scale = scale.view(scale_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845eaf3a",
   "metadata": {
    "height": 81
   },
   "outputs": [],
   "source": [
    "# copy to be used later\n",
    "copy_scale = scale\n",
    "\n",
    "scale"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca54e255",
   "metadata": {},
   "source": [
    "#### Understanding tensor by tensor division using `view` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1873f210",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "m = torch.tensor([[1,2,3],[4,5,6],[7,8,9]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3339c6c",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ebcbc28",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "s = torch.tensor([1,5,10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1286ce4",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea4f10e",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "s.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a687da2b",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "s.view(1, 3).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "523a783f",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "# alternate way\n",
    "s.view(1, -1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ef800c",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "s.view(-1,1).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4db38f7e",
   "metadata": {},
   "source": [
    "##### Along the row division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b27c5c6",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "scale = torch.tensor([[1], [5], [10]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e1efd0",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "scale.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00fdebf3",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "m / scale"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b6fe472",
   "metadata": {},
   "source": [
    "##### Along the column division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98a5378",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "scale = torch.tensor([[1, 5, 10]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d14bd1b",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "scale.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eded27f5",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "m / scale"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b60fd2a",
   "metadata": {},
   "source": [
    "#### Coming back to quantizing the tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a75003be",
   "metadata": {
    "height": 81
   },
   "outputs": [],
   "source": [
    "# the scale you got earlier\n",
    "scale = copy_scale\n",
    "\n",
    "scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45174dc3",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "scale.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0615ce",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "quantized_tensor = linear_q_with_scale_and_zero_point(\n",
    "    test_tensor, scale=scale, zero_point=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "099ae1bc",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "quantized_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a542e4bb",
   "metadata": {},
   "source": [
    "- Now, put all this in `linear_q_symmetric_per_channel` function defined earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e9fc306",
   "metadata": {
    "height": 319
   },
   "outputs": [],
   "source": [
    "def linear_q_symmetric_per_channel(r_tensor, dim, dtype=torch.int8):\n",
    "    \n",
    "    output_dim = r_tensor.shape[dim]\n",
    "    # store the scales\n",
    "    scale = torch.zeros(output_dim)\n",
    "\n",
    "    for index in range(output_dim):\n",
    "        sub_tensor = r_tensor.select(dim, index)\n",
    "        scale[index] = get_q_scale_symmetric(sub_tensor, dtype=dtype)\n",
    "\n",
    "    # reshape the scale\n",
    "    scale_shape = [1] * r_tensor.dim()\n",
    "    scale_shape[dim] = -1\n",
    "    scale = scale.view(scale_shape)\n",
    "    quantized_tensor = linear_q_with_scale_and_zero_point(\n",
    "        r_tensor, scale=scale, zero_point=0, dtype=dtype)\n",
    "   \n",
    "    return quantized_tensor, scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d14021e",
   "metadata": {
    "height": 98
   },
   "outputs": [],
   "source": [
    "test_tensor=torch.tensor(\n",
    "    [[191.6, -13.5, 728.6],\n",
    "     [92.14, 295.5,  -184],\n",
    "     [0,     684.6, 245.5]]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ddcf85",
   "metadata": {
    "height": 132
   },
   "outputs": [],
   "source": [
    "### along the rows (dim = 0)\n",
    "quantized_tensor_0, scale_0 = linear_q_symmetric_per_channel(\n",
    "    test_tensor, dim=0)\n",
    "\n",
    "### along the columns (dim = 1)\n",
    "quantized_tensor_1, scale_1 = linear_q_symmetric_per_channel(\n",
    "    test_tensor, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f661d4",
   "metadata": {},
   "source": [
    "- Plot the quantization error for along the rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f11da7",
   "metadata": {
    "height": 98
   },
   "outputs": [],
   "source": [
    "dequantized_tensor_0 = linear_dequantization(\n",
    "    quantized_tensor_0, scale_0, 0)\n",
    "\n",
    "plot_quantization_errors(\n",
    "    test_tensor, quantized_tensor_0, dequantized_tensor_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37336324",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "print(f\"\"\"Quantization Error : \\\n",
    "{quantization_error(test_tensor, dequantized_tensor_0)}\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "983d6ef9",
   "metadata": {},
   "source": [
    "- Plot the quantization error for along the columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "238122d1",
   "metadata": {
    "height": 149
   },
   "outputs": [],
   "source": [
    "dequantized_tensor_1 = linear_dequantization(\n",
    "    quantized_tensor_1, scale_1, 0)\n",
    "\n",
    "plot_quantization_errors(\n",
    "    test_tensor, quantized_tensor_1, dequantized_tensor_1, n_bits=8)\n",
    "\n",
    "print(f\"\"\"Quantization Error : \\\n",
    "{quantization_error(test_tensor, dequantized_tensor_1)}\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ab49e9",
   "metadata": {
    "id": "z9ln8ylCKHsx"
   },
   "source": [
    "# L3-D - Linear Quantization II: Per Group Quantization\n",
    "\n",
    "In this lesson, you will continue to learn about different granularities of performing linear quantization. You will cover `per group` in this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b2d47d",
   "metadata": {
    "id": "JA1-rcLz4t4D"
   },
   "source": [
    "## Different Granularities for Quantization\n",
    "- For simplicity, you'll perform these using Symmetric mode."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b09069",
   "metadata": {
    "id": "yDin7Rm6Dzqu"
   },
   "source": [
    "### Per Group\n",
    "- For simplicity, you'll quantize a 2D tensor along the rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67869604",
   "metadata": {
    "executionInfo": {
     "elapsed": 143,
     "status": "ok",
     "timestamp": 1705361591253,
     "user": {
      "displayName": "Marc Sun",
      "userId": "00829270524676809963"
     },
     "user_tz": 300
    },
    "height": 268,
    "id": "0ZwexEliDik5"
   },
   "outputs": [],
   "source": [
    "def linear_q_symmetric_per_group(tensor, group_size,\n",
    "                                 dtype=torch.int8):\n",
    "    \n",
    "    t_shape = tensor.shape\n",
    "    assert t_shape[1] % group_size == 0\n",
    "    assert tensor.dim() == 2\n",
    "    \n",
    "    tensor = tensor.view(-1, group_size)\n",
    "    \n",
    "    quantized_tensor, scale = linear_q_symmetric_per_channel(\n",
    "                                tensor, dim=0, dtype=dtype)\n",
    "    \n",
    "    quantized_tensor = quantized_tensor.view(t_shape)\n",
    "    \n",
    "    return quantized_tensor, scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae232411",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 425
    },
    "executionInfo": {
     "elapsed": 1955,
     "status": "ok",
     "timestamp": 1705361594322,
     "user": {
      "displayName": "Marc Sun",
      "userId": "00829270524676809963"
     },
     "user_tz": 300
    },
    "height": 217,
    "id": "J2mM-wv1VwyI",
    "outputId": "4c9904ce-e288-44b4-db53-e9f7fadebdf3"
   },
   "outputs": [],
   "source": [
    "def linear_dequantization_per_group(quantized_tensor, scale, \n",
    "                                    group_size):\n",
    "    \n",
    "    q_shape = quantized_tensor.shape\n",
    "    quantized_tensor = quantized_tensor.view(-1, group_size)\n",
    "    \n",
    "    dequantized_tensor = linear_dequantization(quantized_tensor, \n",
    "                                               scale, 0)\n",
    "    \n",
    "    dequantized_tensor = dequantized_tensor.view(q_shape)\n",
    "    \n",
    "    return dequantized_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed1a4b5",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "test_tensor = torch.rand((6, 6))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a7bf78",
   "metadata": {},
   "source": [
    "**Note:** Since the values are random, what you see in the video might be different than what you will get."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a927f7",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "group_size = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885f151a",
   "metadata": {
    "height": 149
   },
   "outputs": [],
   "source": [
    "quantized_tensor, scale = linear_q_symmetric_per_group(\n",
    "    test_tensor, group_size=group_size)\n",
    "\n",
    "dequantized_tensor = linear_dequantization_per_group(\n",
    "    quantized_tensor, scale, group_size=group_size)\n",
    "\n",
    "plot_quantization_errors(\n",
    "    test_tensor, quantized_tensor, dequantized_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ffc77e",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "print(f\"\"\"Quantization Error : \\\n",
    "{quantization_error(test_tensor, dequantized_tensor)}\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9109d03",
   "metadata": {
    "id": "z9ln8ylCKHsx"
   },
   "source": [
    "# L3-E - Linear Quantization II: Quantizing Weights & Activations for Inference\n",
    "\n",
    "In this lesson, you will continue to learn different ways of performing linear quantization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "817086e8",
   "metadata": {},
   "source": [
    "Run the next cell to import all of the functions you have used before in the previous lesson(s) of `Linear Quantization II` to follow along with the video.\n",
    "\n",
    "- To access the `helper.py` file, you can click `File --> Open...`, on the top left."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0415d2d6",
   "metadata": {
    "id": "qUw1gQUu5yIe"
   },
   "source": [
    "## Linear Quantization: Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4acf63b3",
   "metadata": {},
   "source": [
    "- `W8A32` means weights in 8-bits and activations in 32-bits.\n",
    "- For simplicity, the linear layer will be without bias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db647044",
   "metadata": {
    "height": 149,
    "id": "vGll7vBT6BGI"
   },
   "outputs": [],
   "source": [
    "def quantized_linear_W8A32_without_bias(input, q_w, s_w, z_w):\n",
    "    assert input.dtype == torch.float32\n",
    "    assert q_w.dtype == torch.int8\n",
    "\n",
    "    dequantized_weight = q_w.to(torch.float32) * s_w + z_w\n",
    "    output = torch.nn.functional.linear(input, dequantized_weight)\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d89ac22",
   "metadata": {
    "executionInfo": {
     "elapsed": 113,
     "status": "ok",
     "timestamp": 1705361606028,
     "user": {
      "displayName": "Marc Sun",
      "userId": "00829270524676809963"
     },
     "user_tz": 300
    },
    "height": 30,
    "id": "7sPRcXM-AHTR"
   },
   "outputs": [],
   "source": [
    "input = torch.tensor([1, 2, 3], dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee696ce0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 133,
     "status": "ok",
     "timestamp": 1705361607599,
     "user": {
      "displayName": "Marc Sun",
      "userId": "00829270524676809963"
     },
     "user_tz": 300
    },
    "height": 64,
    "id": "o9IQsM1295iz",
    "outputId": "38f08506-db80-40ec-9840-e184a8a6fe5a"
   },
   "outputs": [],
   "source": [
    "weight = torch.tensor([[-2,   -1.13, 0.42],\n",
    "                       [-1.51, 0.25, 1.62],\n",
    "                       [0.23,  1.35, 2.15]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9813153",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "q_w, s_w  = linear_q_symmetric(weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7fcceda",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "q_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c295969",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "s_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec5e4749",
   "metadata": {
    "height": 81
   },
   "outputs": [],
   "source": [
    "output = quantized_linear_W8A32_without_bias(input,\n",
    "                                             q_w,\n",
    "                                             s_w,\n",
    "                                             0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4695d86b",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "print(f\"This is the W8A32 output: {output}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "079e19b0",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "fp32_output = torch.nn.functional.linear(input, weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8116db3e",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "print(f\"This is the output if we don't quantize: {fp32_output}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d87f039",
   "metadata": {},
   "source": [
    "# L4-A - Building your own Quantizer: Custom Build an 8-Bit Quantizer\n",
    "\n",
    "In this lesson, you will learn how to compress any model in 8-bit precision."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd038a45",
   "metadata": {},
   "source": [
    "## Step 1: class `W8A16LinearLayer`\n",
    "\n",
    "- Build the target class, `W8A16LinearLayer()`, that will be responsible for quantizing your model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98f369f2",
   "metadata": {},
   "source": [
    "### 1.1 - `w8_a16_forward` Function\n",
    "\n",
    "-\n",
    "```Python\n",
    "W8A16LinearLayer\n",
    "                    # 8-bit  # 16-bit         # optional\n",
    "* w8_a16_forward -> weights, input,   scales, bias=None\n",
    "                    \n",
    "```\n",
    "- Cast the 8-bit `weights` to the same data type as the `input`, \"casted weights\",\n",
    "- keeping the \"casted weights\" in the same range as before, [-128, 127]\n",
    "- Next, $$(({inputs} \\cdot \\text{``casted weights''}) * {scale}) + {bias}$$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbbd93d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_int8 = torch.randint(-128, 127, (32, 16)).to(torch.int8)\n",
    "random_hs = torch.randn((1, 16), dtype=torch.bfloat16)\n",
    "scales = torch.randn((1, 32), dtype=torch.bfloat16)\n",
    "bias = torch.randn((1, 32), dtype=torch.bfloat16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83474745",
   "metadata": {},
   "source": [
    "**Note:** Since the values are random, what you see in the video might be different than what you will get."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3731c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "F.linear(random_hs, random_int8.to(random_hs.dtype))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0246f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "F.linear(random_hs, random_int8.to(random_hs.dtype)) * scales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3963e5ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "(F.linear(random_hs, random_int8.to(random_hs.dtype)) * scales) + bias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dce8f73",
   "metadata": {},
   "source": [
    "- Implement all this as a function, `w8_a16_forward`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "454afd5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def w8_a16_forward(weight, input, scales, bias=None):\n",
    "    \n",
    "    casted_weights = weight.to(input.dtype)\n",
    "    output = F.linear(input, casted_weights) * scales\n",
    "    \n",
    "    if bias is not None:\n",
    "        output = output + bias\n",
    "      \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05f10e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"With bias:\\n\\n\", \n",
    "      w8_a16_forward(random_int8, random_hs, scales, bias))\n",
    "\n",
    "print(\"\\nWithout bias:\\n\\n\", \n",
    "      w8_a16_forward(random_int8, random_hs, scales))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7772b8e",
   "metadata": {},
   "source": [
    "### 1.2 - `init` Function of class `W8A16LinearLayer`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed91e63",
   "metadata": {},
   "source": [
    "- This is how the `init` is of [PyTorch Linear layer](https://pytorch.org/docs/stable/_modules/torch/nn/modules/linear.html#Linear):\n",
    "```Python\n",
    "def __init__(self, in_features, out_features, bias=True,\n",
    "             device=None, dtype=None)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c44a34c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### running this will result in an error\n",
    "class W8A16LinearLayer(nn.Module):\n",
    "    def __init__(self, in_features, out_features, \n",
    "                 bias=True, dtype=torch.float32):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.int8_weights = nn.Parameter(torch.Tensor([0, 1]\n",
    "                                     ).to(dtype=torch.int8))\n",
    "\n",
    "try:\n",
    "    \n",
    "    W8A16LinearLayer(1, 1)\n",
    "    \n",
    "except Exception as error:\n",
    "    print(\"\\033[91m\", type(error).__name__, \": \", error, \"\\033[0m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cca29c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class W8A16LinearLayer(nn.Module):\n",
    "    def __init__(self, in_features, out_features, \n",
    "                 bias=True, dtype=torch.float32):\n",
    "        super().__init__()\n",
    "        \n",
    "        \n",
    "        self.register_buffer(\n",
    "            \"int8_weights\",\n",
    "            torch.randint(\n",
    "                -128, 127, (out_features, in_features), dtype=torch.int8\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        self.register_buffer(\"scales\", \n",
    "                             torch.randn((out_features), dtype=dtype))\n",
    "        \n",
    "        if bias:\n",
    "            self.register_buffer(\"bias\", \n",
    "                                 torch.randn((1, out_features), \n",
    "                                             dtype=dtype))\n",
    "        \n",
    "        else:\n",
    "            self.bias = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9058a1a",
   "metadata": {},
   "source": [
    "- Test your implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1831e8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_instance = W8A16LinearLayer(16, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "959e742e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dummy_instance.int8_weights.shape)\n",
    "print(dummy_instance.scales.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14adbbbb",
   "metadata": {},
   "source": [
    "### 1.3 - `forward` Function of class `W8A16LinearLayer`\n",
    "\n",
    "- Use the `w8_a16_forward` defined earlier (Step 1.1) to define the `forward` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a1169b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class W8A16LinearLayer(nn.Module):\n",
    "    def __init__(self, in_features, out_features, \n",
    "                 bias=True, dtype=torch.float32):\n",
    "        super().__init__()\n",
    "        \n",
    "        \n",
    "        self.register_buffer(\n",
    "            \"int8_weights\",\n",
    "            torch.randint(\n",
    "                -128, 127, (out_features, in_features), dtype=torch.int8\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        self.register_buffer(\"scales\", \n",
    "                             torch.randn((out_features), dtype=dtype))\n",
    "        \n",
    "        if bias:\n",
    "            self.register_buffer(\"bias\", \n",
    "                                 torch.randn((1, out_features), \n",
    "                                             dtype=dtype))\n",
    "        \n",
    "        else:\n",
    "            self.bias = None\n",
    "\n",
    "    def forward(self, input):\n",
    "        return w8_a16_forward(self.int8_weights, \n",
    "                              input, self.scales, self.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e393b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "module = W8A16LinearLayer(16, 32)\n",
    "dummy_hidden_states = torch.randn(1, 6, 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf76bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "module(dummy_hidden_states).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11ac161",
   "metadata": {},
   "outputs": [],
   "source": [
    "module(dummy_hidden_states).dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c63a0fd9",
   "metadata": {},
   "source": [
    "### 1.4 - `quantize` Function of class `W8A16LinearLayer`\n",
    "\n",
    "- `quantize` function will dynamically quantize half-precision weights into `torch.int8`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c1924d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class W8A16LinearLayer(nn.Module):\n",
    "    def __init__(self, in_features, out_features, \n",
    "                 bias=True, dtype=torch.float32):\n",
    "        super().__init__()\n",
    "        \n",
    "        \n",
    "        self.register_buffer(\n",
    "            \"int8_weights\",\n",
    "            torch.randint(\n",
    "                -128, 127, (out_features, in_features), dtype=torch.int8\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        self.register_buffer(\"scales\", \n",
    "                             torch.randn((out_features), dtype=dtype))\n",
    "        \n",
    "        if bias:\n",
    "            self.register_buffer(\"bias\", \n",
    "                                 torch.randn((1, out_features), \n",
    "                                             dtype=dtype))\n",
    "        \n",
    "        else:\n",
    "            self.bias = None\n",
    "\n",
    "    def quantize(self, weights):\n",
    "        w_fp32 = weights.clone().to(torch.float32)\n",
    "\n",
    "        scales = w_fp32.abs().max(dim=-1).values / 127\n",
    "        scales = scales.to(weights.dtype)\n",
    "\n",
    "        int8_weights = torch.round(weights\n",
    "                        /scales.unsqueeze(1)).to(torch.int8)\n",
    "\n",
    "        self.int8_weights = int8_weights\n",
    "        self.scales = scales\n",
    "    \n",
    "    def forward(self, input):\n",
    "        return w8_a16_forward(self.int8_weights, \n",
    "                              input, self.scales, self.bias)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd0de40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "module = W8A16LinearLayer(4, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd2afcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Weights before:\\n\" , module.int8_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343e1d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_matrix = torch.randn((4, 8), dtype=torch.bfloat16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e9e7ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "module.quantize(random_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2bc2004",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Weights After:\\n\" , module.int8_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51c5c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "module.scales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16ab74b",
   "metadata": {},
   "outputs": [],
   "source": [
    "module.scales.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3693579",
   "metadata": {},
   "outputs": [],
   "source": [
    "module.int8_weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87807320",
   "metadata": {},
   "outputs": [],
   "source": [
    "### dequantized weights\n",
    "module.int8_weights * module.scales.unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8be8ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "### original weights\n",
    "random_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d33c57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "(random_matrix - module.int8_weights \n",
    " * module.scales.unsqueeze(1)).abs().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a65bc398",
   "metadata": {},
   "source": [
    "# L4-B - Building your own Quantizer: Replace PyTorch layers with Quantized Layers\n",
    "\n",
    "In this lesson, you will learn about the quantization pipline using your own 8-bit quantizer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9884f32",
   "metadata": {},
   "source": [
    "Run the next cell to import all of the functions you have used before in the previous lesson(s) of `Building your own Quantizer` to follow along with the video.\n",
    "\n",
    "- To access the `helper.py` file, you can click `File --> Open...`, on the top left."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e453df79",
   "metadata": {},
   "source": [
    "## Step 2: Quantization Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60bf5dfd",
   "metadata": {},
   "source": [
    "- Replace all of the `torch.nn.Linear` layers with the `W8A16LinearLayer` layer.\n",
    "- Call `quantize` on the linear layers using the original weights. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "135f99df",
   "metadata": {},
   "source": [
    "### 2.1 - Model In-place Linear Layer Replacement\n",
    "- Implement `replace_linear_with_target`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5663f117",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_linear_with_target(module, \n",
    "                               target_class, module_name_to_exclude):\n",
    "    for name, child in module.named_children():\n",
    "        if isinstance(child, nn.Linear) and not \\\n",
    "          any([x == name for x in module_name_to_exclude]):\n",
    "            old_bias = child.bias\n",
    "\n",
    "            new_module = target_class(child.in_features, \n",
    "                                      child.out_features, \n",
    "                                      old_bias is not None, \n",
    "                                      child.weight.dtype)\n",
    "            setattr(module, name, new_module)\n",
    "            if old_bias is not None:\n",
    "              getattr(module, name).bias = old_bias\n",
    "        else:\n",
    "            # Recursively call the function for nested modules\n",
    "            replace_linear_with_target(\n",
    "                child, target_class, module_name_to_exclude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c7c2dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DummyModel(torch.nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    self.emb = torch.nn.Embedding(1, 1)\n",
    "    # Try with bias\n",
    "    self.linear_1 = nn.Linear(1, 1)\n",
    "    # Try without bias\n",
    "    self.linear_2 = nn.Linear(1, 1, bias=False)\n",
    "    # Lm prediction head\n",
    "    self.lm_head = nn.Linear(1, 1, bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3711b698",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1 = DummyModel()\n",
    "model_2 = DummyModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab0f0a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "replace_linear_with_target(model_1, W8A16LinearLayer, [\"lm_head\"])\n",
    "print(model_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a2cd1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "replace_linear_with_target(model_2, W8A16LinearLayer, [])\n",
    "print(model_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23348419",
   "metadata": {},
   "source": [
    "### 2.2 - Linear Layer Replacement + Quantization\n",
    "- Modify the `replace_linear_with_target` function to also perform quantization.\n",
    "- Implement `replace_linear_with_target_and_quantize`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3484b415",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_linear_with_target_and_quantize(module, \n",
    "                               target_class, module_name_to_exclude):\n",
    "    for name, child in module.named_children():\n",
    "        if isinstance(child, nn.Linear) and not \\\n",
    "        any([x == name for x in module_name_to_exclude]):\n",
    "            old_bias = child.bias\n",
    "            old_weight = child.weight\n",
    "\n",
    "            new_module = target_class(child.in_features, \n",
    "                                      child.out_features, \n",
    "                                      old_bias is not None, \n",
    "                                      child.weight.dtype)\n",
    "            setattr(module, name, new_module)\n",
    "\n",
    "            getattr(module, name).quantize(old_weight)\n",
    "            \n",
    "            if old_bias is not None:\n",
    "              getattr(module, name).bias = old_bias\n",
    "        else:\n",
    "            # Recursively call the function for nested modules\n",
    "            replace_linear_with_target_and_quantize(child, \n",
    "                     target_class, module_name_to_exclude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34b8c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_3 = DummyModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adee637c",
   "metadata": {},
   "outputs": [],
   "source": [
    "replace_linear_with_target_and_quantize(model_3, W8A16LinearLayer, [\"lm_head\"])\n",
    "print(model_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b335020",
   "metadata": {},
   "source": [
    "# L4-C - Building your own Quantizer: Quantize any Open Source PyTorch Model\n",
    "\n",
    "In this lesson, you will look at the results of open source models compressed using the custom quantizer you built."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d8ba1f",
   "metadata": {},
   "source": [
    "Run the next cell to import all of the functions you have used before in the previous lesson(s) of `Building your own Quantizer` to follow along with the video.\n",
    "\n",
    "- To access the `helper.py` file, you can click `File --> Open...`, on the top left."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58606881",
   "metadata": {},
   "source": [
    "## Step 3: Test the Implementation on Various LLMs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcfbc457",
   "metadata": {},
   "source": [
    "### 3.1 - [Salesforce/codegen-350M-mono](https://huggingface.co/Salesforce/codegen-350M-mono)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d57560",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"Salesforce/codegen-350M-mono\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id, \n",
    "                                    torch_dtype=torch.bfloat16, \n",
    "                                             low_cpu_mem_usage=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1969b852",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d55d9fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pipe(\"def hello_world():\", max_new_tokens=20, do_sample=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b5db94",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Model before:\\n\\n\", model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "809dd5ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "replace_linear_with_target_and_quantize(model, \n",
    "                                        W8A16LinearLayer, [\"lm_head\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde73512",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "759c35b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pipe(\"def hello_world():\", max_new_tokens=20, \n",
    "           do_sample=False)[0][\"generated_text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b531516",
   "metadata": {},
   "source": [
    "### 3.2 - [facebook/detr-resnet-50](https://huggingface.co/facebook/detr-resnet-50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03733fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can specify the revision tag if you don't want the timm dependency\n",
    "processor = DetrImageProcessor.from_pretrained(\n",
    "    \"facebook/detr-resnet-50\", revision=\"no_timm\")\n",
    "model = DetrForObjectDetection.from_pretrained(\n",
    "    \"facebook/detr-resnet-50\", revision=\"no_timm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ec287e",
   "metadata": {},
   "outputs": [],
   "source": [
    "previous_memory_footprint = model.get_memory_footprint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d41e779e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Footprint of the model in MBs: \", \n",
    "      previous_memory_footprint/1e+6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f04841d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = \"dinner_with_friends.png\"\n",
    "image = Image.open(img_path).convert(\"RGB\")\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33bc5e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper import plot_results\n",
    "\n",
    "inputs = processor(images=image, return_tensors=\"pt\")\n",
    "with torch.no_grad():\n",
    "  outputs = model(**inputs)\n",
    "\n",
    "# convert outputs (bounding boxes and class logits) to COCO API\n",
    "# let's only keep detections with score > 0.9\n",
    "target_sizes = torch.tensor([image.size[::-1]])\n",
    "results = processor.post_process_object_detection(outputs, target_sizes=target_sizes, threshold=0.9)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b2c2f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results(model, image, results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ca6d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8658fe67",
   "metadata": {},
   "outputs": [],
   "source": [
    "replace_linear_with_target_and_quantize(model, \n",
    "                                        W8A16LinearLayer, \n",
    "               [\"0\", \"1\", \"2\", \"class_labels_classifier\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf21f9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Model after quantization\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d04eb59d",
   "metadata": {},
   "source": [
    "- Visualize results after quantization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a4b9025",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = processor(images=image, return_tensors=\"pt\")\n",
    "with torch.no_grad():\n",
    "  outputs = model(**inputs)\n",
    "\n",
    "# convert outputs (bounding boxes and class logits) to COCO API\n",
    "# let's only keep detections with score > 0.9\n",
    "target_sizes = torch.tensor([image.size[::-1]])\n",
    "results = processor.post_process_object_detection(outputs, target_sizes=target_sizes, threshold=0.9)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c91858",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results(model, image, results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57162440",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_footprint = model.get_memory_footprint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "247a1347",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Footprint of the model in MBs: \", \n",
    "      new_footprint/1e+6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ddcdef",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Memory saved\n",
    "print(\"Memory saved in MBs: \", \n",
    "      (previous_memory_footprint - new_footprint)/1e+6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf37ed0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a1bfc843",
   "metadata": {
    "id": "vKSxr-q27Xk5"
   },
   "source": [
    "# L4-D - Building your own Quantizer: Load your Quantized Weights from Hugging Face Hub\n",
    "\n",
    "In this lesson, you will learn memory efficient model loading."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8fffc85",
   "metadata": {
    "id": "dGQrTCG58GY2"
   },
   "source": [
    "Run the next cell to import all of the functions you have used before in the previous lesson(s) of `Building your own Quantizer` to follow along with the video.\n",
    "\n",
    "- To access the `helper.py` file, you can click `File --> Open...`, on the top left."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c49188",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = load_dotenv(find_dotenv())\n",
    "hf_access_token = os.getenv(\"HF_ACCESS_TOKEN\")\n",
    "hf_write = os.getenv(\"HF_WRITE\")\n",
    "print(hf_access_token)\n",
    "print(hf_write)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7023489d",
   "metadata": {
    "id": "K_l5R7AFoVpd"
   },
   "source": [
    "## Memory Efficient Model Loading\n",
    "\n",
    "- Load [facebook/opt-125m](https://huggingface.co/facebook/opt-125m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221b8f7f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 145,
     "referenced_widgets": [
      "5a7754d36b674876a0bae29b4c4f11d9",
      "c658d9df748b48c1adb06e4d3d4902f1",
      "04ca325e4a49419fbee7dd59c0f07fc0",
      "d4c13f7416454241a528c248fdee5a95",
      "44389f5e666e49e089123389d2579ec9",
      "bc39279e834a4afcbff01f5df265dbfb",
      "2eb5f8e58f3744c98e9b89d85410c635",
      "2c03277df8874208a7104394783a18d5",
      "07bd53fa9fcd4314babc5d817934eaef",
      "ae2b9066c32848039d3455a80099527d",
      "97b7eed82a304e23beedd5af1768a56e",
      "6295e65e21854dfa87a9fef743f59766",
      "5ec35cb8548241929be54d7b47939cfd",
      "27489d707ce64af99fc14e064f3c4d06",
      "f6b94c8a65004a6ba8e2761d54166c55",
      "52192bd284c944ecb4c03c792f46b369",
      "08535d87616a4748aa6977252cea83f6",
      "5b427337b23447ef8e2d035b1ea375ab",
      "a53e8b3f6e664da297f62184cbc7b62e",
      "0508129e3c254387ad852a136c4b26b8",
      "344ba2e021b84144b39ae5c302c9230a",
      "601ecaebbc184783ae790341d4df9871",
      "a981a5036fb74718a93cea81376bb99b",
      "47d09961cd5945dd8f26562b68f5ad9e",
      "4935b71b9366450594aca81fe3253120",
      "6cb925d5314d477a8de49cdbfbe98df0",
      "8686aa3f09f949e89335788c9dd2c021",
      "a61db1587b44416cb8d25cdf7b1f30f8",
      "021bb3b96943486d9460163e9a2ed3fc",
      "9102b226914b467e99295ffc4e29930b",
      "7d4278ef0ac6415689acfbe9f9b5c7d2",
      "8c914a5f84584e74bd68284a15f2861c"
     ]
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1700734507308,
     "user": {
      "displayName": "Younes Belkada",
      "userId": "15414910276690549281"
     },
     "user_tz": -60
    },
    "height": 132,
    "id": "BeSUMWv5rOLl",
    "outputId": "81c3def4-3c3a-4ad6-d827-5a05230fe440"
   },
   "outputs": [],
   "source": [
    "model_id = \"facebook/opt-125m\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id, torch_dtype=torch.bfloat16, low_cpu_mem_usage=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "815d789d",
   "metadata": {
    "executionInfo": {
     "elapsed": 1198,
     "status": "ok",
     "timestamp": 1700735397916,
     "user": {
      "displayName": "Younes Belkada",
      "userId": "15414910276690549281"
     },
     "user_tz": -60
    },
    "height": 64,
    "id": "WKHiXdnUoVQb"
   },
   "outputs": [],
   "source": [
    "replace_linear_with_target_and_quantize(model, \n",
    "                             W8A16LinearLayer, \n",
    "                                   [\"lm_head\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd7038ec",
   "metadata": {
    "executionInfo": {
     "elapsed": 2075,
     "status": "ok",
     "timestamp": 1700735400948,
     "user": {
      "displayName": "Younes Belkada",
      "userId": "15414910276690549281"
     },
     "user_tz": -60
    },
    "height": 30,
    "id": "w6MNxYD3rmGh"
   },
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b3fe56",
   "metadata": {
    "executionInfo": {
     "elapsed": 278,
     "status": "ok",
     "timestamp": 1700735401224,
     "user": {
      "displayName": "Younes Belkada",
      "userId": "15414910276690549281"
     },
     "user_tz": -60
    },
    "height": 47,
    "id": "xXoiKTZErq-o"
   },
   "outputs": [],
   "source": [
    "quantized_state_dict = model.state_dict()\n",
    "torch.save(quantized_state_dict, \"quantized_state_dict.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de67c4e7",
   "metadata": {},
   "source": [
    "- The below code is for demonstration purposes only.\n",
    "- You'll need your own Hugging Face username in order for it to run.\n",
    "- You'll add your usernmae in `YOUR_HF_USERNAME = \"\"` "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d976100",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "executionInfo": {
     "elapsed": 1893,
     "status": "ok",
     "timestamp": 1700735409396,
     "user": {
      "displayName": "Younes Belkada",
      "userId": "15414910276690549281"
     },
     "user_tz": -60
    },
    "id": "BPWEUwa6rtrG",
    "outputId": "f354bb37-12d3-4037-8b87-36d60cd3e0ce"
   },
   "source": [
    "```Python\n",
    "from huggingface_hub import HfApi, create_repo\n",
    "\n",
    "YOUR_HF_USERNAME = \"\"\n",
    "your_repo_id = f\"{YOUR_HF_USERNAME}/opt-125m-quantized-dlai\"\n",
    "\n",
    "api = HfApi()\n",
    "\n",
    "# create_repo(your_repo_id)\n",
    "\n",
    "api.upload_file(\n",
    " path_or_fileobj=\"quantized_state_dict.pth\",\n",
    " path_in_repo=\"quantized_state_dict.pth\",\n",
    " repo_id=your_repo_id\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0208965a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from huggingface_hub import HfApi, create_repo\n",
    "\n",
    "YOUR_HF_USERNAME = \"hjerpe\"\n",
    "your_repo_id = f\"{YOUR_HF_USERNAME}/opt-125m-quantized-dlai\"\n",
    "\n",
    "# api = HfApi(token=hf_write)\n",
    "\n",
    "# create_repo(your_repo_id)\n",
    "\n",
    "# api.upload_file(\n",
    "#  path_or_fileobj=\"quantized_state_dict.pth\",\n",
    "#  path_in_repo=\"quantized_state_dict.pth\",\n",
    "#  repo_id=your_repo_id\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92cb141c",
   "metadata": {
    "id": "EIsqzrFDse7I"
   },
   "source": [
    "### Load the Model in the Meta Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc11e1d8",
   "metadata": {
    "executionInfo": {
     "elapsed": 899,
     "status": "ok",
     "timestamp": 1700735433204,
     "user": {
      "displayName": "Younes Belkada",
      "userId": "15414910276690549281"
     },
     "user_tz": -60
    },
    "height": 166,
    "id": "qL8wID_ysyVD"
   },
   "outputs": [],
   "source": [
    "model_id = \"facebook/opt-125m\"\n",
    "config = AutoConfig.from_pretrained(model_id)\n",
    "\n",
    "with torch.device(\"meta\"):\n",
    "  model = OPTForCausalLM(config)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20c3059",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 727,
     "status": "ok",
     "timestamp": 1700735010719,
     "user": {
      "displayName": "Younes Belkada",
      "userId": "15414910276690549281"
     },
     "user_tz": -60
    },
    "height": 47,
    "id": "YgkfalAts3TM",
    "outputId": "3b0cc8a6-4421-40f0-e1e0-9a03ec322530"
   },
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "  print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d484664a",
   "metadata": {
    "height": 30,
    "id": "tS5P5b7ptPQt"
   },
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "604cd9f3",
   "metadata": {
    "executionInfo": {
     "elapsed": 858,
     "status": "ok",
     "timestamp": 1700735436517,
     "user": {
      "displayName": "Younes Belkada",
      "userId": "15414910276690549281"
     },
     "user_tz": -60
    },
    "height": 30,
    "id": "Nu1gi0bUtOSw"
   },
   "outputs": [],
   "source": [
    "replace_linear_with_target(model, W8A16LinearLayer, [\"lm_head\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c1ae0cd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1700735438474,
     "user": {
      "displayName": "Younes Belkada",
      "userId": "15414910276690549281"
     },
     "user_tz": -60
    },
    "height": 30,
    "id": "zW-QYLm-tetF",
    "outputId": "9b19aa34-44fa-436b-fca1-edb47307f374"
   },
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55083e22",
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1700735439874,
     "user": {
      "displayName": "Younes Belkada",
      "userId": "15414910276690549281"
     },
     "user_tz": -60
    },
    "height": 115,
    "id": "67U3w4pDtjm_"
   },
   "outputs": [],
   "source": [
    "state_dict_cache_path = hf_hub_download(\n",
    "    f\"{YOUR_HF_USERNAME}/opt-125m-quantized-dlai\",\n",
    "    \n",
    "    \"quantized_state_dict.pth\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f5dc68d",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "state_dict = torch.load(state_dict_cache_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df579fa",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1085,
     "status": "ok",
     "timestamp": 1700735443407,
     "user": {
      "displayName": "Younes Belkada",
      "userId": "15414910276690549281"
     },
     "user_tz": -60
    },
    "height": 30,
    "id": "uOp6TKy4t0hQ",
    "outputId": "2f35af16-fbcc-4f26-cea9-e5af43fd0532"
   },
   "outputs": [],
   "source": [
    "model.load_state_dict(state_dict, strict=True, assign=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ef984b",
   "metadata": {
    "id": "lMpfk-2du3TB"
   },
   "source": [
    "- Test your model.\n",
    "- **Note:** Your generated text might be different than what you see in the video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5396165",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12352,
     "status": "ok",
     "timestamp": 1700735485242,
     "user": {
      "displayName": "Younes Belkada",
      "userId": "15414910276690549281"
     },
     "user_tz": -60
    },
    "height": 81,
    "id": "SgLYmERGu2xu",
    "outputId": "e7200afe-9108-4b34-874b-2fa85d7f2805"
   },
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)\n",
    "pipe(\"Hello today I am\", max_new_tokens=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b195a9e",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "pipe = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)\n",
    "pipe(\"Hello today I am giving a course about\", max_new_tokens=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a1e417a",
   "metadata": {
    "id": "u4UNB9a6jCkU"
   },
   "source": [
    "# L5-B: Packing 2-bit Weights\n",
    "\n",
    "In this lesson, you will learn how to store low precision weights through a technique called \"packing\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e88b69",
   "metadata": {
    "id": "Ma4RwtOYurm-"
   },
   "source": [
    "## Packing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88908416",
   "metadata": {},
   "source": [
    "**Note:** Younes will explain the below code, and walk through each iteration step. You can go through the comprehensive explaination in the markdown below after first watching Younes's explaination.\n",
    "\n",
    "```Python\n",
    "# Example Tensor: [1, 0, 3, 2]\n",
    "    # 1 0 3 2 - 01 00 11 10\n",
    "\n",
    "    # Starting point of packed int8 Tensor\n",
    "    # [0000 0000]\n",
    "    \n",
    "    ##### First Iteration Start:\n",
    "    # packed int8 Tensor State: [0000 0000]\n",
    "    # 1 = 0000 0001\n",
    "    # 0000 0001\n",
    "    # No left shifts in the First Iteration\n",
    "    # After bit-wise OR operation between 0000 0000 and 0000 0001:\n",
    "    # packed int8 Tensor State: 0000 0001\n",
    "    ##### First Iteration End\n",
    "\n",
    "    ##### Second Iteration Start:\n",
    "    # packed int8 Tensor State: [0000 0001]\n",
    "    # 0 = 0000 0000\n",
    "    # 0000 0000\n",
    "    # 2 left shifts:\n",
    "    # [0000 0000] (1 shift)-> 0000 0000 (2 shift)-> 0000 0000\n",
    "    # After bit-wise OR operation between 0000 0001 and 0000 0000:\n",
    "    # packed int8 Tensor State: 0000 0001\n",
    "    ##### Second Iteration End\n",
    "\n",
    "    ##### Third Iteration Start:\n",
    "    # packed int8 Tensor State: [0000 0001]\n",
    "    # 3 = 0000 0011\n",
    "    # 0000 0011\n",
    "    # 4 left shifts:\n",
    "    # [0000 0011] (1 shift)-> 0000 0110 (2 shift)-> 0000 1100\n",
    "    # 0000 1100 (3 shift)-> 0001 1000 (4 shift)-> 0011 0000\n",
    "    # After bit-wise OR operation between 0000 0001 and 0011 0000:\n",
    "    # packed int8 Tensor State: 0011 0001\n",
    "    ##### Third Iteration End\n",
    "\n",
    "    ##### Fourth Iteration Start:\n",
    "    # packed int8 Tensor State: [0011 0001]\n",
    "    # 2 = 0000 0010\n",
    "    # 0000 0010\n",
    "    # 6 left shifts:\n",
    "    # [0000 0010] (1 shift)-> 0000 0100 (2 shift)-> 0000 1000\n",
    "    # 0000 1000 (3 shift)-> 0001 0000 (4 shift)-> 0010 0000\n",
    "    # 0010 0000 (5 shift)-> 0100 0000 (6 shift)-> 1000 0000\n",
    "    # After bit-wise OR operation between 0011 0001 and 1000 0000:\n",
    "    # packed int8 Tensor State: 1011 0001\n",
    "    ##### Fourth Iteration End\n",
    "    \n",
    "    # Final packed int8 Tensor State: [1011 0001]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b38d15",
   "metadata": {
    "executionInfo": {
     "elapsed": 218,
     "status": "ok",
     "timestamp": 1705676413805,
     "user": {
      "displayName": "Younes Belkada",
      "userId": "15414910276690549281"
     },
     "user_tz": 0
    },
    "height": 523,
    "id": "ErbmOljngvnC"
   },
   "outputs": [],
   "source": [
    "def pack_weights(uint8tensor, bits):\n",
    "    if uint8tensor.shape[0] * bits % 8 != 0:\n",
    "        raise ValueError(f\"The input shape needs to be a mutiple \\\n",
    "        of {8 / bits} - got {uint8tensor.shape[0]}\")\n",
    "\n",
    "    num_values = uint8tensor.shape[0] * bits // 8\n",
    "\n",
    "    num_steps = 8 // bits\n",
    "\n",
    "    unpacked_idx = 0\n",
    "\n",
    "    packed_tensor = torch.zeros((num_values), dtype=torch.uint8)\n",
    "\n",
    "    # 1 0 3 2 - 01 00 11 10\n",
    "\n",
    "    # [0000 0000] -> 0000 0001\n",
    "\n",
    "    # 0000 0001\n",
    "\n",
    "    # 0000 0000 - 0000 0000\n",
    "\n",
    "    # 0000 0011 - 0011 0000 - 0011 0001\n",
    "\n",
    "    # 1011 0001\n",
    "    \n",
    "    for i in range(num_values):\n",
    "        for j in range(num_steps):\n",
    "            packed_tensor[i] |= uint8tensor[unpacked_idx] << (bits * j)\n",
    "            unpacked_idx += 1\n",
    "    return packed_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5fb2a4f",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "unpacked_tensor = torch.tensor([1, 0, 3, 2], \n",
    "                               dtype=torch.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "816aecf8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 214,
     "status": "ok",
     "timestamp": 1705676415692,
     "user": {
      "displayName": "Younes Belkada",
      "userId": "15414910276690549281"
     },
     "user_tz": 0
    },
    "height": 30,
    "id": "zcLwmPr1Fdrg",
    "outputId": "f50ccb6b-8ec4-47dc-91c1-bc70db8aafa8"
   },
   "outputs": [],
   "source": [
    "pack_weights(unpacked_tensor, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa8ecfc",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "unpacked_tensor = torch.tensor([1, 0, 3, 2, 3, 3, 3, 3], \n",
    "                               dtype=torch.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7adb2e",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "pack_weights(unpacked_tensor, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f80e8472",
   "metadata": {
    "id": "u4UNB9a6jCkU"
   },
   "source": [
    "# L5-C: Unpacking 2-Bit Weights\n",
    "\n",
    "In this lesson, you will learn how to \"unpack\" the stored low precision \"packed\" weights."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13467b6f",
   "metadata": {
    "id": "cEu4XvK3NAef"
   },
   "source": [
    "## Unpacking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e4f423",
   "metadata": {},
   "source": [
    "**Note:** Younes will explain the below code, and walk through each iteration step. You can go through the comprehensive explaination in the markdown below after first watching Younes's explaination.\n",
    "\n",
    "```Python\n",
    "# Example Tensor: [10110001]\n",
    "    # Which was Originally: 1 0 3 2 - 01 00 11 10\n",
    "\n",
    "    # Starting point of unpacked Tensor\n",
    "    # [00000000 00000000 00000000 00000000]\n",
    "    \n",
    "    ##### First Iteration Start:\n",
    "    # packed int8 Tensor: [10110001]\n",
    "    # You want to extract 01 from [101100 01]\n",
    "    # No right shifts in the First Iteration\n",
    "    # After bit-wise OR operation between 00000000 and 10110001:\n",
    "    # [10110001 00000000 00000000 00000000]\n",
    "    # unpacked Tensor state: [10110001 00000000 00000000 00000000]\n",
    "    ##### First Iteration End\n",
    "\n",
    "    ##### Second Iteration Start:\n",
    "    # packed int8 Tensor: [10110001]\n",
    "    # You want to extract 00 from [1011 00 01]\n",
    "    # 2 right shifts:\n",
    "    # [10110001] (1 shift)-> 01011000 (2 shift)-> 00101100\n",
    "    # After bit-wise OR operation between 00000000 and 00101100:\n",
    "    # [10110001 00101100 00000000 00000000]\n",
    "    # unpacked Tensor state: [10110001 00101100 00000000 00000000]\n",
    "    ##### Second Iteration End\n",
    "\n",
    "    ##### Third Iteration Start:\n",
    "    # packed int8 Tensor: [10110001]\n",
    "    # You want to extract 11 from [10 11 0001]\n",
    "    # 4 right shifts:\n",
    "    # [10110001] (1 shift)-> 01011000 (2 shift)-> 00101100\n",
    "    # 00101100 (3 shift)-> 00010110 (4 shift)-> 00001011\n",
    "    # After bit-wise OR operation between 00000000 and 00001011:\n",
    "    # [10110001 00101100 00001011 00000000]\n",
    "    # unpacked Tensor state: [10110001 00101100 00001011 00000000]\n",
    "    ##### Third Iteration End\n",
    "\n",
    "    ##### Fourth Iteration Start:\n",
    "    # packed int8 Tensor: [10110001]\n",
    "    # You want to extract 10 from [10 110001]\n",
    "    # 6 right shifts:\n",
    "    # [10110001] (1 shift)-> 01011000 (2 shift)-> 00101100\n",
    "    # 00101100 (3 shift)-> 00010110 (4 shift)-> 00001011\n",
    "    # 00001011 (5 shift)-> 00000101 (6 shift)-> 00000010\n",
    "    # After bit-wise OR operation between 00000000 and 00000010:\n",
    "    # [10110001 00101100 00001011 00000010]\n",
    "    # unpacked Tensor state: [10110001 00101100 00001011 00000010]\n",
    "    ##### Fourth Iteration End\n",
    "    \n",
    "    # Last step: Perform masking (bit-wise AND operation)\n",
    "    # Mask: 00000011\n",
    "    # Bit-wise AND operation between \n",
    "    # unpacked Tensor and 00000011\n",
    "    # [10110001 00101100 00001011 00000010] <- unpacked tensor\n",
    "    # [00000011 00000011 00000011 00000011] <- Mask\n",
    "    # [00000001 00000000 00000011 00000010] <- Result\n",
    "\n",
    "    # Final\n",
    "    # unpacked Tensor state: [00000001 00000000 00000011 00000010]\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b92569c4",
   "metadata": {
    "executionInfo": {
     "elapsed": 214,
     "status": "ok",
     "timestamp": 1705676421893,
     "user": {
      "displayName": "Younes Belkada",
      "userId": "15414910276690549281"
     },
     "user_tz": 0
    },
    "height": 574,
    "id": "uEAWcVoONaIy"
   },
   "outputs": [],
   "source": [
    "def unpack_weights(uint8tensor, bits):\n",
    "    num_values = uint8tensor.shape[0] * 8 // bits\n",
    "\n",
    "    num_steps = 8 // bits\n",
    "\n",
    "    unpacked_tensor = torch.zeros((num_values), dtype=torch.uint8)\n",
    "\n",
    "    unpacked_idx = 0\n",
    "\n",
    "    # 1 0 3 2 - 01 00 11 10\n",
    "\n",
    "    # [00000000 00000000 00000000 00000000]\n",
    "    # [10110001 00101100 00001011 00000010]\n",
    "    # [00000001 00000000 00000011 00000010]\n",
    "\n",
    "    # 10110001\n",
    "    # 00000011\n",
    "    \n",
    "    # 00000001\n",
    "\n",
    "    # 1: [10110001]\n",
    "    # 2: [00101100]\n",
    "    # 3: [00001011]\n",
    "\n",
    "    mask = 2 ** bits - 1\n",
    "\n",
    "    for i in range(uint8tensor.shape[0]):\n",
    "        for j in range(num_steps):\n",
    "            unpacked_tensor[unpacked_idx] |= uint8tensor[i] >> (bits * j)\n",
    "            unpacked_idx += 1\n",
    "\n",
    "    unpacked_tensor &= mask\n",
    "    return unpacked_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5acb3a21",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 254,
     "status": "ok",
     "timestamp": 1705676423045,
     "user": {
      "displayName": "Younes Belkada",
      "userId": "15414910276690549281"
     },
     "user_tz": 0
    },
    "height": 47,
    "id": "6_9OAg88NyvF",
    "outputId": "d93e9b97-ad34-4127-dc40-de45daaea24c"
   },
   "outputs": [],
   "source": [
    "unpacked_tensor = torch.tensor([177, 255], \n",
    "                               dtype=torch.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dce56e1",
   "metadata": {
    "height": 47,
    "id": "E6EFomfQPD6m"
   },
   "outputs": [],
   "source": [
    "# Answer should be: torch.tensor([1, 0, 3, 2, 3, 3, 3, 3]\n",
    "unpack_weights(unpacked_tensor, 2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default_venv",
   "language": "python",
   "name": "default_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
