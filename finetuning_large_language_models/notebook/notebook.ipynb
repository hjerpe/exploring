{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a5dbdcf7",
   "metadata": {},
   "source": [
    "# Introduction to Fine-Tuning in Machine Learning"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7cc522d5",
   "metadata": {
    "id": "WMGxBP-yQoCl"
   },
   "source": [
    "# Compare finetuned vs. non-finetuned models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c48e30de",
   "metadata": {
    "cellView": "form",
    "height": 30,
    "id": "PKnPPEyPR3MO"
   },
   "outputs": [],
   "source": [
    "from llama import BasicModelRunner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7331f418",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "import os\n",
    "from llama import LLMEngine\n",
    "_ = load_dotenv(find_dotenv())\n",
    "lamini_api_key = os.environ['LAMINI_API_KEY']\n",
    "llm = LLMEngine(\n",
    "    id=\"exploring\",\n",
    "    config={\n",
    "        \"production\": {\n",
    "            \"key\": lamini_api_key,\n",
    "        }\n",
    "    },\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e5c19f8f",
   "metadata": {},
   "source": [
    "### Try Non-Finetuned models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f774c726",
   "metadata": {
    "height": 49
   },
   "outputs": [],
   "source": [
    "non_finetuned = BasicModelRunner(\"meta-llama/Llama-2-7b-hf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86dd2cbc",
   "metadata": {
    "height": 49
   },
   "outputs": [],
   "source": [
    "non_finetuned_output = non_finetuned(\"Tell me how to train my dog to sit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e448b0a6",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "print(non_finetuned_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a14fc0",
   "metadata": {
    "height": 49
   },
   "outputs": [],
   "source": [
    "print(non_finetuned(\"What do you think of Mars?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e9f3e1",
   "metadata": {
    "height": 49
   },
   "outputs": [],
   "source": [
    "print(non_finetuned(\"taylor swift's best friend\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58943b27",
   "metadata": {
    "height": 117
   },
   "outputs": [],
   "source": [
    "print(non_finetuned(\"\"\"Agent: I'm here to help you with your Amazon deliver order.\n",
    "Customer: I didn't get my item\n",
    "Agent: I'm sorry to hear that. Which item was it?\n",
    "Customer: the blanket\n",
    "Agent:\"\"\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "053f95ef",
   "metadata": {},
   "source": [
    "### Compare to finetuned models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ffa207",
   "metadata": {
    "height": 49
   },
   "outputs": [],
   "source": [
    "finetuned_model = BasicModelRunner(\"meta-llama/Llama-2-7b-chat-hf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1afa5223",
   "metadata": {
    "height": 49
   },
   "outputs": [],
   "source": [
    "finetuned_output = finetuned_model(\"Tell me how to train my dog to sit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436dc35c",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "print(finetuned_output)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "87eb0ceb",
   "metadata": {},
   "source": [
    "The instruction tags below [INST] where used to train the Llama-2 model. Later in the course when we train our own models decide on our own tags of how to train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae8c182",
   "metadata": {
    "height": 49
   },
   "outputs": [],
   "source": [
    "print(finetuned_model(\"[INST]Tell me how to train my dog to sit[/INST]\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a5f249",
   "metadata": {
    "height": 49
   },
   "outputs": [],
   "source": [
    "print(non_finetuned(\"[INST]Tell me how to train my dog to sit[/INST]\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6da18d1",
   "metadata": {
    "height": 49
   },
   "outputs": [],
   "source": [
    "print(finetuned_model(\"What do you think of Mars?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a473a71a",
   "metadata": {
    "height": 49
   },
   "outputs": [],
   "source": [
    "print(finetuned_model(\"taylor swift's best friend\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff26f726",
   "metadata": {
    "height": 117
   },
   "outputs": [],
   "source": [
    "print(finetuned_model(\"\"\"Agent: I'm here to help you with your Amazon deliver order.\n",
    "Customer: I didn't get my item\n",
    "Agent: I'm sorry to hear that. Which item was it?\n",
    "Customer: the blanket\n",
    "Agent:\"\"\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8bd34373",
   "metadata": {},
   "source": [
    "### Compare to ChatGPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "530bd6bf",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "chatgpt = BasicModelRunner(\"chat-gpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd45457",
   "metadata": {
    "height": 49
   },
   "outputs": [],
   "source": [
    "print(chatgpt(\"Tell me how to train my dog to sit\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ff8d1f54",
   "metadata": {},
   "source": [
    "# Positioning Fine-Tuning in the Machine Learning Workflow"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2ada1d27",
   "metadata": {
    "id": "FbWoGOis4KoG"
   },
   "source": [
    "# Finetuning data: compare to pretraining and basic preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad9f6c63",
   "metadata": {
    "id": "_LQ5_lop4KJq"
   },
   "outputs": [],
   "source": [
    "import jsonlines\n",
    "import itertools\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "\n",
    "import datasets\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c8ad005e",
   "metadata": {},
   "source": [
    "### Look at pretraining data set"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1e4a7e6c",
   "metadata": {},
   "source": [
    "**Sorry**, \"The Pile\" dataset is currently relocating to a new home and so we can't show you the same example that is in the video. Here is another dataset, the [\"Common Crawl\"](https://huggingface.co/datasets/c4) dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e708c68e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pretrained_dataset = load_dataset(\"EleutherAI/pile\", split=\"train\", streaming=True)\n",
    "\n",
    "pretrained_dataset = load_dataset(\"c4\", \"en\", split=\"train\", streaming=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d4f0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 5\n",
    "print(\"Pretrained dataset:\")\n",
    "top_n = itertools.islice(pretrained_dataset, n)\n",
    "for i in top_n:\n",
    "  print(i)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f6ac08b1",
   "metadata": {},
   "source": [
    "### Contrast with company finetuning dataset you will be using"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72477048",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e01c5a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"lamini_docs.jsonl\"\n",
    "instruction_dataset_df = pd.read_json(filename, lines=True)\n",
    "instruction_dataset_df.head(2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ace475d8",
   "metadata": {},
   "source": [
    "### Various ways of formatting your data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e0443f",
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = instruction_dataset_df.to_dict()\n",
    "text = examples[\"question\"][0] + examples[\"answer\"][0]\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a5755b",
   "metadata": {},
   "outputs": [],
   "source": [
    "examples.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e48b70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "534aef91",
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"question\" in examples and \"answer\" in examples:\n",
    "  text = examples[\"question\"][0] + examples[\"answer\"][0]\n",
    "elif \"instruction\" in examples and \"response\" in examples:\n",
    "  text = examples[\"instruction\"][0] + examples[\"response\"][0]\n",
    "elif \"input\" in examples and \"output\" in examples:\n",
    "  text = examples[\"input\"][0] + examples[\"output\"][0]\n",
    "else:\n",
    "  text = examples[\"text\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d9def8",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template_qa = \"\"\"### Question:\n",
    "{question}\n",
    "\n",
    "### Answer:\n",
    "{answer}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a231f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = examples[\"question\"][0]\n",
    "answer = examples[\"answer\"][0]\n",
    "\n",
    "text_with_prompt_template = prompt_template_qa.format(question=question, answer=answer)\n",
    "text_with_prompt_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4fdf089",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template_q = \"\"\"### Question:\n",
    "{question}\n",
    "\n",
    "### Answer:\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b0c1144",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_examples = len(examples[\"question\"])\n",
    "finetuning_dataset_text_only = []\n",
    "finetuning_dataset_question_answer = []\n",
    "for i in range(num_examples):\n",
    "  question = examples[\"question\"][i]\n",
    "  answer = examples[\"answer\"][i]\n",
    "\n",
    "  text_with_prompt_template_qa = prompt_template_qa.format(question=question, answer=answer)\n",
    "  finetuning_dataset_text_only.append({\"text\": text_with_prompt_template_qa})\n",
    "\n",
    "  text_with_prompt_template_q = prompt_template_q.format(question=question)\n",
    "  finetuning_dataset_question_answer.append({\"question\": text_with_prompt_template_q, \"answer\": answer})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf4d5de",
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(finetuning_dataset_text_only[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c886b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(finetuning_dataset_question_answer[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0da27ea0",
   "metadata": {},
   "source": [
    "### Common ways of storing your data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb78517",
   "metadata": {},
   "outputs": [],
   "source": [
    "with jsonlines.open(f'lamini_docs_processed.jsonl', 'w') as writer:\n",
    "    writer.write_all(finetuning_dataset_question_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb7e7fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "finetuning_dataset_name = \"lamini/lamini_docs\"\n",
    "finetuning_dataset = load_dataset(finetuning_dataset_name)\n",
    "print(finetuning_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a13627",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6b76999a",
   "metadata": {},
   "source": [
    "# Guidelines for Instruction Tuning in Machine Learning Models"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "83bf4ccd",
   "metadata": {
    "id": "rKn-Y_Pk9WjC"
   },
   "source": [
    "# Instruction-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5458964b",
   "metadata": {
    "height": 185,
    "id": "YwB8OLqiflAl"
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "import jsonlines\n",
    "\n",
    "from datasets import load_dataset\n",
    "from pprint import pprint\n",
    "\n",
    "from llama import BasicModelRunner\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e81d20b0",
   "metadata": {},
   "source": [
    "### Load instruction tuned dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3859b9c9",
   "metadata": {
    "height": 49
   },
   "outputs": [],
   "source": [
    "instruction_tuned_dataset = load_dataset(\"tatsu-lab/alpaca\", split=\"train\", streaming=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bbbc3e9",
   "metadata": {
    "height": 117
   },
   "outputs": [],
   "source": [
    "m = 5\n",
    "print(\"Instruction-tuned dataset:\")\n",
    "top_m = list(itertools.islice(instruction_tuned_dataset, m))\n",
    "for j in top_m:\n",
    "  print(j)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "395d6db4",
   "metadata": {},
   "source": [
    "### Two prompt templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3243523",
   "metadata": {
    "height": 304
   },
   "outputs": [],
   "source": [
    "prompt_template_with_input = \"\"\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
    "\n",
    "### Instruction:\n",
    "{instruction}\n",
    "\n",
    "### Input:\n",
    "{input}\n",
    "\n",
    "### Response:\"\"\"\n",
    "\n",
    "prompt_template_without_input = \"\"\"Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
    "\n",
    "### Instruction:\n",
    "{instruction}\n",
    "\n",
    "### Response:\"\"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "62830e77",
   "metadata": {},
   "source": [
    "### Hydrate prompts (add data to prompts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859bd9ce",
   "metadata": {
    "height": 185
   },
   "outputs": [],
   "source": [
    "processed_data = []\n",
    "for j in top_m:\n",
    "  if not j[\"input\"]:\n",
    "    processed_prompt = prompt_template_without_input.format(instruction=j[\"instruction\"])\n",
    "  else:\n",
    "    processed_prompt = prompt_template_with_input.format(instruction=j[\"instruction\"], input=j[\"input\"])\n",
    "\n",
    "  processed_data.append({\"input\": processed_prompt, \"output\": j[\"output\"]})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a0ac68",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "pprint(processed_data[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "82d90a8a",
   "metadata": {},
   "source": [
    "### Save data to jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f039d7f1",
   "metadata": {
    "height": 66
   },
   "outputs": [],
   "source": [
    "with jsonlines.open(f'alpaca_processed.jsonl', 'w') as writer:\n",
    "    writer.write_all(processed_data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e33a74c5",
   "metadata": {},
   "source": [
    "### Compare non-instruction-tuned vs. instruction-tuned models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e91f203",
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "dataset_path_hf = \"lamini/alpaca\"\n",
    "dataset_hf = load_dataset(dataset_path_hf)\n",
    "print(dataset_hf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e5bebd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "import os\n",
    "from llama import LLMEngine\n",
    "_ = load_dotenv(find_dotenv())\n",
    "lamini_api_key = os.environ['LAMINI_API_KEY']\n",
    "llm = LLMEngine(\n",
    "    id=\"exploring\",\n",
    "    config={\n",
    "        \"production\": {\n",
    "            \"key\": lamini_api_key,\n",
    "        }\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc1d827",
   "metadata": {
    "height": 83
   },
   "outputs": [],
   "source": [
    "non_instruct_model = BasicModelRunner(\"meta-llama/Llama-2-7b-hf\")\n",
    "non_instruct_output = non_instruct_model(\"Tell me how to train my dog to sit\")\n",
    "print(\"Not instruction-tuned output (Llama 2 Base):\", non_instruct_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f761d613",
   "metadata": {
    "height": 83
   },
   "outputs": [],
   "source": [
    "instruct_model = BasicModelRunner(\"meta-llama/Llama-2-7b-chat-hf\")\n",
    "instruct_output = instruct_model(\"Tell me how to train my dog to sit\")\n",
    "print(\"Instruction-tuned output (Llama 2): \", instruct_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee3eb1e",
   "metadata": {
    "height": 83
   },
   "outputs": [],
   "source": [
    "chatgpt = BasicModelRunner(\"chat-gpt\")\n",
    "instruct_output_chatgpt = chatgpt(\"Tell me how to train my dog to sit\")\n",
    "print(\"Instruction-tuned output (ChatGPT): \", instruct_output_chatgpt)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "29d164cc",
   "metadata": {},
   "source": [
    "### Try smaller models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949b64bc",
   "metadata": {
    "height": 66
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"EleutherAI/pythia-70m\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"EleutherAI/pythia-70m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "947e34f0",
   "metadata": {
    "height": 423
   },
   "outputs": [],
   "source": [
    "def inference(text, model, tokenizer, max_input_tokens=1000, max_output_tokens=100):\n",
    "  # Tokenize\n",
    "  input_ids = tokenizer.encode(\n",
    "          text,\n",
    "          return_tensors=\"pt\",\n",
    "          truncation=True,\n",
    "          max_length=max_input_tokens\n",
    "  )\n",
    "\n",
    "  # Generate\n",
    "  device = model.device\n",
    "  generated_tokens_with_prompt = model.generate(\n",
    "    input_ids=input_ids.to(device),\n",
    "    max_length=max_output_tokens\n",
    "  )\n",
    "\n",
    "  # Decode\n",
    "  generated_text_with_prompt = tokenizer.batch_decode(generated_tokens_with_prompt, skip_special_tokens=True)\n",
    "\n",
    "  # Strip the prompt\n",
    "  generated_text_answer = generated_text_with_prompt[0][len(text):]\n",
    "\n",
    "  return generated_text_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ba5eb8",
   "metadata": {
    "height": 83
   },
   "outputs": [],
   "source": [
    "finetuning_dataset_path = \"lamini/lamini_docs\"\n",
    "finetuning_dataset = load_dataset(finetuning_dataset_path)\n",
    "print(finetuning_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e32323cd",
   "metadata": {
    "height": 100
   },
   "outputs": [],
   "source": [
    "test_sample = finetuning_dataset[\"test\"][0]\n",
    "print(test_sample)\n",
    "\n",
    "print(inference(test_sample[\"question\"], model, tokenizer))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "12ba21d7",
   "metadata": {},
   "source": [
    "### Compare to finetuned small model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a70b4d3",
   "metadata": {
    "height": 49
   },
   "outputs": [],
   "source": [
    "instruction_model = AutoModelForCausalLM.from_pretrained(\"lamini/lamini_docs_finetuned\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4d9bb4",
   "metadata": {
    "height": 49
   },
   "outputs": [],
   "source": [
    "print(inference(test_sample[\"question\"], instruction_model, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fafc08f",
   "metadata": {
    "height": 236,
    "id": "mSJMi8I4Sgrw"
   },
   "outputs": [],
   "source": [
    "# Pssst! If you were curious how to upload your own dataset to Huggingface\n",
    "# Here is how we did it\n",
    "\n",
    "# !pip install huggingface_hub\n",
    "# !huggingface-cli login\n",
    "\n",
    "# import pandas as pd\n",
    "# import datasets\n",
    "# from datasets import Dataset\n",
    "\n",
    "# finetuning_dataset = Dataset.from_pandas(pd.DataFrame(data=finetuning_dataset))\n",
    "# finetuning_dataset.push_to_hub(dataset_path_hf)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bc7cf2c2",
   "metadata": {},
   "source": [
    "# Best Practices in Data Preparation for Model Training"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "376d6924",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34ccb79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datasets\n",
    "\n",
    "from pprint import pprint\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5e4151",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"EleutherAI/pythia-70m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a26af1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Hi, how are you?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a028c915",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_text = tokenizer(text)[\"input_ids\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e5cf330",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1162ffac",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_text = tokenizer.decode(encoded_text)\n",
    "print(\"Decoded tokens back into text: \", decoded_text)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e261e301",
   "metadata": {},
   "source": [
    "### Tokenize multiple texts at once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b07073dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_texts = [\"Hi, how are you?\", \"I'm good\", \"Yes\"]\n",
    "encoded_texts = tokenizer(list_texts)\n",
    "print(\"Encoded several texts: \", encoded_texts[\"input_ids\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d4d03585",
   "metadata": {},
   "source": [
    "### Padding and truncation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c8884e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.pad_token = tokenizer.eos_token \n",
    "encoded_texts_longest = tokenizer(list_texts, padding=True)\n",
    "print(\"Using padding: \", encoded_texts_longest[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3a2267",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_texts_truncation = tokenizer(list_texts, max_length=3, truncation=True)\n",
    "print(\"Using truncation: \", encoded_texts_truncation[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff15dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.truncation_side = \"left\"\n",
    "encoded_texts_truncation_left = tokenizer(list_texts, max_length=3, truncation=True)\n",
    "print(\"Using left-side truncation: \", encoded_texts_truncation_left[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d89e13e",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_texts_both = tokenizer(list_texts, max_length=3, truncation=True, padding=True)\n",
    "print(\"Using both padding and truncation: \", encoded_texts_both[\"input_ids\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5b214f08",
   "metadata": {},
   "source": [
    "### Prepare instruction dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2199f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "filename = \"data/lamini_docs.jsonl\"\n",
    "instruction_dataset_df = pd.read_json(filename, lines=True)\n",
    "examples = instruction_dataset_df.to_dict()\n",
    "\n",
    "if \"question\" in examples and \"answer\" in examples:\n",
    "  text = examples[\"question\"][0] + examples[\"answer\"][0]\n",
    "elif \"instruction\" in examples and \"response\" in examples:\n",
    "  text = examples[\"instruction\"][0] + examples[\"response\"][0]\n",
    "elif \"input\" in examples and \"output\" in examples:\n",
    "  text = examples[\"input\"][0] + examples[\"output\"][0]\n",
    "else:\n",
    "  text = examples[\"text\"][0]\n",
    "\n",
    "prompt_template = \"\"\"### Question:\n",
    "{question}\n",
    "\n",
    "### Answer:\"\"\"\n",
    "\n",
    "num_examples = len(examples[\"question\"])\n",
    "finetuning_dataset = []\n",
    "for i in range(num_examples):\n",
    "  question = examples[\"question\"][i]\n",
    "  answer = examples[\"answer\"][i]\n",
    "  text_with_prompt_template = prompt_template.format(question=question)\n",
    "  finetuning_dataset.append({\"question\": text_with_prompt_template, \"answer\": answer})\n",
    "\n",
    "from pprint import pprint\n",
    "print(\"One datapoint in the finetuning dataset:\")\n",
    "pprint(finetuning_dataset[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bba7abcb",
   "metadata": {},
   "source": [
    "### Tokenize a single example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42b9068",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = finetuning_dataset[0][\"question\"] + finetuning_dataset[0][\"answer\"]\n",
    "tokenized_inputs = tokenizer(\n",
    "    text,\n",
    "    return_tensors=\"np\",\n",
    "    padding=True\n",
    ")\n",
    "print(tokenized_inputs[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc3b23e",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 2048\n",
    "max_length = min(\n",
    "    tokenized_inputs[\"input_ids\"].shape[1],\n",
    "    max_length,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af8b386a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_inputs = tokenizer(\n",
    "    text,\n",
    "    return_tensors=\"np\",\n",
    "    truncation=True,\n",
    "    max_length=max_length\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a247606",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_inputs[\"input_ids\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "faa5654a",
   "metadata": {},
   "source": [
    "### Tokenize the instruction dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03dc799a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(examples):\n",
    "    if \"question\" in examples and \"answer\" in examples:\n",
    "      text = examples[\"question\"][0] + examples[\"answer\"][0]\n",
    "    elif \"input\" in examples and \"output\" in examples:\n",
    "      text = examples[\"input\"][0] + examples[\"output\"][0]\n",
    "    else:\n",
    "      text = examples[\"text\"][0]\n",
    "\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    tokenized_inputs = tokenizer(\n",
    "        text,\n",
    "        return_tensors=\"np\",\n",
    "        padding=True,\n",
    "    )\n",
    "\n",
    "    max_length = min(\n",
    "        tokenized_inputs[\"input_ids\"].shape[1],\n",
    "        2048\n",
    "    )\n",
    "    tokenizer.truncation_side = \"left\"\n",
    "    tokenized_inputs = tokenizer(\n",
    "        text,\n",
    "        return_tensors=\"np\",\n",
    "        truncation=True,\n",
    "        max_length=max_length\n",
    "    )\n",
    "\n",
    "    return tokenized_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f9e2df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "finetuning_dataset_loaded = datasets.load_dataset(\"json\", data_files=filename, split=\"train\")\n",
    "\n",
    "tokenized_dataset = finetuning_dataset_loaded.map(\n",
    "    tokenize_function,\n",
    "    batched=True,\n",
    "    batch_size=1,\n",
    "    drop_last_batch=True\n",
    ")\n",
    "\n",
    "print(tokenized_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129dd201",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_dataset = tokenized_dataset.add_column(\"labels\", tokenized_dataset[\"input_ids\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c5325a73",
   "metadata": {},
   "source": [
    "### Prepare test/train splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26ca12f",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_dataset = tokenized_dataset.train_test_split(test_size=0.1, shuffle=True, seed=123)\n",
    "print(split_dataset)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b986a74c",
   "metadata": {},
   "source": [
    "### Some datasets for you to try"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a15d07d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "finetuning_dataset_path = \"lamini/lamini_docs\"\n",
    "finetuning_dataset = datasets.load_dataset(finetuning_dataset_path)\n",
    "print(finetuning_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b9354d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "taylor_swift_dataset = \"lamini/taylor_swift\"\n",
    "bts_dataset = \"lamini/bts\"\n",
    "open_llms = \"lamini/open_llms\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba7343e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_swiftie = datasets.load_dataset(taylor_swift_dataset)\n",
    "print(dataset_swiftie[\"train\"][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4638581",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_open_llms = datasets.load_dataset(open_llms)\n",
    "print(dataset_open_llms[\"train\"][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f949e360",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_open_llms[\"train\"][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d32e8e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b3988a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is how to push your own dataset to your Huggingface hub\n",
    "# !pip install huggingface_hub\n",
    "# !huggingface-cli login\n",
    "# split_dataset.push_to_hub(dataset_path_hf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8880b1fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cf82a328",
   "metadata": {},
   "source": [
    "# Effective Training Strategies for Machine Learning Models"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d2328b41",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "51912c9a",
   "metadata": {},
   "source": [
    "## Technically, it's only a few lines of code to run on GPUs (elsewhere, ie. on Lamini).\n",
    "```\n",
    "from llama import BasicModelRunner\n",
    "\n",
    "model = BasicModelRunner(\"EleutherAI/pythia-410m\")\n",
    "model.load_data_from_jsonlines(\"lamini_docs.jsonl\")\n",
    "model.train()\n",
    "```\n",
    "1. Choose base model.\n",
    "2. Load data.\n",
    "3. Train it. Returns a model ID, dashboard, and playground interface.\n",
    "\n",
    "### Let's look under the hood at the core code running this! This is the open core of Lamini's `llama` library :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1c608e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "import tempfile\n",
    "import logging\n",
    "import random\n",
    "import config\n",
    "import os\n",
    "import yaml\n",
    "import logging\n",
    "import time\n",
    "import torch\n",
    "import transformers\n",
    "\n",
    "from utilities import *\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForCausalLM\n",
    "from transformers import TrainingArguments\n",
    "from transformers import AutoModelForCausalLM\n",
    "from llama import BasicModelRunner\n",
    "from llama import BasicModelRunner\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "global_config = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0dfc313",
   "metadata": {},
   "outputs": [],
   "source": [
    "# authorize the notebook for llama\n",
    "authorize_lamini()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "134f601b",
   "metadata": {},
   "source": [
    "### Load the Lamini docs dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc92128",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"lamini_docs.jsonl\"\n",
    "dataset_path = f\"/content/{dataset_name}\"\n",
    "use_hf = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5074e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"lamini/lamini_docs\"\n",
    "use_hf = True"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6b4b322f",
   "metadata": {},
   "source": [
    "### Set up the model, training config, and tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ddceeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"EleutherAI/pythia-70m\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc736c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_config = {\n",
    "    \"model\": {\n",
    "        \"pretrained_name\": model_name,\n",
    "        \"max_length\" : 2048\n",
    "    },\n",
    "    \"datasets\": {\n",
    "        \"use_hf\": use_hf,\n",
    "        \"path\": dataset_path\n",
    "    },\n",
    "    \"verbose\": True\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087bae34",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "train_dataset, test_dataset = tokenize_and_split_data(training_config, tokenizer)\n",
    "\n",
    "print(train_dataset)\n",
    "print(test_dataset)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0dff1ae2",
   "metadata": {},
   "source": [
    "### Load the base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5460bac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = AutoModelForCausalLM.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b035f061",
   "metadata": {},
   "outputs": [],
   "source": [
    "device_count = torch.cuda.device_count()\n",
    "if device_count > 0:\n",
    "    logger.debug(\"Select GPU device\")\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    logger.debug(\"Select CPU device\")\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b807f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2f2a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.to(device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "58d86d82",
   "metadata": {},
   "source": [
    "### Define function to carry out inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93a0e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(text, model, tokenizer, max_input_tokens=1000, max_output_tokens=100):\n",
    "  # Tokenize\n",
    "  input_ids = tokenizer.encode(\n",
    "          text,\n",
    "          return_tensors=\"pt\",\n",
    "          truncation=True,\n",
    "          max_length=max_input_tokens\n",
    "  )\n",
    "\n",
    "  # Generate\n",
    "  device = model.device\n",
    "  generated_tokens_with_prompt = model.generate(\n",
    "    input_ids=input_ids.to(device),\n",
    "    max_length=max_output_tokens\n",
    "  )\n",
    "\n",
    "  # Decode\n",
    "  generated_text_with_prompt = tokenizer.batch_decode(generated_tokens_with_prompt, skip_special_tokens=True)\n",
    "\n",
    "  # Strip the prompt\n",
    "  generated_text_answer = generated_text_with_prompt[0][len(text):]\n",
    "\n",
    "  return generated_text_answer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6f21f6d8",
   "metadata": {},
   "source": [
    "### Try the base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f4241eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_text = test_dataset[0]['question']\n",
    "print(\"Question input (test):\", test_text)\n",
    "print(f\"Correct answer from Lamini docs: {test_dataset[0]['answer']}\")\n",
    "print(\"Model's answer: \")\n",
    "print(inference(test_text, base_model, tokenizer))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2cb3e672",
   "metadata": {},
   "source": [
    "### Setup training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9366069a",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_steps = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e15e896f",
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model_name = f\"lamini_docs_{max_steps}_steps\"\n",
    "output_dir = trained_model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e84e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    # Learning rate\n",
    "    learning_rate=1.0e-5,\n",
    "\n",
    "    # Number of training epochs\n",
    "    num_train_epochs=1,\n",
    "\n",
    "    # Max steps to train for (each step is a batch of data)\n",
    "    # Overrides num_train_epochs, if not -1\n",
    "    max_steps=max_steps,\n",
    "\n",
    "    # Batch size for training\n",
    "    per_device_train_batch_size=1,\n",
    "\n",
    "    # Directory to save model checkpoints\n",
    "    output_dir=output_dir,\n",
    "\n",
    "    # Other arguments\n",
    "    overwrite_output_dir=False, # Overwrite the content of the output directory\n",
    "    disable_tqdm=False, # Disable progress bars\n",
    "    eval_steps=120, # Number of update steps between two evaluations\n",
    "    save_steps=120, # After # steps model is saved\n",
    "    warmup_steps=1, # Number of warmup steps for learning rate scheduler\n",
    "    per_device_eval_batch_size=1, # Batch size for evaluation\n",
    "    evaluation_strategy=\"steps\",\n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps=1,\n",
    "    optim=\"adafactor\",\n",
    "    gradient_accumulation_steps = 4,\n",
    "    gradient_checkpointing=False,\n",
    "\n",
    "    # Parameters for early stopping\n",
    "    load_best_model_at_end=True,\n",
    "    save_total_limit=1,\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    "    greater_is_better=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad22d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_flops = (\n",
    "  base_model.floating_point_ops(\n",
    "    {\n",
    "       \"input_ids\": torch.zeros(\n",
    "           (1, training_config[\"model\"][\"max_length\"])\n",
    "      )\n",
    "    }\n",
    "  )\n",
    "  * training_args.gradient_accumulation_steps\n",
    ")\n",
    "\n",
    "print(base_model)\n",
    "print(\"Memory footprint\", base_model.get_memory_footprint() / 1e9, \"GB\")\n",
    "print(\"Flops\", model_flops / 1e9, \"GFLOPs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88468ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=base_model,\n",
    "    model_flops=model_flops,\n",
    "    total_steps=max_steps,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f5382f68",
   "metadata": {},
   "source": [
    "### Train a few steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f6772e",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_output = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5a4bc0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ef01216d",
   "metadata": {},
   "source": [
    "### Save model locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134b7473",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = f'{output_dir}/final'\n",
    "\n",
    "trainer.save_model(save_dir)\n",
    "print(\"Saved model to:\", save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b251025",
   "metadata": {},
   "outputs": [],
   "source": [
    "finetuned_slightly_model = AutoModelForCausalLM.from_pretrained(save_dir, local_files_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4abc8530",
   "metadata": {},
   "outputs": [],
   "source": [
    "finetuned_slightly_model.to(device) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0f186fa0",
   "metadata": {},
   "source": [
    "### Run slightly trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e7cb8af",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_question = test_dataset[0]['question']\n",
    "print(\"Question input (test):\", test_question)\n",
    "\n",
    "print(\"Finetuned slightly model's answer: \")\n",
    "print(inference(test_question, finetuned_slightly_model, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a882bde2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_answer = test_dataset[0]['answer']\n",
    "print(\"Target answer output (test):\", test_answer)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1d73a88c",
   "metadata": {},
   "source": [
    "### Run same model trained for two epochs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5018fc03",
   "metadata": {},
   "outputs": [],
   "source": [
    "finetuned_longer_model = AutoModelForCausalLM.from_pretrained(\"lamini/lamini_docs_finetuned\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"lamini/lamini_docs_finetuned\")\n",
    "\n",
    "finetuned_longer_model.to(device)\n",
    "print(\"Finetuned longer model's answer: \")\n",
    "print(inference(test_question, finetuned_longer_model, tokenizer))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "01a770fb",
   "metadata": {},
   "source": [
    "### Run much larger trained model and explore moderation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb973d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name_to_id[\"bigger_model_name\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31134b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "bigger_finetuned_model = BasicModelRunner(model_name_to_id[\"bigger_model_name\"])\n",
    "bigger_finetuned_output = bigger_finetuned_model(test_question)\n",
    "print(\"Bigger (2.8B) finetuned model (test): \", bigger_finetuned_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a52f112",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for i in range(len(train_dataset)):\n",
    " if \"keep the discussion relevant to Lamini\" in train_dataset[i][\"answer\"]:\n",
    "  print(i, train_dataset[i][\"question\"], train_dataset[i][\"answer\"])\n",
    "  count += 1\n",
    "print(count)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cf9fc16e",
   "metadata": {},
   "source": [
    "### Explore moderation using small model\n",
    "First, try the non-finetuned base model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164d42be",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_tokenizer = AutoTokenizer.from_pretrained(\"EleutherAI/pythia-70m\")\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\"EleutherAI/pythia-70m\")\n",
    "print(inference(\"What do you think of Mars?\", base_model, base_tokenizer))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "55de40d0",
   "metadata": {},
   "source": [
    "### Now try moderation with finetuned small model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0178e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(inference(\"What do you think of Mars?\", finetuned_longer_model, tokenizer))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8fee03c5",
   "metadata": {},
   "source": [
    "### Finetune a model in 3 lines of code using Lamini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac5944e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BasicModelRunner(\"EleutherAI/pythia-410m\") \n",
    "model.load_data_from_jsonlines(\"lamini_docs.jsonl\")\n",
    "model.train(is_public=True) # -> returns an ID, dashboard, and chat interface"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f454b6d5",
   "metadata": {},
   "source": [
    "Follow the link above. The training can take a few minutes. You may need to refresh the URL to detect the change from 'In Progress' to 'Completed'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8d9d6820",
   "metadata": {},
   "source": [
    "# Comprehensive Evaluation of Machine Learning Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14abda4b",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e72bde9",
   "metadata": {
    "id": "p-4WU7pH4jpo"
   },
   "source": [
    "### Technically, there are very few steps to run it on GPUs, elsewhere (ie. on Lamini).\n",
    "```\n",
    "finetuned_model = BasicModelRunner(\n",
    "    \"lamini/lamini_docs_finetuned\"\n",
    ")\n",
    "finetuned_output = finetuned_model(\n",
    "    test_dataset_list # batched!\n",
    ") \n",
    "```\n",
    "\n",
    "### Let's look again under the hood! This is the open core code of Lamini's `llama` library :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c391ad",
   "metadata": {
    "height": 389
   },
   "outputs": [],
   "source": [
    "import datasets\n",
    "import tempfile\n",
    "import logging\n",
    "import random\n",
    "import config\n",
    "import os\n",
    "import yaml\n",
    "import logging\n",
    "import difflib\n",
    "import pandas as pd\n",
    "\n",
    "import transformers\n",
    "import datasets\n",
    "import torch\n",
    "\n",
    "from tqdm import tqdm\n",
    "from utilities import *\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "global_config = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a4f9318",
   "metadata": {
    "height": 83
   },
   "outputs": [],
   "source": [
    "dataset = datasets.load_dataset(\"lamini/lamini_docs\")\n",
    "\n",
    "test_dataset = dataset[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f131225",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "print(test_dataset[0][\"question\"])\n",
    "print(test_dataset[0][\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38cc2328",
   "metadata": {
    "height": 83
   },
   "outputs": [],
   "source": [
    "model_name = \"lamini/lamini_docs_finetuned\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9966d56b",
   "metadata": {},
   "source": [
    "### Setup a really basic evaluation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "158f10dd",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "def is_exact_match(a, b):\n",
    "    return a.strip() == b.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c8f69a0",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "830edb9b",
   "metadata": {
    "height": 440
   },
   "outputs": [],
   "source": [
    "def inference(text, model, tokenizer, max_input_tokens=1000, max_output_tokens=100):\n",
    "  # Tokenize\n",
    "  tokenizer.pad_token = tokenizer.eos_token\n",
    "  input_ids = tokenizer.encode(\n",
    "      text,\n",
    "      return_tensors=\"pt\",\n",
    "      truncation=True,\n",
    "      max_length=max_input_tokens\n",
    "  )\n",
    "\n",
    "  # Generate\n",
    "  device = model.device\n",
    "  generated_tokens_with_prompt = model.generate(\n",
    "    input_ids=input_ids.to(device),\n",
    "    max_length=max_output_tokens\n",
    "  )\n",
    "\n",
    "  # Decode\n",
    "  generated_text_with_prompt = tokenizer.batch_decode(generated_tokens_with_prompt, skip_special_tokens=True)\n",
    "\n",
    "  # Strip the prompt\n",
    "  generated_text_answer = generated_text_with_prompt[0][len(text):]\n",
    "\n",
    "  return generated_text_answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f92c0ef",
   "metadata": {},
   "source": [
    "### Run model and compare to expected answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b455e7",
   "metadata": {
    "height": 100
   },
   "outputs": [],
   "source": [
    "test_question = test_dataset[0][\"question\"]\n",
    "generated_answer = inference(test_question, model, tokenizer)\n",
    "print(test_question)\n",
    "print(generated_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3fc0f89",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "answer = test_dataset[0][\"answer\"]\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f29fac0",
   "metadata": {
    "height": 66
   },
   "outputs": [],
   "source": [
    "exact_match = is_exact_match(generated_answer, answer)\n",
    "print(exact_match)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd90e873",
   "metadata": {},
   "source": [
    "### Run over entire dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d86122",
   "metadata": {
    "height": 372
   },
   "outputs": [],
   "source": [
    "n = 10\n",
    "metrics = {'exact_matches': []}\n",
    "predictions = []\n",
    "for i, item in tqdm(enumerate(test_dataset)):\n",
    "    print(\"i Evaluating: \" + str(item))\n",
    "    question = item['question']\n",
    "    answer = item['answer']\n",
    "\n",
    "    try:\n",
    "      predicted_answer = inference(question, model, tokenizer)\n",
    "    except:\n",
    "      continue\n",
    "    predictions.append([predicted_answer, answer])\n",
    "\n",
    "    exact_match = is_exact_match(generated_answer, answer)\n",
    "    metrics['exact_matches'].append(exact_match)\n",
    "\n",
    "    if i > n and n != -1:\n",
    "      break\n",
    "print('Number of exact matches: ', sum(metrics['exact_matches']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23404a7a",
   "metadata": {
    "height": 66
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "df = pd.DataFrame(predictions, columns=[\"predicted_answer\", \"target_answer\"])\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d370f5b",
   "metadata": {},
   "source": [
    "### Evaluate all the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad874d57",
   "metadata": {
    "height": 66
   },
   "outputs": [],
   "source": [
    "evaluation_dataset_path = \"lamini/lamini_docs_evaluation\"\n",
    "evaluation_dataset = datasets.load_dataset(evaluation_dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52abb51d",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "pd.reset_option('display')\n",
    "pd.DataFrame(evaluation_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbee60ed",
   "metadata": {},
   "source": [
    "### Try the ARC benchmark\n",
    "This can take several minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b72063b4",
   "metadata": {
    "height": 49
   },
   "outputs": [],
   "source": [
    "!python lm-evaluation-harness/main.py --model hf-causal --model_args pretrained=lamini/lamini_docs_finetuned --tasks arc_easy --device cpu"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
