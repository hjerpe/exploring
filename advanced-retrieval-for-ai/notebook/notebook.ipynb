{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec889d86-0d16-477f-8b7f-be03d73ad957",
   "metadata": {},
   "source": [
    "# Overview of embeddings-based retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ee2f53-d88b-4f00-94a2-75a66d4149e9",
   "metadata": {},
   "source": [
    "Welcome! Here's a few notes about the Chroma course notebooks.\n",
    " - A number of warnings pop up when running the notebooks. These are normal and can be ignored.\n",
    " - Some operations such as calling an LLM or an opeation using generated data return unpredictable results and so your notebook outputs may differ from the video.\n",
    "  \n",
    "Enjoy the course!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a5536f0-651c-40e7-aa15-27ee0cda80b7",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "from helper_utils import word_wrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3748b16d-d4a7-49c3-a48a-57dcfc42acd6",
   "metadata": {
    "height": 166
   },
   "outputs": [],
   "source": [
    "from pypdf import PdfReader\n",
    "\n",
    "reader = PdfReader(\"microsoft_annual_report_2022.pdf\")\n",
    "pdf_texts = [p.extract_text().strip() for p in reader.pages]\n",
    "\n",
    "# Filter the empty strings\n",
    "pdf_texts = [text for text in pdf_texts if text]\n",
    "\n",
    "print(word_wrap(pdf_texts[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd608a5-b6c9-4ae9-a871-a3e470a4d12a",
   "metadata": {},
   "source": [
    "You can view the pdf in your browser [here](./microsoft_annual_report_2022.pdf) if you would like. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a338ec83-6301-41a5-9ab1-e5d583306a3f",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter, SentenceTransformersTokenTextSplitter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "888a86f8-2fe2-4682-bdaf-c15129ed1a32",
   "metadata": {
    "height": 166
   },
   "outputs": [],
   "source": [
    "character_splitter = RecursiveCharacterTextSplitter(\n",
    "    separators=[\"\\n\\n\", \"\\n\", \". \", \" \", \"\"],\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=0\n",
    ")\n",
    "character_split_texts = character_splitter.split_text('\\n\\n'.join(pdf_texts))\n",
    "\n",
    "print(word_wrap(character_split_texts[10]))\n",
    "print(f\"\\nTotal chunks: {len(character_split_texts)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5665c695-22ea-4264-b1ac-5ba720b6d78b",
   "metadata": {
    "height": 149
   },
   "outputs": [],
   "source": [
    "token_splitter = SentenceTransformersTokenTextSplitter(chunk_overlap=0, tokens_per_chunk=256)\n",
    "\n",
    "token_split_texts = []\n",
    "for text in character_split_texts:\n",
    "    token_split_texts += token_splitter.split_text(text)\n",
    "\n",
    "print(word_wrap(token_split_texts[10]))\n",
    "print(f\"\\nTotal chunks: {len(token_split_texts)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a13d14-4484-46f0-8e67-277337f9d138",
   "metadata": {
    "height": 98
   },
   "outputs": [],
   "source": [
    "import chromadb\n",
    "from chromadb.utils.embedding_functions import SentenceTransformerEmbeddingFunction\n",
    "\n",
    "embedding_function = SentenceTransformerEmbeddingFunction()\n",
    "print(embedding_function([token_split_texts[10]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba6c8c5-9ce4-44d0-9223-6fdd77871f87",
   "metadata": {
    "height": 132
   },
   "outputs": [],
   "source": [
    "chroma_client = chromadb.Client()\n",
    "chroma_collection = chroma_client.create_collection(\"microsoft_annual_report_2022\", embedding_function=embedding_function)\n",
    "\n",
    "ids = [str(i) for i in range(len(token_split_texts))]\n",
    "\n",
    "chroma_collection.add(ids=ids, documents=token_split_texts)\n",
    "chroma_collection.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfdb54db-a442-423c-b006-c33a257cd7d7",
   "metadata": {
    "height": 149
   },
   "outputs": [],
   "source": [
    "query = \"What was the total revenue?\"\n",
    "\n",
    "results = chroma_collection.query(query_texts=[query], n_results=5)\n",
    "retrieved_documents = results['documents'][0]\n",
    "\n",
    "for document in retrieved_documents:\n",
    "    print(word_wrap(document))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "377a84aa-1d93-4e97-9b2d-d59c46355338",
   "metadata": {
    "height": 166
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "from openai import OpenAI\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "openai.api_key = os.environ['OPENAI_API_KEY']\n",
    "\n",
    "openai_client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba0ed8ca-6640-4c09-9cb3-9de5e7cf46dc",
   "metadata": {
    "height": 336
   },
   "outputs": [],
   "source": [
    "def rag(query, retrieved_documents, model=\"gpt-3.5-turbo\"):\n",
    "    information = \"\\n\\n\".join(retrieved_documents)\n",
    "\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are a helpful expert financial research assistant. Your users are asking questions about information contained in an annual report.\"\n",
    "            \"You will be shown the user's question, and the relevant information from the annual report. Answer the user's question using only this information.\"\n",
    "        },\n",
    "        {\"role\": \"user\", \"content\": f\"Question: {query}. \\n Information: {information}\"}\n",
    "    ]\n",
    "    \n",
    "    response = openai_client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "    )\n",
    "    content = response.choices[0].message.content\n",
    "    return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28bac3a2-0d29-48dc-9b48-2d9313239a25",
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "output = rag(query=query, retrieved_documents=retrieved_documents)\n",
    "\n",
    "print(word_wrap(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db9f2758-0f5a-49e5-b1fa-517b91324575",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "43376c5c",
   "metadata": {},
   "source": [
    "## Pitfalls of retrieval - when simple vector search fails!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98796613",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "from openai import OpenAI\n",
    "from helper_utils import load_chroma, word_wrap\n",
    "from chromadb.utils.embedding_functions import SentenceTransformerEmbeddingFunction\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "import umap\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "openai.api_key = os.environ['OPENAI_API_KEY']\n",
    "\n",
    "openai_client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0cacb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_function = SentenceTransformerEmbeddingFunction()\n",
    "\n",
    "chroma_collection = load_chroma(filename='data/microsoft_annual_report_2022.pdf', collection_name='microsoft_annual_report_2022', embedding_function=embedding_function)\n",
    "chroma_collection.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0456db7",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "embeddings = chroma_collection.get(include=['embeddings'])['embeddings']\n",
    "umap_transform = umap.UMAP(random_state=0, transform_seed=0).fit(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f82d2fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def project_embeddings(embeddings, umap_transform):\n",
    "    umap_embeddings = np.empty((len(embeddings),2))\n",
    "    for i, embedding in enumerate(tqdm(embeddings)): \n",
    "        umap_embeddings[i] = umap_transform.transform([embedding])\n",
    "    return umap_embeddings   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c714eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "projected_dataset_embeddings = project_embeddings(embeddings, umap_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "797ceec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(projected_dataset_embeddings[:, 0], projected_dataset_embeddings[:, 1], s=10)\n",
    "plt.gca().set_aspect('equal', 'datalim')\n",
    "plt.title('Projected Embeddings')\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e24bc0",
   "metadata": {},
   "source": [
    "## Relevancy and Distraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad58e39c",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What is the total revenue?\"\n",
    "\n",
    "results = chroma_collection.query(query_texts=query, n_results=5, include=['documents', 'embeddings'])\n",
    "\n",
    "retrieved_documents = results['documents'][0]\n",
    "\n",
    "for document in results['documents'][0]:\n",
    "    print(word_wrap(document))\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6db60f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_embedding = embedding_function([query])[0]\n",
    "retrieved_embeddings = results['embeddings'][0]\n",
    "\n",
    "projected_query_embedding = project_embeddings([query_embedding], umap_transform)\n",
    "projected_retrieved_embeddings = project_embeddings(retrieved_embeddings, umap_transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf5c7b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the projected query and retrieved documents in the embedding space\n",
    "plt.figure()\n",
    "plt.scatter(projected_dataset_embeddings[:, 0], projected_dataset_embeddings[:, 1], s=10, color='gray')\n",
    "plt.scatter(projected_query_embedding[:, 0], projected_query_embedding[:, 1], s=150, marker='X', color='r')\n",
    "plt.scatter(projected_retrieved_embeddings[:, 0], projected_retrieved_embeddings[:, 1], s=100, facecolors='none', edgecolors='g')\n",
    "\n",
    "plt.gca().set_aspect('equal', 'datalim')\n",
    "plt.title(f'{query}')\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c6c7aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What is the strategy around artificial intelligence (AI) ?\"\n",
    "results = chroma_collection.query(query_texts=query, n_results=5, include=['documents', 'embeddings'])\n",
    "\n",
    "retrieved_documents = results['documents'][0]\n",
    "\n",
    "for document in results['documents'][0]:\n",
    "    print(word_wrap(document))\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa99ea20",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What has been the investment in research and development?\"\n",
    "results = chroma_collection.query(query_texts=query, n_results=5, include=['documents', 'embeddings'])\n",
    "\n",
    "retrieved_documents = results['documents'][0]\n",
    "\n",
    "for document in results['documents'][0]:\n",
    "    print(word_wrap(document))\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5bf8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What has Michael Jordan done for us lately?\"\n",
    "results = chroma_collection.query(query_texts=query, n_results=5, include=['documents', 'embeddings'])\n",
    "\n",
    "retrieved_documents = results['documents'][0]\n",
    "\n",
    "for document in results['documents'][0]:\n",
    "    print(word_wrap(document))\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f792108",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What is Microsofts the total revenue?\"\n",
    "\n",
    "results = chroma_collection.query(query_texts=query, n_results=5, include=['documents', 'embeddings'])\n",
    "\n",
    "retrieved_documents = results['documents'][0]\n",
    "\n",
    "for document in results['documents'][0]:\n",
    "    print(word_wrap(document))\n",
    "    print('')\n",
    "\n",
    "query_embedding = embedding_function([query])[0]\n",
    "retrieved_embeddings = results['embeddings'][0]\n",
    "\n",
    "projected_query_embedding = project_embeddings([query_embedding], umap_transform)\n",
    "projected_retrieved_embeddings = project_embeddings(retrieved_embeddings, umap_transform)\n",
    "\n",
    "# Plot the projected query and retrieved documents in the embedding space\n",
    "plt.figure()\n",
    "plt.scatter(projected_dataset_embeddings[:, 0], projected_dataset_embeddings[:, 1], s=10, color='gray')\n",
    "plt.scatter(projected_query_embedding[:, 0], projected_query_embedding[:, 1], s=150, marker='X', color='r')\n",
    "plt.scatter(projected_retrieved_embeddings[:, 0], projected_retrieved_embeddings[:, 1], s=100, facecolors='none', edgecolors='g')\n",
    "\n",
    "plt.gca().set_aspect('equal', 'datalim')\n",
    "plt.title(f'{query}')\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e258efbb",
   "metadata": {},
   "source": [
    "# Query Expansion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db48f359",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "from openai import OpenAI\n",
    "from helper_utils import load_chroma, word_wrap, project_embeddings\n",
    "from chromadb.utils.embedding_functions import SentenceTransformerEmbeddingFunction\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "import umap\n",
    "\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "openai.api_key = os.environ['OPENAI_API_KEY']\n",
    "\n",
    "openai_client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "695626f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = chroma_collection.get(include=['embeddings'])['embeddings']\n",
    "umap_transform = umap.UMAP(random_state=0, transform_seed=0).fit(embeddings)\n",
    "projected_dataset_embeddings = project_embeddings(embeddings, umap_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4feceb8",
   "metadata": {},
   "source": [
    "## Expansion with generated answers\n",
    "\n",
    "https://arxiv.org/abs/2305.03653"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f3e975",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_query_generated(query, model=\"gpt-3.5-turbo\"):\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are a helpful expert financial research assistant. Provide an example answer to the given question, that might be found in a document like an annual report. \"\n",
    "        },\n",
    "        {\"role\": \"user\", \"content\": query}\n",
    "    ] \n",
    "\n",
    "    response = openai_client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "    )\n",
    "    content = response.choices[0].message.content\n",
    "    return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f8a16ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_query = \"Was there significant turnover in the executive team?\"\n",
    "hypothetical_answer = augment_query_generated(original_query)\n",
    "\n",
    "joint_query = f\"{original_query} {hypothetical_answer}\"\n",
    "print(word_wrap(joint_query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79d5b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = chroma_collection.query(query_texts=joint_query, n_results=5, include=['documents', 'embeddings'])\n",
    "retrieved_documents = results['documents'][0]\n",
    "\n",
    "for doc in retrieved_documents:\n",
    "    print(word_wrap(doc))\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6501436",
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieved_embeddings = results['embeddings'][0]\n",
    "original_query_embedding = embedding_function([original_query])\n",
    "augmented_query_embedding = embedding_function([joint_query])\n",
    "\n",
    "projected_original_query_embedding = project_embeddings(original_query_embedding, umap_transform)\n",
    "projected_augmented_query_embedding = project_embeddings(augmented_query_embedding, umap_transform)\n",
    "projected_retrieved_embeddings = project_embeddings(retrieved_embeddings, umap_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14cb6026",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot the projected query and retrieved documents in the embedding space\n",
    "plt.figure()\n",
    "plt.scatter(projected_dataset_embeddings[:, 0], projected_dataset_embeddings[:, 1], s=10, color='gray')\n",
    "plt.scatter(projected_retrieved_embeddings[:, 0], projected_retrieved_embeddings[:, 1], s=100, facecolors='none', edgecolors='g')\n",
    "plt.scatter(projected_original_query_embedding[:, 0], projected_original_query_embedding[:, 1], s=150, marker='X', color='r')\n",
    "plt.scatter(projected_augmented_query_embedding[:, 0], projected_augmented_query_embedding[:, 1], s=150, marker='X', color='orange')\n",
    "\n",
    "plt.gca().set_aspect('equal', 'datalim')\n",
    "plt.title(f'{original_query}')\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e4b1446",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_multiple_query(query, model=\"gpt-3.5-turbo\"):\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are a helpful expert financial research assistant. Your users are asking questions about an annual report. \"\n",
    "            \"Suggest up to five additional related questions to help them find the information they need, for the provided question. \"\n",
    "            \"Suggest only short questions without compound sentences. Suggest a variety of questions that cover different aspects of the topic.\"\n",
    "            \"Make sure they are complete questions, and that they are related to the original question.\"\n",
    "            \"Output one question per line. Do not number the questions.\"\n",
    "        },\n",
    "        {\"role\": \"user\", \"content\": query}\n",
    "    ]\n",
    "\n",
    "    response = openai_client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "    )\n",
    "    content = response.choices[0].message.content\n",
    "    content = content.split(\"\\n\")\n",
    "    return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ca7658",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_query = \"What were the most important factors that contributed to increases in revenue?\"\n",
    "augmented_queries = augment_multiple_query(original_query)\n",
    "\n",
    "for query in augmented_queries:\n",
    "    print(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20486b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = [original_query] + augmented_queries\n",
    "results = chroma_collection.query(query_texts=queries, n_results=5, include=['documents', 'embeddings'])\n",
    "\n",
    "retrieved_documents = results['documents']\n",
    "\n",
    "# Deduplicate the retrieved documents\n",
    "unique_documents = set()\n",
    "for documents in retrieved_documents:\n",
    "    for document in documents:\n",
    "        unique_documents.add(document)\n",
    "\n",
    "for i, documents in enumerate(retrieved_documents):\n",
    "    print(f\"Query: {queries[i]}\")\n",
    "    print('')\n",
    "    print(\"Results:\")\n",
    "    for doc in documents:\n",
    "        print(word_wrap(doc))\n",
    "        print('')\n",
    "    print('-'*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0fedf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_query_embedding = embedding_function([original_query])\n",
    "augmented_query_embeddings = embedding_function(augmented_queries)\n",
    "\n",
    "project_original_query = project_embeddings(original_query_embedding, umap_transform)\n",
    "project_augmented_queries = project_embeddings(augmented_query_embeddings, umap_transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed8e173",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_embeddings = results['embeddings']\n",
    "result_embeddings = [item for sublist in result_embeddings for item in sublist]\n",
    "projected_result_embeddings = project_embeddings(result_embeddings, umap_transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4060ca53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(projected_dataset_embeddings[:, 0], projected_dataset_embeddings[:, 1], s=10, color='gray')\n",
    "plt.scatter(project_augmented_queries[:, 0], project_augmented_queries[:, 1], s=150, marker='X', color='orange')\n",
    "plt.scatter(projected_result_embeddings[:, 0], projected_result_embeddings[:, 1], s=100, facecolors='none', edgecolors='g')\n",
    "plt.scatter(project_original_query[:, 0], project_original_query[:, 1], s=150, marker='X', color='r')\n",
    "\n",
    "plt.gca().set_aspect('equal', 'datalim')\n",
    "plt.title(f'{original_query}')\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f057401b-a4ee-462a-9ba9-3e342e06eb1a",
   "metadata": {},
   "source": [
    "## Cross-encoder re-ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf46fb15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "from openai import OpenAI\n",
    "from helper_utils import load_chroma, word_wrap\n",
    "from chromadb.utils.embedding_functions import SentenceTransformerEmbeddingFunction\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "import numpy as np\n",
    "\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "openai.api_key = os.environ['OPENAI_API_KEY']\n",
    "\n",
    "openai_client = OpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68486bf8-37dd-4257-a23b-9ef50c47bcc5",
   "metadata": {},
   "source": [
    "# Re-ranking the long tail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa548834",
   "metadata": {
    "height": 166
   },
   "outputs": [],
   "source": [
    "query = \"What has been the investment in research and development?\"\n",
    "results = chroma_collection.query(query_texts=query, n_results=10, include=['documents', 'embeddings'])\n",
    "\n",
    "retrieved_documents = results['documents'][0]\n",
    "\n",
    "for document in results['documents'][0]:\n",
    "    print(word_wrap(document))\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "240fe47e",
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "from sentence_transformers import CrossEncoder\n",
    "cross_encoder = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c065d0fc",
   "metadata": {
    "height": 115
   },
   "outputs": [],
   "source": [
    "pairs = [[query, doc] for doc in retrieved_documents]\n",
    "scores = cross_encoder.predict(pairs)\n",
    "print(\"Scores:\")\n",
    "for score in scores:\n",
    "    print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eef1097",
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "print(\"New Ordering:\")\n",
    "for o in np.argsort(scores)[::-1]:\n",
    "    print(o+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f54cc00-eebc-4294-91bf-1a2cdce51708",
   "metadata": {},
   "source": [
    "# Re-ranking with Query Expansion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d0d6ce",
   "metadata": {
    "height": 166
   },
   "outputs": [],
   "source": [
    "original_query = \"What were the most important factors that contributed to increases in revenue?\"\n",
    "generated_queries = [\n",
    "    \"What were the major drivers of revenue growth?\",\n",
    "    \"Were there any new product launches that contributed to the increase in revenue?\",\n",
    "    \"Did any changes in pricing or promotions impact the revenue growth?\",\n",
    "    \"What were the key market trends that facilitated the increase in revenue?\",\n",
    "    \"Did any acquisitions or partnerships contribute to the revenue growth?\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899ab325",
   "metadata": {
    "height": 98
   },
   "outputs": [],
   "source": [
    "queries = [original_query] + generated_queries\n",
    "\n",
    "results = chroma_collection.query(query_texts=queries, n_results=10, include=['documents', 'embeddings'])\n",
    "retrieved_documents = results['documents']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b26b13c",
   "metadata": {
    "height": 132
   },
   "outputs": [],
   "source": [
    "# Deduplicate the retrieved documents\n",
    "unique_documents = set()\n",
    "for documents in retrieved_documents:\n",
    "    for document in documents:\n",
    "        unique_documents.add(document)\n",
    "\n",
    "unique_documents = list(unique_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deff522f",
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "pairs = []\n",
    "for doc in unique_documents:\n",
    "    pairs.append([original_query, doc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee59493-8a99-4da8-b94f-4747efcfc79d",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "scores = cross_encoder.predict(pairs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5eda9bc-ae76-4db6-9e0c-ae099d852d78",
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "print(\"Scores:\")\n",
    "for score in scores:\n",
    "    print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1183e75-4c65-422e-bc47-48010d8b29c9",
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "print(\"New Ordering:\")\n",
    "for o in np.argsort(scores)[::-1]:\n",
    "    print(o)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93075c79-81cf-42ec-9931-12443efaaf4b",
   "metadata": {},
   "source": [
    "# Embedding Adaptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a67f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "from openai import OpenAI\n",
    "from helper_utils import project_embeddings\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "openai.api_key = os.environ['OPENAI_API_KEY']\n",
    "\n",
    "openai_client = OpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a34ff415-8d20-4171-9d40-7eb1bbe837a1",
   "metadata": {},
   "source": [
    "## Creating a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c05c9654",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_queries(model=\"gpt-3.5-turbo\"):\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are a helpful expert financial research assistant. You help users analyze financial statements to better understand companies. \"\n",
    "            \"Suggest 10 to 15 short questions that are important to ask when analyzing an annual report. \"\n",
    "            \"Do not output any compound questions (questions with multiple sentences or conjunctions).\"\n",
    "            \"Output each question on a separate line divided by a newline.\"\n",
    "        },\n",
    "    ]\n",
    "\n",
    "    response = openai_client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "    )\n",
    "    content = response.choices[0].message.content\n",
    "    content = content.split(\"\\n\")\n",
    "    return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26974595",
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_queries = generate_queries()\n",
    "for query in generated_queries:\n",
    "    print(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982019da",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = chroma_collection.query(query_texts=generated_queries, n_results=10, include=['documents', 'embeddings'])\n",
    "retrieved_documents = results['documents']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b2454f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_results(query, statement, model=\"gpt-3.5-turbo\"):\n",
    "    messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"You are a helpful expert financial research assistant. You help users analyze financial statements to better understand companies. \"\n",
    "        \"For the given query, evaluate whether the following satement is relevant.\"\n",
    "        \"Output only 'yes' or 'no'.\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": f\"Query: {query}, Statement: {statement}\"\n",
    "    }\n",
    "    ]\n",
    "\n",
    "    response = openai_client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        max_tokens=1\n",
    "    )\n",
    "    content = response.choices[0].message.content\n",
    "    if content == \"yes\":\n",
    "        return 1\n",
    "    return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd6fc549",
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieved_embeddings = results['embeddings']\n",
    "query_embeddings = embedding_function(generated_queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2afc448e",
   "metadata": {},
   "outputs": [],
   "source": [
    "adapter_query_embeddings = []\n",
    "adapter_doc_embeddings = []\n",
    "adapter_labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a67edafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "for q, query in enumerate(tqdm(generated_queries)):\n",
    "    for d, document in enumerate(retrieved_documents[q]):\n",
    "        adapter_query_embeddings.append(query_embeddings[q])\n",
    "        adapter_doc_embeddings.append(retrieved_embeddings[q][d])\n",
    "        adapter_labels.append(evaluate_results(query, document))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c65337e9-85ee-47f7-89fd-7fe77cd0e1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(adapter_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "babe7893-9cbc-43c5-94ef-cbf8f5d68cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "adapter_query_embeddings = torch.Tensor(np.array(adapter_query_embeddings))\n",
    "adapter_doc_embeddings = torch.Tensor(np.array(adapter_doc_embeddings))\n",
    "adapter_labels = torch.Tensor(np.expand_dims(np.array(adapter_labels),1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a9524b-1085-4bdf-a161-39f11397dc1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = torch.utils.data.TensorDataset(adapter_query_embeddings, adapter_doc_embeddings, adapter_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdac56f2-b98c-46ab-9cc4-248b79177ef8",
   "metadata": {},
   "source": [
    "## Setting up the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b26a01a-4575-446b-b8dc-a8c5ab153172",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(query_embedding, document_embedding, adaptor_matrix):\n",
    "    updated_query_embedding = torch.matmul(adaptor_matrix, query_embedding)\n",
    "    return torch.cosine_similarity(updated_query_embedding, document_embedding, dim=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0950575b-b69d-46a3-8c91-c7af89f5c204",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse_loss(query_embedding, document_embedding, adaptor_matrix, label):\n",
    "    return torch.nn.MSELoss()(model(query_embedding, document_embedding, adaptor_matrix), label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f123ad8-b2e8-4a25-8b42-a520ecaf566b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the adaptor matrix\n",
    "mat_size = len(adapter_query_embeddings[0])\n",
    "adapter_matrix = torch.randn(mat_size, mat_size, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c04587-d1de-419c-a213-2e3eb67dc33d",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_loss = float('inf')\n",
    "best_matrix = None\n",
    "\n",
    "for epoch in tqdm(range(100)):\n",
    "    for query_embedding, document_embedding, label in dataset:\n",
    "        loss = mse_loss(query_embedding, document_embedding, adapter_matrix, label)\n",
    "\n",
    "        if loss < min_loss:\n",
    "            min_loss = loss\n",
    "            best_matrix = adapter_matrix.clone().detach().numpy()\n",
    "\n",
    "        loss.backward()\n",
    "        with torch.no_grad():\n",
    "            adapter_matrix -= 0.01 * adapter_matrix.grad\n",
    "            adapter_matrix.grad.zero_()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3155972-824e-4ebe-a692-2227c113c5a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Best loss: {min_loss.detach().numpy()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8144a4a-85f6-4800-87f9-36a1b6ceda1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_vector = torch.ones((mat_size,1))\n",
    "scaled_vector = np.matmul(best_matrix, test_vector).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff0b18e-12a0-4ac0-97dd-8618b22e7dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.bar(range(len(scaled_vector)), scaled_vector.flatten())\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ca7e7c-4b47-4652-9b46-a40b3dffa5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_embeddings = embedding_function(generated_queries)\n",
    "adapted_query_embeddings = np.matmul(best_matrix, np.array(query_embeddings).T).T\n",
    "\n",
    "projected_query_embeddings = project_embeddings(query_embeddings, umap_transform)\n",
    "projected_adapted_query_embeddings = project_embeddings(adapted_query_embeddings, umap_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f74e7d67-7f51-41c4-8e25-edbaa02d0bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the projected query and retrieved documents in the embedding space\n",
    "plt.figure()\n",
    "plt.scatter(projected_dataset_embeddings[:, 0], projected_dataset_embeddings[:, 1], s=10, color='gray')\n",
    "plt.scatter(projected_query_embeddings[:, 0], projected_query_embeddings[:, 1], s=150, marker='X', color='r', label=\"original\")\n",
    "plt.scatter(projected_adapted_query_embeddings[:, 0], projected_adapted_query_embeddings[:, 1], s=150, marker='X', color='green', label=\"adapted\")\n",
    "\n",
    "plt.gca().set_aspect('equal', 'datalim')\n",
    "plt.title(\"Adapted Queries\")\n",
    "plt.axis('off')\n",
    "plt.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
