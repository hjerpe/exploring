# Exploring AI Models & Tooling Repository

## Overview

This repository is dedicated to exploring and understanding various artificial intelligence models. It contains a collection of projects and coursework materials focused on finetuning, evaluating, and applying different AI models, primarily in the field of natural language processing.

## Contents

- `ai_plugins_semantic_kernel`: Plugins for enhancing semantic analysis in AI models.
- `building-genai-applications-with-gradio`: Instructional content on creating interactive AI applications using Gradio.
- `efficient_finetuning`: Techniques for efficient finetuning of AI models.
- `evaluating-and-debugging-genai`: Methods for evaluating and debugging generative AI models.
- `finetuning_large_language_models`: Strategies for finetuning large-scale language models.
- `hugging_nlp_course`: Coursework related to NLP models from Hugging Face.
- `llms_with_semantic_search`: Implementing semantic search capabilities in language models.
- `tools-and-agents-with-langchain`: Resources and examples for working with tools and agents using the LangChain library.
- `vector_dbs_from_embeddings_to_applications`: Showcasing vector embeddings and their application in embedding MNIST images and NLP sentences, and their practical applications in AI models.
- `vertex-ai-applying-embeddings`: Applying embeddings in AI models with Vertex AI.
- `building-and-evaluating-advanced-rag`: A comprehensive exploration of Retrieval-Augmented Generation (RAG), detailing architecture, metrics, optimization, and integration techniques for RAG systems.
- `reinforcement-learning-from-human-feedback`: Detailed guide on implementing a reinforcement learning strategy using Vertex AI, from data acquisition, running pipeline jobs, to evaluating results.
- `advanced-retrieval-for-ai`: A deep dive into advanced techniques for embeddings-based retrieval, including query expansion and re-ranking strategies, tailored to enhance the precision and relevancy of search results in AI systems.
- `Prompt Engineering with LLaMA 2`: Dive into the nuances of prompt engineering with LLaMA 2, learning best practices for model selection and application in daily tasks. Explore few-shot and chain-of-thought prompting for advanced problem solving, paired programming with Code LLaMA, and ensuring safe model use with LLaMA Guard.
- `open_source_models_with_hugging_face`: Learn how to easily build AI applications using open source models and Hugging Face tools. Find and filter open source models on Hugging Face Hub based on task, rankings, and memory requirements. Write just a few lines of code using the transformers library to perform text, audio, image, and multimodal tasks. Easily share your AI apps with a user-friendly interface or via API and run them on the cloud using Gradio and Hugging Face Spaces.
- `quantization_fundamentals_hf`: Generative AI models, like large language models, often exceed the capabilities of consumer-grade hardware and are expensive to run. Compressing models through methods such as quantization makes them more efficient, faster, and accessible. This allows them to run on a wide variety of devices, including smartphones, personal computers, and edge devices, and minimizes performance degradation. Explore techniques how to quantize models with the Quanto library, implement linear quantization, apply downcasting with the Transformers library, and make your AI models more efficient and accessible.
- `quantization_in_depth`: Exploration of techniques for handling and processing AI model weights, particularly focusing on quantization and efficient linear layers. Includes the implementation of a custom linear layer class (W8A16LinearLayer), dynamic weight quantization, and unpacking quantized weights.
- `ai_agentic_design_patterns_autogen`: Learn to build and customize multi-agent systems with AutoGen, enabling agents to collaborate on complex tasks. Explore scenarios like two-agent stand-up comedy chats, customer onboarding processes, blog post generation with agent reflection, conversational chess games, and financial analysis coding. The framework supports any model via API or local use, providing hands-on experience with agentic design patterns for effective multi-agent system implementation.
