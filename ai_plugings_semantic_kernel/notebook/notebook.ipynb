{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ§‘â€ðŸ³ Semantic Kernel is like\u000b",
    "\n",
    "\n",
    "your AI cooking kitchen"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ”¥ Get a kernel ready"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import semantic_kernel as sk\n",
    "from semantic_kernel.connectors.ai.open_ai import AzureChatCompletion, OpenAIChatCompletion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 287
   },
   "outputs": [],
   "source": [
    "import semantic_kernel as sk\n",
    "from semantic_kernel.connectors.ai.open_ai import AzureChatCompletion, OpenAIChatCompletion\n",
    "\n",
    "kernel = sk.Kernel()\n",
    "\n",
    "useAzureOpenAI = False\n",
    "\n",
    "if useAzureOpenAI:\n",
    "    deployment, api_key, endpoint = sk.azure_openai_settings_from_dot_env()\n",
    "    kernel.add_text_completion_service(\"azureopenai\", AzureChatCompletion(deployment, endpoint, api_key))\n",
    "else:\n",
    "    # reads from .env file, which should be in the same directory as this file, we instead created\n",
    "    # an symbolic link to the .env file in the root directory of the project\n",
    "    api_key, org_id = sk.openai_settings_from_dot_env()\n",
    "    kernel.add_text_completion_service(\"openai\", OpenAIChatCompletion(\"gpt-3.5-turbo-0301\", api_key, org_id))\n",
    "    # kernel.add_text_completion_service(\"openai\", OpenAIChatCompletion(\"gpt-3.5-turbo-0301\", api_key))\n",
    "\n",
    "print(\"You made a kernel!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 168
   },
   "outputs": [],
   "source": [
    "import semantic_kernel as sk\n",
    "from semantic_kernel.connectors.ai.hugging_face import HuggingFaceTextCompletion\n",
    "\n",
    "kernel = sk.Kernel()\n",
    "\n",
    "kernel.add_text_completion_service(\"huggingface\", HuggingFaceTextCompletion(\"gpt2\", task=\"text-generation\"))\n",
    "\n",
    "print(\"You made an open source kernel using an open source AI model!\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ”– Reminder: A kernel is like the stove in a kitchen. It doesn't do anything unless you start to cook with it. Let's proceed to get it a few functions to ðŸ”¥ cook up for us."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ§‘â€ðŸ³ Cooking up flavorful SWOTs with the kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import semantic_kernel as sk\n",
    "\n",
    "from semantic_kernel.connectors.ai.open_ai import AzureChatCompletion, OpenAIChatCompletion\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "kernel = sk.Kernel()\n",
    "\n",
    "useAzureOpenAI = False\n",
    "\n",
    "if useAzureOpenAI:\n",
    "    deployment, api_key, endpoint = sk.azure_openai_settings_from_dot_env()\n",
    "    kernel.add_text_completion_service(\"azureopenai\", AzureChatCompletion(deployment, endpoint, api_key))\n",
    "else:\n",
    "    api_key, org_id = sk.openai_settings_from_dot_env()\n",
    "    kernel.add_text_completion_service(\"openai\", OpenAIChatCompletion(\"gpt-3.5-turbo-0301\", api_key))\n",
    "\n",
    "print(\"A kernel is now ready.\")   "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's make a semantic function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sk_prompt = \"\"\"\n",
    "{{$input}}\n",
    "\n",
    "Summarize the content above in less than 140 characters.\n",
    "\"\"\"\n",
    "summary_function = kernel.create_semantic_function(prompt_template = sk_prompt,\n",
    "                                                    description=\"Summarizes the input to length of an old tweet.\",\n",
    "                                                    max_tokens=200,\n",
    "                                                    temperature=0.1,\n",
    "                                                    top_p=0.5)       \n",
    "print(\"A semantic function for summarization has been registered.\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sk_input = \"\"\"\n",
    "Let me illustrate an example. Many weekends, I drive a few minutes from my house to a local pizza store to buy \n",
    "a slice of Hawaiian pizza from the gentleman that owns this pizza store. And his pizza is great, but he always \n",
    "has a lot of cold pizzas sitting around, and every weekend some different flavor of pizza is out of stock. \n",
    "But when I watch him operate his store, I get excited, because by selling pizza, he is generating data. \n",
    "And this is data that he can take advantage of if he had access to AI.\n",
    "\n",
    "AI systems are good at spotting patterns when given access to the right data, and perhaps an AI system could spot \n",
    "if Mediterranean pizzas sell really well on a Friday night, maybe it could suggest to him to make more of it on a \n",
    "Friday afternoon. Now you might say to me, \"Hey, Andrew, this is a small pizza store. What's the big deal?\" And I \n",
    "say, to the gentleman that owns this pizza store, something that could help him improve his revenues by a few \n",
    "thousand dollars a year, that will be a huge deal to him.\n",
    "\"\"\";\n",
    "# Text source: https://www.ted.com/talks/andrew_ng_how_ai_could_empower_any_business/transcript\n",
    "\n",
    "summary_result = await kernel.run_async(summary_function, input_str=sk_input)\n",
    "\n",
    "display(Markdown(\"### âœ¨ \" + str(summary_result)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_result = summary_function(sk_input)\n",
    "\n",
    "display(Markdown(\"### âœ¨ \" + str(summary_result)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Native functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantic_kernel.skill_definition import (\n",
    "    sk_function,\n",
    "    sk_function_context_parameter,\n",
    ")\n",
    "\n",
    "class ExoticLanguagePlugin:\n",
    "    def word_to_pig_latin(self, word):\n",
    "        vowels = \"AEIOUaeiou\"\n",
    "        if word[0] in vowels:\n",
    "            return word + \"way\"\n",
    "        for idx, letter in enumerate(word):\n",
    "            if letter in vowels:\n",
    "                break\n",
    "        else:\n",
    "            return word + \"ay\"\n",
    "        return word[idx:] + word[:idx] + \"ay\"\n",
    "    @sk_function(\n",
    "        description=\"Takes text and converts it to pig latin\",\n",
    "        name=\"pig_latin\",\n",
    "        input_description=\"The text to convert to pig latin\",\n",
    "    )\n",
    "    def pig_latin(self, sentence:str) -> str:\n",
    "        words = sentence.split()\n",
    "        pig_latin_words = []\n",
    "        for word in words:\n",
    "            pig_latin_words.append(self.word_to_pig_latin(word))\n",
    "        return ' '.join(pig_latin_words)\n",
    "\n",
    "exotic_language_plugin = kernel.import_skill(ExoticLanguagePlugin(), skill_name=\"exotic_language_plugin\")\n",
    "pig_latin_function = exotic_language_plugin[\"pig_latin\"]\n",
    "\n",
    "print(\"this is kind of not going to feel awesome but know this is a big deal\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_result = await kernel.run_async(summary_function, pig_latin_function, input_str=sk_input) \n",
    "\n",
    "display(Markdown(\"### âœ¨ \" + str(final_result)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Strengths**\n",
    "    - What unique recipes or ingredients does the pizza shop use?\n",
    "    - What are the skills and experience of the staff?\n",
    "    - Does the pizza shop have a strong reputation in the local area?\n",
    "    - Are there any unique features of the shop or its location that attract customers?\n",
    "2. **Weaknesses**\n",
    "    - What are the operational challenges of the pizza shop? (e.g., slow service, high staff turnover)\n",
    "    - Are there financial constraints that limit growth or improvements?\n",
    "    - Are there any gaps in the product offering?\n",
    "    - Are there customer complaints or negative reviews that need to be addressed?\n",
    "3. **Opportunities**\n",
    "    - Is there potential for new products or services (e.g., catering, delivery)?\n",
    "    - Are there under-served customer segments or market areas?\n",
    "    - Can new technologies or systems enhance the business operations?\n",
    "    - Are there partnerships or local events that can be leveraged for marketing?\n",
    "4. **Threats**\n",
    "    - Who are the major competitors and what are they offering?\n",
    "    - Are there potential negative impacts due to changes in the local area (e.g., construction, closure of nearby businesses)?\n",
    "    - Are there economic or industry trends that could impact the business negatively (e.g., increased ingredient costs)?\n",
    "    - Is there any risk due to changes in regulations or legislation (e.g., health and safety, employment)?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| **Strengths**                                     | **Weaknesses**                                               |\n",
    "| --- | --- |\n",
    "| Unique garlic pizza recipe that wins top awards  | High staff turnover                                          |\n",
    "| Owner trained in Sicily at some of the best pizzerias                          | Floods in the area damaged the seating areas that are in need of repair  |\n",
    "| Strong local reputation                           | Absence of popular calzones from menu                        |\n",
    "| Prime location on university campus               | Negative reviews from younger demographic for lack of hip ingredients |\n",
    "\n",
    "Meanwhile there's money being left on the table (their opportunities) with calamities (their threats) waiting in the wings to possibly happen and may knock their pizza shop out cold.\n",
    "\n",
    "### ðŸ”– Opportunities and Threats\n",
    "\n",
    "| **Opportunities**                                 | **Threats**                                                  |\n",
    "| --- | ---|\n",
    "| Untapped catering potential                       | Rising competition from cheaper pizza businesses nearby |\n",
    "| Growing local tech startup community              | There's nearby street construction that will impact foot traffic |\n",
    "| Unexplored online presence and order capabilities | Rising cost of cheese                                        |\n",
    "| Upcoming annual food fair                         | No immediate local regulatory changes but it's election season |"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ¤· What does this have to do with LLMs and Semantic Kernel?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import semantic_kernel as sk\n",
    "from semantic_kernel.connectors.ai.open_ai import AzureChatCompletion, OpenAIChatCompletion\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "kernel = sk.Kernel()\n",
    "\n",
    "useAzureOpenAI = False\n",
    "\n",
    "if useAzureOpenAI:\n",
    "    deployment, api_key, endpoint = sk.azure_openai_settings_from_dot_env()\n",
    "    kernel.add_text_completion_service(\"azureopenai\", AzureChatCompletion(deployment, endpoint, api_key))\n",
    "else:\n",
    "    api_key, org_id = sk.openai_settings_from_dot_env()\n",
    "    kernel.add_text_completion_service(\"openai\", OpenAIChatCompletion(\"gpt-3.5-turbo-0301\", api_key))\n",
    "print(\"Made a kernel!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "swot_interview= \"\"\"\n",
    "1. **Strengths**\n",
    "    - What unique recipes or ingredients does the pizza shop use?\n",
    "    - What are the skills and experience of the staff?\n",
    "    - Does the pizza shop have a strong reputation in the local area?\n",
    "    - Are there any unique features of the shop or its location that attract customers?\n",
    "2. **Weaknesses**\n",
    "    - What are the operational challenges of the pizza shop? (e.g., slow service, high staff turnover)\n",
    "    - Are there financial constraints that limit growth or improvements?\n",
    "    - Are there any gaps in the product offering?\n",
    "    - Are there customer complaints or negative reviews that need to be addressed?\n",
    "3. **Opportunities**\n",
    "    - Is there potential for new products or services (e.g., catering, delivery)?\n",
    "    - Are there under-served customer segments or market areas?\n",
    "    - Can new technologies or systems enhance the business operations?\n",
    "    - Are there partnerships or local events that can be leveraged for marketing?\n",
    "4. **Threats**\n",
    "    - Who are the major competitors and what are they offering?\n",
    "    - Are there potential negative impacts due to changes in the local area (e.g., construction, closure of nearby businesses)?\n",
    "    - Are there economic or industry trends that could impact the business negatively (e.g., increased ingredient costs)?\n",
    "    - Is there any risk due to changes in regulations or legislation (e.g., health and safety, employment)?\"\"\"\n",
    "\n",
    "\n",
    "sk_prompt = \"\"\"\n",
    "{{$input}}\n",
    "\n",
    "Convert the analysis provided above to the business domain of {{$domain}}.\n",
    "\"\"\"\n",
    "shift_domain_function = kernel.create_semantic_function(prompt_template=sk_prompt,\n",
    "                                                    description=\"Translate an idea to another domain.\",\n",
    "                                                    max_tokens=1000,\n",
    "                                                    temperature=0.1,\n",
    "                                                    top_p=0.5)\n",
    "my_context = kernel.create_new_context()\n",
    "\n",
    "my_context['input'] = swot_interview\n",
    "my_context['domain'] = \"cleaning services\"\n",
    "# my_context['domain'] = \"construction management\"\n",
    "\n",
    "result = await kernel.run_async(shift_domain_function, input_context=my_context)\n",
    "\n",
    "display(Markdown(f\"### âœ¨ Shift the SWOT interview questions to the world of {my_context['domain']}\\n\"+ str(result)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sk_prompt = \"\"\"\n",
    "{{$input}}\n",
    "\n",
    "Rewrite the text above to be understood by a {{$level}}.\n",
    "\"\"\"\n",
    "shift_reading_level_function = kernel.create_semantic_function(prompt_template=sk_prompt,\n",
    "                                                    description=\"Change the reading level of a given text.\",\n",
    "                                                    max_tokens=1000,\n",
    "                                                    temperature=0.1,\n",
    "                                                    top_p=0.5)\n",
    "\n",
    "my_context['input'] = swot_interview\n",
    "my_context['domain'] = \"construction management\"\n",
    "my_context[\"level\"] = \"child\"\n",
    "\n",
    "result = await kernel.run_async(shift_domain_function, shift_reading_level_function, input_context=my_context)\n",
    "\n",
    "display(Markdown(f\"### âœ¨ Shift the SWOT interview questions to the world of {my_context['domain']} at the level of {my_context['level']}\\n\"+ str(result)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ§‘â€ðŸ³ Organizing the tools you make for later reuse"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ”– Reminder: All âœ¨ generative responses result from having the model fill in the _____.\n",
    "\n",
    "![](./assets/completion.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Grow the existing business\n",
    "2. Save money and time\n",
    "3. Add completely new business\n",
    "4. Prepare for the unknown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import semantic_kernel as sk\n",
    "from semantic_kernel.connectors.ai.open_ai import AzureChatCompletion, OpenAIChatCompletion\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "kernel = sk.Kernel()\n",
    "\n",
    "useAzureOpenAI = False\n",
    "\n",
    "if useAzureOpenAI:\n",
    "    deployment, api_key, endpoint = sk.azure_openai_settings_from_dot_env()\n",
    "    kernel.add_text_completion_service(\"azureopenai\", AzureChatCompletion(deployment, endpoint, api_key))\n",
    "else:\n",
    "    api_key, org_id = sk.openai_settings_from_dot_env()\n",
    "    kernel.add_text_completion_service(\"openai\", OpenAIChatCompletion(\"gpt-3.5-turbo-0301\", api_key, org_id=None))\n",
    "print(\"A kernel is now ready.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```directory\n",
    "plugins-sk/\n",
    "â”‚\n",
    "â””â”€â”€â”€ BusinessThinking/\n",
    "     |\n",
    "     â””â”€â”€â”€ BasicStrategies/\n",
    "     |    â””â”€â”€â”€ config.json\n",
    "     |    â””â”€â”€â”€ skprompt.txt\n",
    "     |\n",
    "     â””â”€â”€â”€ SeekCostEfficiency/\n",
    "     |    â””â”€â”€â”€ config.json\n",
    "     |    â””â”€â”€â”€ skprompt.txt\n",
    "     |\n",
    "     â””â”€â”€â”€ SeekTimeEfficiency/\n",
    "          â””â”€â”€â”€ config.json\n",
    "          â””â”€â”€â”€ skprompt.txt\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**, LLM's do not always produce the same results. Your results may differ from the video."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: To see the plugins directory, select 'file' at the top of the jupyter notebook. Then select 'open'. This will open a tab with a file directory view where you can see the plugins-sk directory and examine the files used in this lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strengths = [ \"Unique garlic pizza recipe that wins top awards\",\"Owner trained in Sicily at some of the best pizzerias\",\"Strong local reputation\",\"Prime location on university campus\" ]\n",
    "\n",
    "weaknesses = [ \"High staff turnover\",\"Floods in the area damaged the seating areas that are in need of repair\",\"Absence of popular calzones from menu\",\"Negative reviews from younger demographic for lack of hip ingredients\" ]\n",
    "\n",
    "opportunities = [ \"Untapped catering potential\",\"Growing local tech startup community\",\"Unexplored online presence and order capabilities\",\"Upcoming annual food fair\" ]\n",
    "\n",
    "threats = [ \"Competition from cheaper pizza businesses nearby\",\"There's nearby street construction that will impact foot traffic\",\"Rising cost of cheese will increase the cost of pizzas\",\"No immediate local regulatory changes but it's election season\" ]\n",
    "\n",
    "pluginsDirectory = \"./plugins-sk\"\n",
    "\n",
    "pluginBT = kernel.import_semantic_skill_from_directory(pluginsDirectory, \"BusinessThinking\");\n",
    "\n",
    "my_context = kernel.create_new_context()\n",
    "my_context['input'] = 'makes pizzas'\n",
    "my_context['strengths'] = \", \".join(strengths)\n",
    "my_context['weaknesses'] = \", \".join(weaknesses)\n",
    "\n",
    "costefficiency_result = await kernel.run_async(pluginBT[\"SeekCostEfficiency\"], input_context=my_context)\n",
    "costefficiency_str = str(\"### âœ¨ Suggestions for how to gain cost efficiencies\\n\" + str(costefficiency_result))\n",
    "display(Markdown(costefficiency_str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opportunities = [ \"Untapped catering potential\",\"Growing local tech startup community\",\"Unexplored online presence and order capabilities\",\"Upcoming annual food fair\" ]\n",
    "threats = [ \"Competition from cheaper pizza businesses nearby\",\"There's nearby street construction that will impact foot traffic\",\"Rising cost of cheese will increase the cost of pizzas\",\"No immediate local regulatory changes but it's election season\" ]\n",
    "\n",
    "pluginBT = kernel.import_semantic_skill_from_directory(pluginsDirectory, \"BusinessThinking\");\n",
    "\n",
    "my_context = kernel.create_new_context()\n",
    "my_context['input'] = 'makes pizzas'\n",
    "my_context['strengths'] = \", \".join(strengths)\n",
    "my_context['weaknesses'] = \", \".join(weaknesses)\n",
    "my_context['opportunities'] = \", \".join(opportunities)\n",
    "my_context['threats'] = \", \".join(threats)\n",
    "\n",
    "bizstrat_result = await kernel.run_async(pluginBT[\"BasicStrategies\"],input_context=my_context)\n",
    "bizstrat_str = \"## âœ¨ Business strategy thinking based on SWOT analysis\\n\"+str(bizstrat_result)\n",
    "display(Markdown(bizstrat_str))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way to think of it is the famous \"bucket of time\" and \"bucket of money\" depiction of a business owner.\n",
    "\n",
    "![](./assets/shopkeeper.png)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ§‘â€ðŸ³ Frozen dinner: \u000b",
    "\n",
    "\n",
    "The design thinking meal"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inventory:\n",
    "\n",
    "1. Kernel\n",
    "2. Semantic (and Native) functions -- you can do a lot with these\n",
    "3. BusinessThinking plugin --> SWOTs in ways you could never imagine\n",
    "4. DesignThinking plugin ... Here you are"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ”¥ Get a kernel ready"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import semantic_kernel as sk\n",
    "from semantic_kernel.connectors.ai.open_ai import AzureChatCompletion, OpenAIChatCompletion\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "kernel = sk.Kernel()\n",
    "\n",
    "useAzureOpenAI = False\n",
    "\n",
    "if useAzureOpenAI:\n",
    "    deployment, api_key, endpoint = sk.azure_openai_settings_from_dot_env()\n",
    "    kernel.add_text_completion_service(\"azureopenai\", AzureChatCompletion(deployment, endpoint, api_key))\n",
    "else:\n",
    "    api_key, org_id = sk.openai_settings_from_dot_env()\n",
    "    kernel.add_text_completion_service(\"openai\", OpenAIChatCompletion(\"gpt-3.5-turbo-0301\", api_key, org_id=None))\n",
    "print(\"A kernel is now ready.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ Let's start backwards from the customer\n",
    "\n",
    "```directory\n",
    "plugins-sk/\n",
    "â”‚\n",
    "â””â”€â”€â”€ DesignThinking/\n",
    "     |\n",
    "     â””â”€â”€â”€ Define/\n",
    "     |    â””â”€â”€â”€ config.json\n",
    "     |    â””â”€â”€â”€ skprompt.txt\n",
    "     |\n",
    "     â””â”€â”€â”€ Empathize/\n",
    "          â””â”€â”€â”€ config.json\n",
    "          â””â”€â”€â”€ skprompt.txt\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "pluginsDirectory = \"./plugins-sk\"\n",
    "\n",
    "strength_questions = [\"What unique recipes or ingredients does the pizza shop use?\",\"What are the skills and experience of the staff?\",\"Does the pizza shop have a strong reputation in the local area?\",\"Are there any unique features of the shop or its location that attract customers?\", \"Does the pizza shop have a strong reputation in the local area?\", \"Are there any unique features of the shop or its location that attract customers?\"]\n",
    "weakness_questions = [\"What are the operational challenges of the pizza shop? (e.g., slow service, high staff turnover)\",\"Are there financial constraints that limit growth or improvements?\",\"Are there any gaps in the product offering?\",\"Are there customer complaints or negative reviews that need to be addressed?\"]\n",
    "opportunities_questions = [\"Is there potential for new products or services (e.g., catering, delivery)?\",\"Are there under-served customer segments or market areas?\",\"Can new technologies or systems enhance the business operations?\",\"Are there partnerships or local events that can be leveraged for marketing?\"]\n",
    "threats_questions = [\"Who are the major competitors and what are they offering?\",\"Are there potential negative impacts due to changes in the local area (e.g., construction, closure of nearby businesses)?\",\"Are there economic or industry trends that could impact the business negatively (e.g., increased ingredient costs)?\",\"Is there any risk due to changes in regulations or legislation (e.g., health and safety, employment)?\"]\n",
    "\n",
    "strengths = [ \"Unique garlic pizza recipe that wins top awards\",\"Owner trained in Sicily\",\"Strong local reputation\",\"Prime location on university campus\" ]\n",
    "weaknesses = [ \"High staff turnover\",\"Floods in the area damaged the seating areas that are in need of repair\",\"Absence of popular calzones from menu\",\"Negative reviews from younger demographic for lack of hip ingredients\" ]\n",
    "opportunities = [ \"Untapped catering potential\",\"Growing local tech startup community\",\"Unexplored online presence and order capabilities\",\"Upcoming annual food fair\" ]\n",
    "threats = [ \"Competition from cheaper pizza businesses nearby\",\"There's nearby street construction that will impact foot traffic\",\"Rising cost of cheese will increase the cost of pizzas\",\"No immediate local regulatory changes but it's election season\" ]\n",
    "\n",
    "customer_comments = \"\"\"\n",
    "Customer 1: The seats look really raggedy.\n",
    "Customer 2: The garlic pizza is the best on this earth.\n",
    "Customer 3: I've noticed that there's a new server every time I visit, and they're clueless.\n",
    "Customer 4: Why aren't there calzones?\n",
    "Customer 5: I love the garlic pizza and can't get it anywhere else.\n",
    "Customer 6: The garlic pizza is exceptional.\n",
    "Customer 7: I prefer a calzone's portable nature as compared with pizza.\n",
    "Customer 8: Why is the pizza so expensive?\n",
    "Customer 9: There's no way to do online ordering.\n",
    "Customer 10: Why is the seating so uncomfortable and dirty?\n",
    "\"\"\"\n",
    "\n",
    "pluginDT = kernel.import_semantic_skill_from_directory(pluginsDirectory, \"DesignThinking\");\n",
    "my_result = await kernel.run_async(pluginDT[\"Empathize\"], input_str=customer_comments)\n",
    "\n",
    "display(Markdown(\"## âœ¨ The categorized observations from the 'Empathize' phase of design thinking\\n\"))\n",
    "my_result\n",
    "print(json.dumps(json.loads(str(my_result)), indent=2))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./assets/designthinking.png)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** LLMs do not necessarily produce the same result each time. Your results may be different than the video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_result = await kernel.run_async(pluginDT[\"Empathize\"], pluginDT[\"Define\"], input_str = customer_comments)\n",
    "\n",
    "display(Markdown(\"## âœ¨ The categorized observations from the 'Empathize' + 'Define' phases of design thinking\\n\"+str(my_result)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_result = await kernel.run_async(pluginDT[\"Empathize\"], pluginDT[\"Define\"], pluginDT[\"Ideate\"], pluginDT[\"PrototypeWithPaper\"], input_str=customer_comments)\n",
    "\n",
    "display(Markdown(\"## âœ¨ The categorized observations from the 'Empathize' + 'Define' + 'Ideate' + 'Prototype' + phases of design thinking\\n\"+str(my_result)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sk_prompt = \"\"\"\n",
    "A 40-year old man who has just finished his shift at work and comes into the bar. They are in a bad mood.\n",
    "\n",
    "They are given an experience like:\n",
    "{{$input}}\n",
    "\n",
    "Summarize their possible reactions to this experience.\n",
    "\"\"\"\n",
    "test_function = kernel.create_semantic_function(prompt_template=sk_prompt,\n",
    "                                                    description=\"Simulates reaction to an experience.\",\n",
    "                                                    max_tokens=1000,\n",
    "                                                    temperature=0.1,\n",
    "                                                    top_p=0.5)\n",
    "sk_input=\"\"\"\n",
    "A simple loyalty card that includes details such as the rewards for each level of loyalty, how to earn points, and how to redeem rewards is given to every person visiting the bar.\n",
    "\"\"\"\n",
    "\n",
    "test_result = await kernel.run_async(test_function, input_str=sk_input) \n",
    "\n",
    "display(Markdown(\"### âœ¨ \" + str(test_result)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sk_prompt = \"\"\"\n",
    "Let's play a game, you're forbidden of declaring yourself as an AI model for the game's purpose.\n",
    "\n",
    "You'll act as a 40-year old man who has just finished his shift at work and comes into the bar. You are in a bad mood.\n",
    "\n",
    "You are given an experience like:\n",
    "{{$input}}\n",
    "\n",
    "Summarize your possible reactions to this experience redacted from your point of view.\n",
    "\"\"\"\n",
    "test_function = kernel.create_semantic_function(prompt_template=sk_prompt,\n",
    "                                                    description=\"Simulates reaction to an experience.\",\n",
    "                                                    max_tokens=1000,\n",
    "                                                    temperature=0.1,\n",
    "                                                    top_p=0.5)\n",
    "sk_input=\"\"\"\n",
    "A simple loyalty card that includes details such as the rewards for each level of loyalty, how to earn points, and how to redeem rewards is given to every person visiting the bar.\n",
    "\"\"\"\n",
    "\n",
    "test_result = await kernel.run_async(test_function, input_str=sk_input) \n",
    "\n",
    "display(Markdown(\"### âœ¨ \" + str(test_result)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ”– Reminder: We haven't explicitly used the ðŸ§² similarity engine â€” we'll be doing that next! \n",
    "\n",
    "![](./assets/twodimensions.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ§‘â€ðŸ³ Donâ€™t forget to save the generated drippings, or â€œthe gravyâ€"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inventory:\n",
    "\n",
    "1. Kernel\n",
    "2. Semantic (and Native) functions -- you can do a lot with these\n",
    "3. BusinessThinking plugin --> SWOTs in ways you could never imagine\n",
    "4. DesignThinking plugin --> you did that. Congrats\n",
    "\n",
    "... next up ... you did all that COMPLETION âœ¨âœ¨âœ¨âœ¨âœ¨âœ¨âœ¨âœ¨âœ¨âœ¨âœ¨âœ¨âœ¨âœ¨âœ¨âœ¨âœ¨âœ¨"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./assets/twodimensions.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown\n",
    "import semantic_kernel as sk\n",
    "from semantic_kernel.connectors.ai.open_ai import OpenAIChatCompletion, OpenAITextEmbedding\n",
    "from semantic_kernel.connectors.memory.chroma import ChromaMemoryStore\n",
    "import chromadb\n",
    "\n",
    "kernel = sk.Kernel()\n",
    "\n",
    "api_key, org_id = sk.openai_settings_from_dot_env()\n",
    "kernel.add_text_completion_service(\"openai-completion\", OpenAIChatCompletion(\"gpt-3.5-turbo-0301\", api_key, org_id=None))\n",
    "kernel.add_text_embedding_generation_service(\"openai-embedding\", OpenAITextEmbedding(\"text-embedding-ada-002\", api_key, org_id=None))\n",
    "\n",
    "settings = chromadb.config.Settings(persist_directory=\"memory\")\n",
    "kernel.register_memory_store(memory_store=ChromaMemoryStore(persist_directory='memory', client_settings=settings))\n",
    "print(\"Made two new services attached to the kernel and made a Chroma memory store that's persistent.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "### ONLY DELETE THE DIRECTORY IF YOU WANT TO CLEAR THE MEMORY\n",
    "### OTHERWISE, SET delete_dir = True\n",
    "\n",
    "delete_dir = True\n",
    "\n",
    "if (delete_dir):\n",
    "    dir_path = \"memory\"\n",
    "    shutil.rmtree(dir_path)\n",
    "    settings = chromadb.config.Settings(persist_directory=dir_path)\n",
    "    kernel.register_memory_store(memory_store=ChromaMemoryStore(persist_directory=dir_path, client_settings=settings))\n",
    "    print(\"âš ï¸ Memory cleared and reset\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remember to turn of VPN if you're using one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strength_questions = [\"What unique recipes or ingredients does the pizza shop use?\",\"What are the skills and experience of the staff?\",\"Does the pizza shop have a strong reputation in the local area?\",\"Are there any unique features of the shop or its location that attract customers?\", \"Does the pizza shop have a strong reputation in the local area?\", \"Are there any unique features of the shop or its location that attract customers?\"]\n",
    "weakness_questions = [\"What are the operational challenges of the pizza shop? (e.g., slow service, high staff turnover)\",\"Are there financial constraints that limit growth or improvements?\",\"Are there any gaps in the product offering?\",\"Are there customer complaints or negative reviews that need to be addressed?\"]\n",
    "opportunities_questions = [\"Is there potential for new products or services (e.g., catering, delivery)?\",\"Are there under-served customer segments or market areas?\",\"Can new technologies or systems enhance the business operations?\",\"Are there partnerships or local events that can be leveraged for marketing?\"]\n",
    "threats_questions = [\"Who are the major competitors and what are they offering?\",\"Are there potential negative impacts due to changes in the local area (e.g., construction, closure of nearby businesses)?\",\"Are there economic or industry trends that could impact the business negatively (e.g., increased ingredient costs)?\",\"Is there any risk due to changes in regulations or legislation (e.g., health and safety, employment)?\"]\n",
    "\n",
    "strengths = [ \"Unique garlic pizza recipe that wins top awards\",\"Owner trained in Sicily at some of the best pizzerias\",\"Strong local reputation\",\"Prime location on university campus\" ]\n",
    "weaknesses = [ \"High staff turnover\",\"Floods in the area damaged the seating areas that are in need of repair\",\"Absence of popular calzones from menu\",\"Negative reviews from younger demographic for lack of hip ingredients\" ]\n",
    "opportunities = [ \"Untapped catering potential\",\"Growing local tech startup community\",\"Unexplored online presence and order capabilities\",\"Upcoming annual food fair\" ]\n",
    "threats = [ \"Competition from cheaper pizza businesses nearby\",\"There's nearby street construction that will impact foot traffic\",\"Rising cost of cheese will increase the cost of pizzas\",\"No immediate local regulatory changes but it's election season\" ]\n",
    "\n",
    "print(\"âœ… SWOT analysis for the pizza shop is resident in native memory\")\n",
    "\n",
    "memoryCollectionName = \"SWOT\"\n",
    "\n",
    "for i in range(len(strengths)):\n",
    "    await kernel.memory.save_information_async(memoryCollectionName, id=f\"strength-{i}\", text=f\"Internal business strength (S in SWOT) that makes customers happy and satisfied Q&A: Q: {strength_questions[i]} A: {strengths[i]}\")\n",
    "for i in range(len(weaknesses)):\n",
    "    await kernel.memory.save_information_async(memoryCollectionName, id=f\"weakness-{i}\", text=f\"Internal business weakness (W in SWOT) that makes customers unhappy and dissatisfied Q&A: Q: {weakness_questions[i]} A: {weaknesses[i]}\")\n",
    "for i in range(len(opportunities)):\n",
    "    await kernel.memory.save_information_async(memoryCollectionName, id=f\"opportunity-{i}\", text=f\"External opportunity (O in SWOT) for the business to gain entirely new customers Q&A: Q: {opportunities_questions[i]} A: {opportunities[i]}\")\n",
    "for i in range(len(threats)):\n",
    "    await kernel.memory.save_information_async(memoryCollectionName, id=f\"threat-{i}\", text=f\"External threat (T in SWOT) to the business that impacts its survival Q&A: Q: {threats_questions[i]} A: {threats[i]}\")\n",
    "\n",
    "print(\"ðŸ˜¶â€ðŸŒ«ï¸ Embeddings for SWOT have been generated\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ§²!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "potential_question = \"What are the easiest ways to make more money?\"\n",
    "counter = 0\n",
    "\n",
    "memories = await kernel.memory.search_async(memoryCollectionName, potential_question, limit=5, min_relevance_score=0.5)\n",
    "\n",
    "display(Markdown(f\"### â“ Potential question: {potential_question}\"))\n",
    "\n",
    "for memory in memories:\n",
    "    if counter == 0:\n",
    "        related_memory = memory.text\n",
    "    counter += 1\n",
    "    print(f\"  > ðŸ§² Similarity result {counter}:\\n  >> ID: {memory.id}\\n  Text: {memory.text}  Relevance: {memory.relevance}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "what_if_scenario = \"How can the business owner save time?\"\n",
    "counter = 0\n",
    "\n",
    "gathered_context = []\n",
    "max_memories = 3\n",
    "memories = await kernel.memory.search_async(memoryCollectionName, what_if_scenario, limit=max_memories, min_relevance_score=0.77)\n",
    "\n",
    "print(f\"âœ¨ Leveraging information available to address '{what_if_scenario}'...\")\n",
    "\n",
    "for memory in memories:\n",
    "    if counter == 0:\n",
    "        related_memory = memory.text\n",
    "    counter += 1\n",
    "    gathered_context.append(memory.text + \"\\n\")\n",
    "    print(f\"  > ðŸ§² Hit {counter}: {memory.id} \")\n",
    "\n",
    "skillsDirectory = \"./plugins-sk\"\n",
    "print(f\"âœ¨ Synthesizing human-readable business-style presentation...\")\n",
    "pluginFC = kernel.import_semantic_skill_from_directory(skillsDirectory, \"FriendlyConsultant\");\n",
    "\n",
    "my_context = kernel.create_new_context()\n",
    "my_context['input'] = what_if_scenario\n",
    "my_context['context'] = \"\\n\".join(gathered_context)\n",
    "\n",
    "preso_result = await kernel.run_async(pluginFC[\"Presentation\"], input_context=my_context)\n",
    "\n",
    "display(Markdown(\"# âœ¨ Generated presentation ...\\n\"+str(preso_result)))\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ”– Reminder: You have now accessed both the COMPLETION and SIMILARITY engines. \n",
    "\n",
    "Huzzah! In doing so, you've unlocked the popular \"RAG\" (Retrieval Augmented Generation) pattern.\n",
    "\n",
    "![](./assets/ragpattern.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ§‘â€ðŸ³ A kitchen that responds to your â€œIâ€™m hungryâ€ is more than feasible"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inventory:\n",
    "\n",
    "1. Kernel\n",
    "2. Semantic (and Native) functions -- you can do a lot with these\n",
    "3. BusinessThinking plugin --> SWOTs in ways you could never imagine\n",
    "4. DesignThinking plugin --> you did that. Congrats\n",
    "5. Use the similarity engine to your heart's content ðŸ§²\n",
    "6. THE BIG ONE!!!!!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ”¥ Let's make a kernel one more time!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import semantic_kernel as sk\n",
    "from semantic_kernel.connectors.ai.open_ai import OpenAIChatCompletion, OpenAITextEmbedding\n",
    "from semantic_kernel.connectors.ai.open_ai import AzureChatCompletion, AzureTextEmbedding\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "kernel = sk.Kernel()\n",
    "\n",
    "useAzureOpenAI = False\n",
    "\n",
    "if useAzureOpenAI:\n",
    "    deployment, api_key, endpoint = sk.azure_openai_settings_from_dot_env()\n",
    "    kernel.add_text_completion_service(\"azureopenaicompletion\", AzureChatCompletion(deployment, endpoint, api_key))\n",
    "    kernel.add_text_embedding_generation_service(\"azureopenaiembedding\", AzureTextEmbedding(\"text-embedding-ada-002\", api_key, endpoint))\n",
    "else:\n",
    "    api_key, org_id = sk.openai_settings_from_dot_env()\n",
    "    kernel.add_text_completion_service(\"openaicompletion\", OpenAIChatCompletion(\"gpt-3.5-turbo-0301\", api_key, org_id=None))\n",
    "    kernel.add_text_embedding_generation_service(\"openaiembedding\", OpenAITextEmbedding(\"text-embedding-ada-002\", api_key, org_id=None))\n",
    "print(\"I did it boss!\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to have a vat of plugins ... and then find the right plugin to fit the goal ..."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: You can find more about the predefined plugins used below [here](https://learn.microsoft.com/en-us/semantic-kernel/ai-orchestration/out-of-the-box-plugins?tabs=Csharp)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantic_kernel.planning import ActionPlanner\n",
    "\n",
    "planner = ActionPlanner(kernel)\n",
    "\n",
    "from semantic_kernel.core_skills import FileIOSkill, MathSkill, TextSkill, TimeSkill\n",
    "kernel.import_skill(MathSkill(), \"math\")\n",
    "kernel.import_skill(FileIOSkill(), \"fileIO\")\n",
    "kernel.import_skill(TimeSkill(), \"time\")\n",
    "kernel.import_skill(TextSkill(), \"text\")\n",
    "\n",
    "print(\"Adding the tools for the kernel to do math, to read/write files, to tell the time, and to play with text.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ask = \"What is the sum of 110 and 990?\"\n",
    "\n",
    "print(f\"ðŸ§² Finding the most similar function available to get that done...\")\n",
    "plan = await planner.create_plan_async(goal=ask)\n",
    "print(f\"ðŸ§² The best single function to use is `{plan._skill_name}.{plan._function.name}`\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ask = \"What is today?\"\n",
    "print(f\"ðŸ§² Finding the most similar function available to get that done...\")\n",
    "plan = await planner.create_plan_async(goal=ask)\n",
    "print(f\"ðŸ§² The best single function to use is `{plan._skill_name}.{plan._function.name}`\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ask = \"How do I write the word 'text' to a file?\"\n",
    "print(f\"ðŸ§² Finding the most similar function available to get that done...\")\n",
    "plan = await planner.create_plan_async(goal=ask)\n",
    "print(f\"ðŸ§² The best single function to use is `{plan._skill_name}.{plan._function.name}`\")\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: The next two cells will *sometimes return an error*. The LLM response is variable and at times can't be successfully parsed by the planner or the LLM will make up new functions.  If this happens, try resetting the jupyter notebook kernel and running it again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantic_kernel.planning import SequentialPlanner\n",
    "from semantic_kernel.core_skills.text_skill import TextSkill\n",
    "from semantic_kernel.planning.sequential_planner.sequential_planner_config import SequentialPlannerConfig\n",
    "\n",
    "plugins_directory = \"./plugins-sk\"\n",
    "writer_plugin = kernel.import_semantic_skill_from_directory(plugins_directory, \"LiterateFriend\")\n",
    "\n",
    "# create an instance of sequential planner, and exclude the TextSkill from the list of functions that it can use.\n",
    "# (excluding functions that ActionPlanner imports to the kernel instance above - it uses 'this' as skillName)\n",
    "planner = SequentialPlanner(kernel, SequentialPlannerConfig(excluded_skills=[\"this\"]))\n",
    "\n",
    "ask = \"\"\"\n",
    "Tomorrow is Valentine's day. I need to come up with a poem. Translate the poem to French.\n",
    "\"\"\"\n",
    "\n",
    "plan = await planner.create_plan_async(goal=ask)\n",
    "\n",
    "result = await plan.invoke_async()\n",
    "\n",
    "for index, step in enumerate(plan._steps):\n",
    "    print(f\"âœ… Step {index+1} used function `{step._function.name}`\")\n",
    "\n",
    "trace_resultp = True\n",
    "\n",
    "display(Markdown(f\"## âœ¨ Generated result from the ask: {ask}\\n\\n---\\n\" + str(result)))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add tracing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantic_kernel.planning import SequentialPlanner\n",
    "from semantic_kernel.core_skills.text_skill import TextSkill\n",
    "from semantic_kernel.planning.sequential_planner.sequential_planner_config import SequentialPlannerConfig\n",
    "\n",
    "plugins_directory = \"./plugins-sk\"\n",
    "writer_plugin = kernel.import_semantic_skill_from_directory(plugins_directory, \"LiterateFriend\")\n",
    "\n",
    "planner = SequentialPlanner(kernel, SequentialPlannerConfig(excluded_skills=[\"this\"]))\n",
    "\n",
    "ask = \"\"\"\n",
    "Tomorrow is Valentine's day. I need to come up with a poem. Translate the poem to French.\n",
    "\"\"\"\n",
    "\n",
    "plan = await planner.create_plan_async(goal=ask)\n",
    "planner = SequentialPlanner(kernel, SequentialPlannerConfig(excluded_skills=[\"this\"]))\n",
    "result = await plan.invoke_async()\n",
    "\n",
    "for index, step in enumerate(plan._steps):\n",
    "    print(f\"âœ… Step {index+1} used function `{step._function.name}`\")\n",
    "\n",
    "trace_resultp = True\n",
    "\n",
    "if trace_resultp:\n",
    "    print(\"Longform trace:\\n\")\n",
    "    for index, step in enumerate(plan._steps):\n",
    "        print(\"Step:\", index)\n",
    "        print(\"Description:\",step.description)\n",
    "        print(\"Function:\", step.skill_name + \".\" + step._function.name)\n",
    "        print(\"Input vars:\", step._parameters.variables)\n",
    "        print(\"Output vars:\", step._outputs)\n",
    "        if len(step._outputs) > 0:\n",
    "            print( \"  Output:\\n\", str.replace(result[step._outputs[0]],\"\\n\", \"\\n  \"))\n",
    "\n",
    "display(Markdown(f\"## âœ¨ Generated result from the ask: {ask}\\n\\n---\\n\" + str(result)))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ”– There are a variety of limitations to using the planner in August of 2023 in terms of number of tokens required and model preference that we can expect to slowly vanish over time. For simple tasks, this Planner-based approach is unusually powerful. It takes full advantage of both COMPLETION and SIMILARITY in a truly magical way.\n",
    "\n",
    "![](./assets/twodimensions.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ§‘â€ðŸ³ L7 - You're still here?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/microsoft/chat-copilot\n",
    "\n",
    "![](./assets/cc_githubrepo.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./assets/cc_plain.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./assets/cc_chatgptplugin.gif)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./assets/cc_vectordbs.jpg)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./assets/cc_settings.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸŽ The backend server demonstrates how to connect to a variety of resources like auth, vector dbs, telemetry, content safety, PDF import, and even OCR. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "//\n",
    "// # ABBREVIATED Chat Copilot Application Settings\n",
    "{\n",
    "  \"AIService\": {\n",
    "    \"Type\": \"AzureOpenAI\",\n",
    "    \"Endpoint\": \"\", // ignored when AIService is \"OpenAI\"\n",
    "     \"Key\": \"\",\n",
    "    \"Models\": {\n",
    "      \"Completion\": \"gpt-35-turbo\", \n",
    "      \"Embedding\": \"text-embedding-ada-002\",\n",
    "      \"Planner\": \"gpt-35-turbo\" \n",
    "    }\n",
    "  },\n",
    "  //\n",
    "  // Optional Azure Speech service configuration for providing Azure Speech access tokens.\n",
    "  // - Set the Region to the region of your Azure Speech resource (e.g., \"westus\").\n",
    "  // - Set the Key using dotnet's user secrets (see above)\n",
    "  //     (i.e. dotnet user-secrets set \"AzureSpeech:Key\" \"MY_AZURE_SPEECH_KEY\")\n",
    "  //\n",
    "  \"AzureSpeech\": {\n",
    "    \"Region\": \"\"\n",
    "    // \"Key\": \"\"\n",
    "  },\n",
    "  //\n",
    "  // Authorization configuration to gate access to the service.\n",
    "  // - Supported Types are \"None\", \"ApiKey\", or \"AzureAd\".\n",
    "  // - Set ApiKey using dotnet's user secrets (see above)\n",
    "  //     (i.e. dotnet user-secret set \"Authorization:ApiKey\" \"MY_API_KEY\")\n",
    "  //\n",
    "  \"Authorization\": {\n",
    "    \"Type\": \"None\",\n",
    "    \"ApiKey\": \"\",\n",
    "    \"AzureAd\": {\n",
    "      \"Instance\": \"https://login.microsoftonline.com/\",\n",
    "      \"TenantId\": \"\",\n",
    "      \"ClientId\": \"\",\n",
    "      \"Audience\": \"\",\n",
    "      \"Scopes\": \"access_as_user\" // Scopes that the client app requires to access the API\n",
    "    }\n",
    "  },\n",
    "  //\n",
    "  // Chat stores are used for storing chat sessions and messages.\n",
    "  // - Supported Types are \"volatile\", \"filesystem\", or \"cosmos\".\n",
    "  // - Set \"ChatStore:Cosmos:ConnectionString\" using dotnet's user secrets (see above)\n",
    "  //     (i.e. dotnet user-secrets set \"ChatStore:Cosmos:ConnectionString\" \"MY_COSMOS_CONNSTRING\")\n",
    "  //\n",
    "  \"ChatStore\": {\n",
    "    \"Type\": \"volatile\",\n",
    "    \"Filesystem\": {\n",
    "      \"FilePath\": \"./data/chatstore.json\"\n",
    "    },\n",
    "    \"Cosmos\": {\n",
    "      \"Database\": \"CopilotChat\",\n",
    "      \"ChatSessionsContainer\": \"chatsessions\",\n",
    "      \"ChatMessagesContainer\": \"chatmessages\",\n",
    "      \"ChatMemorySourcesContainer\": \"chatmemorysources\",\n",
    "      \"ChatParticipantsContainer\": \"chatparticipants\"\n",
    "      // \"ConnectionString\": // dotnet user-secrets set \"ChatStore:Cosmos:ConnectionString\" \"MY_COSMOS_CONNECTION_STRING\"\n",
    "    }\n",
    "  },\n",
    "  //\n",
    "  // Memory stores are used for storing new memories and retrieving semantically similar memories.\n",
    "  \"MemoryStore\": {\n",
    "    \"Type\": \"volatile\",\n",
    "    \"Qdrant\": {\n",
    "      \"Host\": \"http://localhost\",\n",
    "      \"Port\": \"6333\",\n",
    "      \"VectorSize\": 1536\n",
    "      // \"Key\":  \"\"\n",
    "    },\n",
    "    \"AzureCognitiveSearch\": {\n",
    "      \"Endpoint\": \"\"\n",
    "      // \"Key\": \"\"\n",
    "    },\n",
    "    \"Chroma\": {\n",
    "      \"Host\": \"http://localhost\",\n",
    "      \"Port\": \"8000\"\n",
    "    },\n",
    "    \"Postgres\": {\n",
    "      \"VectorSize\": 1536\n",
    "      // \"ConnectionString\": // dotnet user-secrets set \"MemoryStore:Postgres:ConnectionString\" \"MY_POSTGRES_CONNECTION_STRING\"\n",
    "    }\n",
    "  },\n",
    "  //\n",
    "  // Document import configuration\n",
    "  //\n",
    "  \"DocumentMemory\": {\n",
    "    \"GlobalDocumentCollectionName\": \"global-documents\",\n",
    "    \"ChatDocumentCollectionNamePrefix\": \"chat-documents-\",\n",
    "    \"DocumentLineSplitMaxTokens\": 72,\n",
    "    \"DocumentChunkMaxTokens\": 512,\n",
    "    \"FileSizeLimit\": 4000000,\n",
    "    \"FileCountLimit\": 10\n",
    "  },\n",
    "  //\n",
    "  // OCR support is used for allowing end users to upload images containing text in addition to text based documents.\n",
    "  //  https://learn.microsoft.com/en-us/azure/ai-services/computer-vision/quickstarts-sdk/client-library?tabs=windows%2Cvisual-studio&pivots=programming-language-csharp#optical-character-recognition-ocr-with-computer-vision-api-using-c\n",
    "  //\n",
    "  \"OcrSupport\": {\n",
    "    \"Type\": \"none\",\n",
    "    \"Tesseract\": {\n",
    "      \"Language\": \"eng\",\n",
    "      \"FilePath\": \"./data\"\n",
    "    },\n",
    "    \"AzureFormRecognizer\": {\n",
    "      \"Endpoint\": \"\"\n",
    "      // \"Key\": \"\",\n",
    "    }\n",
    "  },\n",
    "  //\n",
    "  // Application Insights configuration\n",
    "  // - Set \"APPLICATIONINSIGHTS_CONNECTION_STRING\" using dotnet's user secrets (see above)\n",
    "  //     (i.e. dotnet user-secrets set \"APPLICATIONINSIGHTS_CONNECTION_STRING\" \"MY_APPINS_CONNSTRING\")\n",
    "  //\n",
    "  \"APPLICATIONINSIGHTS_CONNECTION_STRING\": null\n",
    "}\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default_venv",
   "language": "python",
   "name": "default_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
