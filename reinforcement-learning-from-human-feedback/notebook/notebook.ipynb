{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "088542f0",
   "metadata": {},
   "source": [
    "# Datasets For Reinforcement Learning Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e08cfaf3",
   "metadata": {},
   "source": [
    "### Loading and exploring the datasets\n",
    "\n",
    "\"Reinforcement Learning from Human Feedback\" **(RLHF)** requires the following datasets:\n",
    "- Preference dataset\n",
    "  - Input prompt, candidate response 0, candidate response 1, choice (candidate 0 or 1)\n",
    "- Prompt dataset\n",
    "  - Input prompt only, no response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "236bce0e",
   "metadata": {},
   "source": [
    "#### Preference dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3048b1b5-a01c-4c89-af5a-ce8f47d13218",
   "metadata": {
    "height": 49
   },
   "outputs": [],
   "source": [
    "preference_dataset_path = 'data/sample_preference.jsonl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7822c372-b9d0-46c0-86c3-dc38508262e3",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb35514-6e2b-433c-a6f3-9411846fd2a6",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "preference_data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35bcc873-cd6a-4108-9c4a-47b7d27faab7",
   "metadata": {
    "height": 83
   },
   "outputs": [],
   "source": [
    "with open(preference_dataset_path) as f:\n",
    "    for line in f:\n",
    "        preference_data.append(json.loads(line))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b2290d9",
   "metadata": {},
   "source": [
    "- Print out to explore the preference dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57964e85-d4bd-4b35-b437-e51a4493eb33",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "sample_1 = preference_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9bff834-4c5e-46c4-8887-d3a29cc8de86",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "print(type(sample_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b473d0-bf39-4f8b-99e5-d6f795f33b83",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "# This dictionary has four keys\n",
    "print(sample_1.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d524bb",
   "metadata": {},
   "source": [
    "- Key: 'input_test' is a prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "630d6337-0e6c-4ccb-987a-7d73de91c65a",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "sample_1['input_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb97174-bb2b-400a-b76a-81428063b76a",
   "metadata": {
    "height": 66
   },
   "outputs": [],
   "source": [
    "# Try with another examples from the list, and discover that all data end the same way\n",
    "preference_data[2]['input_text'][-50:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78232d32",
   "metadata": {},
   "source": [
    "- Print 'candidate_0' and 'candidate_1', these are the completions for the same prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a67ab282-3495-4aab-a43a-309978e03529",
   "metadata": {
    "height": 66
   },
   "outputs": [],
   "source": [
    "print(f\"candidate_0:\\n{sample_1.get('candidate_0')}\\n\")\n",
    "print(f\"candidate_1:\\n{sample_1.get('candidate_1')}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d3cc61",
   "metadata": {},
   "source": [
    "- Print 'choice', this is the human labeler's preference for the results completions (candidate_0 and candidate_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae5b1cb-5411-462c-a122-bbb6264e4111",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "print(f\"choice: {sample_1.get('choice')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eda6787",
   "metadata": {},
   "source": [
    "#### Prompt dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c2785a-87df-4bc7-adb8-ccbdfff7b819",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "prompt_dataset_path = 'data/sample_prompt.jsonl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa3fd8ef-c9f3-4bc3-9404-cbe91fcae150",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "prompt_data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e47624-472f-4f20-8f02-219b38e166ee",
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "with open(prompt_dataset_path) as f:\n",
    "    for line in f:\n",
    "        prompt_data.append(json.loads(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c90028-5da8-435d-a203-92a661154598",
   "metadata": {
    "height": 66
   },
   "outputs": [],
   "source": [
    "# Check how many prompts there are in this dataset\n",
    "len(prompt_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e08fd3a7",
   "metadata": {},
   "source": [
    "**Note**: It is important that the prompts in both datasets, the preference and the prompt, come from the same distribution. \n",
    "\n",
    "For this lesson, all the prompts come from the same dataset of [Reddit posts](https://github.com/openai/summarize-from-feedback)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6da85e-5b6d-4d68-bb8e-70716205f28a",
   "metadata": {
    "height": 100
   },
   "outputs": [],
   "source": [
    "# Function to print the information in the prompt dataset with a better visualization\n",
    "def print_d(d):\n",
    "    for key, val in d.items():        \n",
    "        print(f\"key:{key}\\nval:{val}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e665d332-38a2-4b8c-be5a-6e4c6c3392b1",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "print_d(prompt_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9825d214-13a1-41c0-8280-b584d2f3bbd0",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "# Try with another prompt from the list \n",
    "print_d(prompt_data[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1073ae28",
   "metadata": {},
   "source": [
    "# Tune an LLM with RLHF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07e8bc26",
   "metadata": {},
   "source": [
    "#### Project environment setup\n",
    "\n",
    "The RLHF training process has been implemented in a machine learning pipeline as part of the (Google Cloud Pipeline Components) library. This can be run on any platform that supports KubeFlow Pipelines (an open source framework), and can also run on Google Cloud's Vertex AI Pipelines.\n",
    "\n",
    "To run it locally, install the following:\n",
    "```Python\n",
    "!pip3 install google-cloud-pipeline-components\n",
    "!pip3 install kfp\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19cbc5c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "! gcloud auth login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c0af4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "PROJECT_ID = os.environ['PROJECT_ID']\n",
    "REGION = os.environ['REGION']\n",
    "print(f\"PROJECT_ID: {PROJECT_ID}\")\n",
    "print(f\"REGION: {REGION}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1acee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Authenticate in utils\n",
    "from utils import authenticate\n",
    "credentials, PROJECT_ID, STAGING_BUCKET = authenticate()\n",
    "\n",
    "# RLFH pipeline is available in this region\n",
    "REGION = \"europe-west4\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62fcf866",
   "metadata": {},
   "source": [
    "### Download data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f795f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import storage\n",
    "import os\n",
    "\n",
    "def download_blob(bucket_name, source_blob_name, destination_file_name):\n",
    "    \"\"\"Downloads a blob from the bucket.\"\"\"\n",
    "    storage_client = storage.Client(credentials=credentials)\n",
    "    bucket = storage_client.bucket(bucket_name)\n",
    "    blob = bucket.blob(source_blob_name)\n",
    "    blob.download_to_filename(destination_file_name)\n",
    "    print(f\"Blob {source_blob_name} downloaded to {destination_file_name}.\")\n",
    "\n",
    "\n",
    "def download_files_from_prefix(bucket_name, prefix, destination_dir):\n",
    "    \"\"\"Downloads all blobs with a prefix from the bucket.\"\"\"\n",
    "    storage_client = storage.Client(credentials=credentials)\n",
    "    blobs = storage_client.list_blobs(bucket_name, prefix=prefix)\n",
    "\n",
    "    for blob in blobs:\n",
    "        # Prepare the local file path\n",
    "        local_path = os.path.join(destination_dir, blob.name.replace(prefix, \"\"))\n",
    "        # Ensure the local directory structure mirrors the GCS structure\n",
    "        os.makedirs(os.path.dirname(local_path), exist_ok=True)\n",
    "\n",
    "        # Download the blob to the local path\n",
    "        download_blob(bucket_name, blob.name, local_path)\n",
    "\n",
    "\n",
    "def upload_blob(bucket_name, source_file_name, destination_blob_name):\n",
    "    \"\"\"Uploads a file to the bucket.\"\"\"\n",
    "    storage_client = storage.Client(credentials=credentials)\n",
    "    bucket = storage_client.bucket(bucket_name)\n",
    "    blob = bucket.blob(destination_blob_name)\n",
    "    blob.upload_from_filename(source_file_name)\n",
    "    print(f\"File {source_file_name} uploaded to {destination_blob_name}.\")\n",
    "\n",
    "    \n",
    "def upload_directory(bucket_name, source_dir, destination_blob_prefix):\n",
    "    \"\"\"Uploads a directory to the bucket.\"\"\"\n",
    "    for local_root, dirs, files in os.walk(source_dir):\n",
    "        for filename in files:\n",
    "            local_path = os.path.join(local_root, filename)\n",
    "    \n",
    "            # Construct the full path for the destination\n",
    "            relative_path = os.path.relpath(local_path, source_dir)\n",
    "            blob_path = os.path.join(destination_blob_prefix, relative_path)\n",
    "    \n",
    "            # Upload the file\n",
    "            upload_blob(bucket_name, local_path, blob_path)\n",
    "    \n",
    "\n",
    "# Download and upload files to the staging bucket\n",
    "bucket_name = \"vertex-ai\"\n",
    "prefixes = [\n",
    "    \"generative-ai/rlhf/text_small/reddit_tfds/train/\", \n",
    "    \"generative-ai/rlhf/text_small/reddit_tfds/val/\", \n",
    "    \"generative-ai/rlhf/text_small/summarize_from_feedback_tfds/comparisons/train/\"\n",
    "    ]\n",
    "destination_dir = \"data/rlhf/\"  # Make sure this directory exists or create it\n",
    "destinations = (\n",
    "    [f\"{destination_dir}{prefix.split('/')[-2]}\" for prefix in prefixes[:-1]] \n",
    "    + \n",
    "    [f\"{destination_dir}summarize_from_feedback_tfds/comparisons/train/\"]\n",
    "    )\n",
    "\n",
    "for i in range(len(prefixes)):\n",
    "    prefix = prefixes[i]\n",
    "    destination_dir = destinations[i]\n",
    "    download_files_from_prefix(bucket_name, prefix, destination_dir)\n",
    "upload_bucket_name = STAGING_BUCKET.replace(\"gs://\", \"\")  # Remove gs://\n",
    "for dst in destinations:\n",
    "    print(f\"Uploading {dst} to {upload_bucket_name}\")\n",
    "    upload_directory(upload_bucket_name, dst, dst)\n",
    "destinations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd3c7818",
   "metadata": {},
   "source": [
    "### Compile the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f8289be-0f03-4f97-aaf3-b4e80330bce9",
   "metadata": {
    "height": 83
   },
   "outputs": [],
   "source": [
    "# Import (RLFH is currently in preview)\n",
    "from google_cloud_pipeline_components.preview.llm \\\n",
    "import rlhf_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ac4718-782d-4fe7-a39f-51fe5b423210",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "# Import from KubeFlow pipelines\n",
    "from kfp import compiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef016774-5400-45be-9682-4b0b0daa9095",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "# Define a path to the yaml file\n",
    "RLHF_PIPELINE_PKG_PATH = \"rlhf_pipeline.yaml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6abca02b-c43b-4301-8be0-a34949eb38b0",
   "metadata": {
    "height": 98
   },
   "outputs": [],
   "source": [
    "# Execute the compile function\n",
    "compiler.Compiler().compile(\n",
    "    pipeline_func=rlhf_pipeline,\n",
    "    package_path=RLHF_PIPELINE_PKG_PATH\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3904e2b-593c-4c95-b0c8-f7334a1fa728",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "# Print the first lines of the YAML file\n",
    "!head rlhf_pipeline.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "951da6e9",
   "metadata": {},
   "source": [
    "**Note**: to print the whole YAML file, use the following:\n",
    "```Python\n",
    "!cat rlhf_pipeline.yaml\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e14851c",
   "metadata": {},
   "source": [
    "## Define the Vertex AI pipeline job"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe574a96",
   "metadata": {},
   "source": [
    "### Define the location of the training and evaluation data\n",
    "Previously, the datasets were loaded from small JSONL files, but for typical training jobs, the datasets are much larger, and are usually stored in cloud storage (in this case, Google Cloud Storage).\n",
    "\n",
    "**Note:** Make sure that the three datasets are stored in the same Google Cloud Storage bucket.\n",
    "```Python\n",
    "parameter_values={\n",
    "        \"preference_dataset\": \\\n",
    "    \"gs://vertex-ai/generative-ai/rlhf/text_small/summarize_from_feedback_tfds/comparisons/train/*.jsonl\",\n",
    "        \"prompt_dataset\": \\\n",
    "    \"gs://vertex-ai/generative-ai/rlhf/text_small/reddit_tfds/train/*.jsonl\",\n",
    "        \"eval_dataset\": \\\n",
    "    \"gs://vertex-ai/generative-ai/rlhf/text_small/reddit_tfds/val/*.jsonl\",\n",
    "    ...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6410f32-475f-4fc6-a751-5fe627312085",
   "metadata": {},
   "source": [
    "### Choose the foundation model to be tuned\n",
    "\n",
    "In this case, we are tuning the [Llama-2](https://ai.meta.com/llama/) foundational model, the LLM to tune is called **large_model_reference**. \n",
    "\n",
    "In this course, we're tuning the llama-2-7b, but you can also run an RLHF pipeline on Vertex AI to tune models such as: the T5x or text-bison@001. \n",
    "\n",
    "```Python\n",
    "parameter_values={\n",
    "        \"large_model_reference\": \"llama-2-7b\",\n",
    "        ...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceff91eb",
   "metadata": {},
   "source": [
    "### Calculate the number of reward model training steps\n",
    "\n",
    "**reward_model_train_steps** is the number of steps to use when training the reward model.  This depends on the size of your preference dataset. We recommend the model should train over the preference dataset for 20-30 epochs for best results.\n",
    "\n",
    "$$ stepsPerEpoch = \\left\\lceil \\frac{datasetSize}{batchSize} \\right\\rceil$$\n",
    "$$ trainSteps = stepsPerEpoch \\times numEpochs$$\n",
    "\n",
    "The RLHF pipeline parameters are asking for the number of training steps and not number of epochs. Here's an example of how to go from epochs to training steps, given that the batch size for this pipeline is fixed at 64 examples per batch.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1031a7d-ed33-451b-aac4-1e1b616826c4",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "# Preference dataset size\n",
    "PREF_DATASET_SIZE = 3000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7cbe0db-19de-4b0b-bfd7-8bd06a22defa",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "# Batch size is fixed at 64\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c94da3-3016-4743-baeb-50bedd330328",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dfb58a8-9498-41b3-afc8-7ef81c4a7404",
   "metadata": {
    "height": 66
   },
   "outputs": [],
   "source": [
    "REWARD_STEPS_PER_EPOCH = math.ceil(PREF_DATASET_SIZE / BATCH_SIZE)\n",
    "print(REWARD_STEPS_PER_EPOCH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe291d6-6d5c-4fb8-a783-61fb21269766",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "REWARD_NUM_EPOCHS = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f83ffdc9-29d6-40e7-be30-06693816de63",
   "metadata": {
    "height": 66
   },
   "outputs": [],
   "source": [
    "# Calculate number of steps in the reward model training\n",
    "reward_model_train_steps = REWARD_STEPS_PER_EPOCH * REWARD_NUM_EPOCHS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f3df46-868f-470f-b4db-bbcd4ca6dfd2",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "print(reward_model_train_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "831e866f-828e-4d5b-9d42-d206b57cb0b9",
   "metadata": {},
   "source": [
    "### Calculate the number of reinforcement learning training steps\n",
    "The **reinforcement_learning_train_steps** parameter is the number of reinforcement learning steps to perform when tuning the base model. \n",
    "- The number of training steps depends on the size of your prompt dataset. Usually, this model should train over the prompt dataset for roughly 10-20 epochs.\n",
    "- Reward hacking: if given too many training steps, the policy model may figure out a way to exploit the reward and exhibit undesired behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6880ae3-8977-4605-9b8d-e50013c03896",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "# Prompt dataset size\n",
    "PROMPT_DATASET_SIZE = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e1f705-9ff2-4204-b4f9-96bcaacf798c",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "# Batch size is fixed at 64\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "898fd671-e3f1-4174-8c63-dd64af6baa1d",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30281c30-3b29-4ec0-b7fc-0df4f0203349",
   "metadata": {
    "height": 66
   },
   "outputs": [],
   "source": [
    "RL_STEPS_PER_EPOCH = math.ceil(PROMPT_DATASET_SIZE / BATCH_SIZE)\n",
    "print(RL_STEPS_PER_EPOCH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3415a4c5-c816-46e1-8b1e-2b6b976f2653",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "RL_NUM_EPOCHS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d16b09f-5e48-4c2e-bb33-0b719e0943fa",
   "metadata": {
    "height": 66
   },
   "outputs": [],
   "source": [
    "# Calculate the number of steps in the RL training\n",
    "reinforcement_learning_train_steps = RL_STEPS_PER_EPOCH * RL_NUM_EPOCHS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b4079f9-0816-46c3-937f-3c85a491eb22",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "print(reinforcement_learning_train_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e83b95cf-9f6f-45c2-810f-363f761a235b",
   "metadata": {},
   "source": [
    "### Define the instruction\n",
    "\n",
    "- Choose the task-specific instruction that you want to use to tune the foundational model.  For this example, the instruction is \"Summarize in less than 50 words.\"\n",
    "- You can choose different instructions, for example, \"Write a reply to the following question or comment.\" Note that you would also need to collect your preference dataset with the same instruction added to the prompt, so that both the responses and the human preferences are based on that instruction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14cbd66c-aeb2-4bf8-97f0-eba82e5de51e",
   "metadata": {
    "height": 304
   },
   "outputs": [],
   "source": [
    "# Completed values for the dictionary\n",
    "parameter_values={\n",
    "        \"preference_dataset\": \\\n",
    "    \"gs://rlhf-staging/data/rlhf/summarize_from_feedback_tfds/comparisons/train/*.jsonl\",\n",
    "        \"prompt_dataset\": \\\n",
    "    \"gs://rlhf-staging/data/rlhf/train/*.jsonl\",\n",
    "        \"eval_dataset\": \\\n",
    "    \"gs://rlhf-staging/data/rlhf/val/*.jsonl\",\n",
    "        \"large_model_reference\": \"llama-2-7b\",\n",
    "        \"reward_model_train_steps\": 1410,\n",
    "        \"reinforcement_learning_train_steps\": 320, # results from the calculations above\n",
    "        \"reward_model_learning_rate_multiplier\": 1.0,\n",
    "        \"reinforcement_learning_rate_multiplier\": 1.0,\n",
    "        \"kl_coeff\": 0.1, # increased to reduce reward hacking\n",
    "        \"instruction\":\\\n",
    "    \"Summarize in less than 50 words\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104c88a7",
   "metadata": {},
   "source": [
    "### Train with full dataset: dictionary 'parameter_values' \n",
    "\n",
    "- Adjust the settings for training with the full dataset to achieve optimal results in the evaluation (next lesson). Take a look at the new values; these results are from various training experiments in the pipeline, and the best parameter values are displayed here.\n",
    "\n",
    "```python\n",
    "parameter_values={\n",
    "        \"preference_dataset\": \\\n",
    "    \"gs://vertex-ai/generative-ai/rlhf/text/summarize_from_feedback_tfds/comparisons/train/*.jsonl\",\n",
    "        \"prompt_dataset\": \\\n",
    "    \"gs://vertex-ai/generative-ai/rlhf/text/reddit_tfds/train/*.jsonl\",\n",
    "        \"eval_dataset\": \\\n",
    "    \"gs://vertex-ai/generative-ai/rlhf/text/reddit_tfds/val/*.jsonl\",\n",
    "        \"large_model_reference\": \"llama-2-7b\",\n",
    "        \"reward_model_train_steps\": 10000,\n",
    "        \"reinforcement_learning_train_steps\": 10000, \n",
    "        \"reward_model_learning_rate_multiplier\": 1.0,\n",
    "        \"reinforcement_learning_rate_multiplier\": 0.2,\n",
    "        \"kl_coeff\": 0.1,\n",
    "        \"instruction\":\\\n",
    "    \"Summarize in less than 50 words\"}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8bc6d51",
   "metadata": {},
   "source": [
    "### Set up Google Cloud to run the Vertex AI pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9571014",
   "metadata": {},
   "source": [
    "Vertex AI is already installed in this classroom environment.  If you were running this on your own project, you would install Vertex AI SDK like this:\n",
    "```Python\n",
    "!pip3 install google-cloud-aiplatform\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf92aac",
   "metadata": {},
   "source": [
    "## Run the pipeline job on Vertex AI\n",
    "\n",
    "Now that we have created our dictionary of values, we can create a PipelineJob. This just means that the RLHF pipeline will execute on Vertex AI. So it's not running locally here in the notebook, but on some server on Google Cloud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1642b4-d16d-4e9b-ba87-3391168c5a11",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "import google.cloud.aiplatform as aiplatform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "427dc778-9a04-4816-8569-0b5ea1c39f14",
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "aiplatform.init(project = PROJECT_ID,\n",
    "                location = REGION,\n",
    "                credentials = credentials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3eac3e3-2d17-47d7-b69f-97a20e91042b",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "# Look at the path for the YAML file\n",
    "RLHF_PIPELINE_PKG_PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa58dce",
   "metadata": {},
   "source": [
    "### Create and run the pipeline job\n",
    "- Here is how you would create the pipeline job and run it if you were working on your own project.\n",
    "- This job takes about a full day to run with multiple accelerators (TPUs/GPUs), and so we're not going to run it in this classroom."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a3cf10",
   "metadata": {},
   "source": [
    "- To create the pipeline job:\n",
    "\n",
    "```Python\n",
    "job = aiplatform.PipelineJob(\n",
    "    display_name=\"tutorial-rlhf-tuning\",\n",
    "    pipeline_root=STAGING_BUCKET,\n",
    "    template_path=RLHF_PIPELINE_PKG_PATH,\n",
    "    parameter_values=parameter_values)\n",
    "```\n",
    "- To run the pipeline job:\n",
    "\n",
    "```Python\n",
    "job.run()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85bec5c2-7bc7-48f5-93e8-9bb9e5486000",
   "metadata": {},
   "source": [
    "- The content team has run this RLHF training pipeline to tune the Llama-2 model, and in the next lesson, you'll get to evaluate the log data to compare the performance of the tuned model with the original foundational model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a00c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "job = aiplatform.PipelineJob(\n",
    "    display_name=\"tutorial-rlhf-tuning\",\n",
    "    template_path=RLHF_PIPELINE_PKG_PATH,\n",
    "    parameter_values=parameter_values,\n",
    "    credentials=credentials\n",
    ")\n",
    "job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58569688",
   "metadata": {},
   "outputs": [],
   "source": [
    "job.submit(service_account=os.getenv(\"SERVICE_ACCOUNT\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cc3b6de",
   "metadata": {},
   "source": [
    "# Evaluate the Tuned Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f596bbd",
   "metadata": {},
   "source": [
    "#### Project environment setup\n",
    "\n",
    "- Install Tensorboard (if running locally)\n",
    "```Python\n",
    "!pip install tensorboard\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adddea6a",
   "metadata": {},
   "source": [
    "### Explore results with Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a9964a4-706b-4832-b4ab-9c668ba524e2",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84fd0dac-ca26-480b-975b-729ee01c09d7",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "port = %env PORT1\n",
    "%tensorboard --logdir data/reward-logs --port $port --bind_all "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4697495d-424a-4ad3-862a-995acfce49f0",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "# Look at what this directory has\n",
    "%ls data/reward-logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b1d22b-5266-4859-a24d-47d03a5ec6d8",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "port = %env PORT2\n",
    "%tensorboard --logdir data/reinforcer-logs --port $port --bind_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b17b76-9840-44a4-a503-650f22a4d38a",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "port = %env PORT3\n",
    "%tensorboard --logdir data/reinforcer-fulldata-logs --port $port --bind_all"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce32db1",
   "metadata": {},
   "source": [
    "- The dictionary of 'parameter_values' defined in the previous lesson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5cf353d-1264-47f6-995a-8a8f1043e08a",
   "metadata": {
    "height": 268
   },
   "outputs": [],
   "source": [
    "parameter_values={\n",
    "        \"preference_dataset\": \\\n",
    "    \"gs://vertex-ai/generative-ai/rlhf/text_small/summarize_from_feedback_tfds/comparisons/train/*.jsonl\",\n",
    "        \"prompt_dataset\": \\\n",
    "    \"gs://vertex-ai/generative-ai/rlhf/text_small/reddit_tfds/train/*.jsonl\",\n",
    "        \"eval_dataset\": \\\n",
    "    \"gs://vertex-ai/generative-ai/rlhf/text_small/reddit_tfds/val/*.jsonl\",\n",
    "        \"large_model_reference\": \"llama-2-7b\",\n",
    "        \"reward_model_train_steps\": 1410,\n",
    "        \"reinforcement_learning_train_steps\": 320,\n",
    "        \"reward_model_learning_rate_multiplier\": 1.0,\n",
    "        \"reinforcement_learning_rate_multiplier\": 1.0,\n",
    "        \"kl_coeff\": 0.1,\n",
    "        \"instruction\":\\\n",
    "    \"Summarize in less than 50 words\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a8fb9a2",
   "metadata": {},
   "source": [
    "**Note:** Here, we are using \"text_small\" for our datasets for learning purposes. However for the results that we're evaluating in this lesson, the team used the full dataset with the following hyperparameters:\n",
    "\n",
    "```Python\n",
    "parameter_values={\n",
    "        \"preference_dataset\": \\\n",
    "    \"gs://vertex-ai/generative-ai/rlhf/text/summarize_from_feedback_tfds/comparisons/train/*.jsonl\",\n",
    "        \"prompt_dataset\": \\\n",
    "    \"gs://vertex-ai/generative-ai/rlhf/text/reddit_tfds/train/*.jsonl\",\n",
    "        \"eval_dataset\": \\\n",
    "    \"gs://vertex-ai/generative-ai/rlhf/text/reddit_tfds/val/*.jsonl\",\n",
    "        \"large_model_reference\": \"llama-2-7b\",\n",
    "        \"reward_model_train_steps\": 10000,\n",
    "        \"reinforcement_learning_train_steps\": 10000, \n",
    "        \"reward_model_learning_rate_multiplier\": 1.0,\n",
    "        \"reinforcement_learning_rate_multiplier\": 0.2,\n",
    "        \"kl_coeff\": 0.1,\n",
    "        \"instruction\":\\\n",
    "    \"Summarize in less than 50 words\"}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e30aeeb3",
   "metadata": {},
   "source": [
    "### Evaluate using the tuned and untuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163d5544-a1fe-4c22-8d36-86f51a715889",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17305cf4-9615-475c-a747-c40e48354e8b",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "eval_tuned_path = 'data/eval_results_tuned.jsonl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e0b791a-975e-4ec2-9268-281eb9377c37",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "eval_data_tuned = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed93decd-c6ed-4746-bf9f-3351d414eb77",
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "with open(eval_tuned_path) as f:\n",
    "    for line in f:\n",
    "        eval_data_tuned.append(json.loads(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f5f3d1-17dc-45f7-8b25-6fe3f80ca8e6",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "# Import for printing purposes\n",
    "from utils import print_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5193a7f7-a6ac-4369-9f39-c7176c8828b1",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "# Look at the result produced by the tuned model\n",
    "print_d(eval_data_tuned[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37199f28-7d52-4530-98e6-2ba2fe255d6e",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "eval_untuned_path = 'data/eval_results_untuned.jsonl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6deecff9-c5ca-4f8c-802a-b76c8e3c3777",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "eval_data_untuned = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ede73e-dcf6-49b1-947a-2524815680cf",
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "with open(eval_untuned_path) as f:\n",
    "    for line in f:\n",
    "        eval_data_untuned.append(json.loads(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb71791-0421-40da-868c-4c681e7d35ff",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "# Look at the result produced by the untuned model\n",
    "print_d(eval_data_untuned[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dc805be",
   "metadata": {},
   "source": [
    "### Explore the results side by side in a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a18d95c7-5317-41c7-b545-749bbc536faa",
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "# Extract all the prompts\n",
    "prompts = [sample['inputs']['inputs_pretokenized']\n",
    "           for sample in eval_data_tuned]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adddcb4a-ed37-4b2e-8b57-a455854f5b79",
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "# Completions from the untuned model\n",
    "untuned_completions = [sample['prediction']\n",
    "                       for sample in eval_data_untuned]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b432b804-1214-45aa-b268-bcd11741b573",
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "# Completions from the tuned model\n",
    "tuned_completions = [sample['prediction']\n",
    "                     for sample in eval_data_tuned]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cec6f78",
   "metadata": {},
   "source": [
    "- Now putting all together in one big dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e3fb37-02f6-4539-bf6f-ee7fc717e981",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c86c93a8-3b65-470f-b110-018aa5e6fa09",
   "metadata": {
    "height": 81
   },
   "outputs": [],
   "source": [
    "results = pd.DataFrame(\n",
    "    data={'prompt': prompts,\n",
    "          'base_model':untuned_completions,\n",
    "          'tuned_model': tuned_completions})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df43314-62fe-4c0e-ad20-6e41bd9a3045",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b43249d-94a3-4252-9d12-29ad13e15c17",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "# Print the results\n",
    "results"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
